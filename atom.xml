<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ashley</title>
  
  <subtitle>It might be hard,but it&#39;s worthy.</subtitle>
  <link href="https://allmainashley.github.io/atom.xml" rel="self"/>
  
  <link href="https://allmainashley.github.io/"/>
  <updated>2021-01-15T13:28:29.344Z</updated>
  <id>https://allmainashley.github.io/</id>
  
  <author>
    <name>程海盐</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spacy tutorial</title>
    <link href="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/"/>
    <id>https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/</id>
    <published>2021-01-15T13:28:29.344Z</published>
    <updated>2021-01-15T13:28:29.344Z</updated>
    
    <content type="html"><![CDATA[<p>超过95% 的内容来自于<a href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">一篇非常全的 spacy 教程</a> , 剩余5%的来自于我在实践这篇教程中出的一些错误以及没想明白的问题。</p><a id="more"></a><h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><p><code>pip install spacy</code></p><p><code>python -m spacy download en</code>  下载语言包</p><h1 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h1><h2 id="Basic-processing"><a href="#Basic-processing" class="headerlink" title="Basic processing"></a><font color=cornf>Basic processing</font></h2><ul><li><p>导入模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p><font color=stbl>Doc对象</font>一个标记序列，不仅包含原始文本，还包含spaCy模型在处理文本之后产生的所有结果。预先计算有用的信息，例如文本的引理，是否是停用词，命名实体，文本的词向量等，并很容易地存储在Doc对象中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&quot;&quot;&quot;The economic situation of the country is on edge , as the stock</span></span><br><span class="line"><span class="string">market crashed causing loss of millions. Citizens who had their main investment</span></span><br><span class="line"><span class="string">in the share-market are facing a great loss. Many companies might lay off</span></span><br><span class="line"><span class="string">thousands of people to reduce labor cost&quot;&quot;&quot;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br></pre></td></tr></table></figure></li><li><p><font color=stbl>Token</font>是组成文本的各个文本实体。通常，令牌可以是单词，标点符号，空格等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure></li></ul><h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a><font color=cornf>Preprocessing</font></h2><ul><li><p>判断token是否是停用词</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--&#x27;</span>,token.is_stop,<span class="string">&#x27;---&#x27;</span>)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">The -- True ---</span><br><span class="line">economic -- False ---</span><br><span class="line">situation -- False ---</span><br><span class="line">of -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">country -- False ---</span><br><span class="line">is -- True ---</span><br><span class="line">on -- True ---</span><br><span class="line">edge -- False ---</span><br><span class="line">, -- False ---</span><br><span class="line">as -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">stock -- False ---</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>清除文本中的停用词和标点符号</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_doc_cleaned = [token <span class="keyword">for</span> token <span class="keyword">in</span> my_doc <span class="keyword">if</span> <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> <span class="keyword">not</span> token.is_punct]</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc_cleaned:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">economic</span><br><span class="line">situation</span><br><span class="line">country</span><br><span class="line">edge</span><br><span class="line">stock</span><br><span class="line"></span><br><span class="line">market</span><br><span class="line">crashed</span><br><span class="line">causing</span><br><span class="line">loss</span><br><span class="line">millions</span><br><span class="line">Citizens</span><br><span class="line">main</span><br><span class="line">investment</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>对文本进行这样的预处理,有时候甚至能够使得超过一半的令牌被删除。使处理更快，更有意义。</p></li></ul><h2 id="Lemmatization"><a href="#Lemmatization" class="headerlink" title="Lemmatization"></a><font color=cornf>Lemmatization</font></h2><p>举个例子, “played”, “playing”, “plays”, “play” 都是指向play的, 所以可以通过token的<code>lemma_</code>属性访问到其词根</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;she played chess against rita she likes playing chess.&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.lemma_,token.lemma)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-PRON- 561228191312463089</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">against 16640565335581469180</span><br><span class="line">rita 11924181115131733150</span><br><span class="line">-PRON- 561228191312463089</span><br><span class="line">like 18194338103975822726</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">. 12646065887601541794</span><br></pre></td></tr></table></figure><p>✨ 单词 <code>She</code>的 <code>lemma_</code> 属性是PRON, 是代词的意思</p><h2 id="Strings-to-Hashes"><a href="#Strings-to-Hashes" class="headerlink" title="Strings to Hashes"></a><font color=cornf>Strings to Hashes</font></h2><ul><li><p>打印单词</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">doc1 = nlp(<span class="string">&#x27;Raymond shirts are famous&#x27;</span>)</span><br><span class="line">doc2 = nlp(<span class="string">&#x27;I washed my shirts&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 1-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc1:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 2-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc2:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br></pre></td></tr></table></figure><p>有趣的是，一个单词将具有相同的哈希值，而不管它出现在哪个文档中或使用哪个spaCy模型。因此，即使您在其他人的计算机上运行代码，您的结果也是可重现的。</p></li></ul><h2 id="Other-Token’s-Attributes"><a href="#Other-Token’s-Attributes" class="headerlink" title="Other Token’s Attributes"></a><font color=cornf>Other Token’s Attributes</font></h2><ul><li><p>只打印数字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;2020 is far worse than 2009&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        print(token)</span><br></pre></td></tr></table></figure></li><li><p>只列出百分比</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">production_text=<span class="string">&#x27; Production in chennai is 87 %. In Kolkata, produce it as low as 43 %. In Bangalore, production ia as good as 98 %.In mysore, production is average around 78 %&#x27;</span></span><br><span class="line">doc = nlp(production_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        next_token_index = token.i +<span class="number">1</span></span><br><span class="line">        next_token = doc[next_token_index]</span><br><span class="line">        <span class="keyword">if</span> next_token.text == <span class="string">&#x27;%&#x27;</span>:</span><br><span class="line">            print(token.text)</span><br></pre></td></tr></table></figure><p>第<code>i</code>个token如果是数字并且第<code>i+1</code>个token是<code>%</code>，则它是百分比，可以打印</p></li><li><p>只列出电子邮件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">employee_text=<span class="string">&quot;&quot;&quot; name : Koushiki age: 45 email : koushiki@gmail.com</span></span><br><span class="line"><span class="string">                 name : Gayathri age: 34 email: gayathri1999@gmail.com</span></span><br><span class="line"><span class="string">                 name : Ardra age: 60 email : ardra@gmail.com</span></span><br><span class="line"><span class="string">                 name : pratham parmar age: 15 email : parmar15@yahoo.com</span></span><br><span class="line"><span class="string">                 name : Shashank age: 54 email: shank@rediffmail.com</span></span><br><span class="line"><span class="string">                 name : Utkarsh age: 46 email :utkarsh@gmail.com&quot;&quot;&quot;</span></span><br><span class="line">employee_doc = nlp(employee_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> employee_doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_email:</span><br><span class="line">        print(token.text)</span><br></pre></td></tr></table></figure></li><li><p>同样，spaCy提供了各种令牌属性。以下是这些属性及其执行的功能的列表:</p><ul><li><code>token.is_alpha</code>：返回<code>True</code>令牌是否为字母</li><li><code>token.is_ascii</code>：返回<code>True</code>令牌是否属于ASCII字符</li><li><code>token.is_digit</code>：返回<code>True</code>令牌是否为数字（0-9）</li><li><code>token.is_upper</code>：返回<code>True</code>令牌是否为大写字母</li><li><code>token.is_lower</code>：返回<code>True</code>令牌是否为小写字母</li><li><code>token.is_space</code>：返回<code>True</code>令牌是否为空格’’</li><li><code>token.is_bracket</code>：返回<code>True</code>令牌是否为括号</li><li><code>token.is_quote</code>：返回<code>True</code>令牌是否为引号</li><li><code>token.like_url</code>：返回<code>True</code>令牌是否类似于URl（链接到网站）</li></ul></li></ul><h2 id="Speech-Tags"><a href="#Speech-Tags" class="headerlink" title="Speech Tags"></a><font color=cornf>Speech Tags</font></h2><ul><li><p>打印出所有token的词性标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_text=<span class="string">&#x27;John plays basketball,if time permits. He played in high school too.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--------&#x27;</span>,token.pos_)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">John -------- PROPN</span><br><span class="line">plays -------- VERB</span><br><span class="line">basketball -------- NOUN</span><br><span class="line">, -------- PUNCT</span><br><span class="line">if -------- SCONJ</span><br><span class="line">time -------- NOUN</span><br><span class="line">permits -------- VERB</span><br><span class="line">. -------- PUNCT</span><br><span class="line">He -------- PRON</span><br><span class="line">played -------- VERB</span><br><span class="line">in -------- ADP</span><br><span class="line">high -------- ADJ</span><br><span class="line">school -------- NOUN</span><br><span class="line">too -------- ADV</span><br><span class="line">. -------- PUNCT</span><br></pre></td></tr></table></figure></li><li><p>解释标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spacy.explain(<span class="string">&#x27;SCONJ&#x27;</span>)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#39;subordinating conjunction&#39;</span><br></pre></td></tr></table></figure></li><li><p>使用spacy的<code>pos_</code>属性，您可以检查特定令牌是否为垃圾邮件并删除。(删除类似<code>etc</code>, <code>i.e.</code>等词汇)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">raw_text=<span class="string">&quot;&quot;&quot;I liked the movies etc The movie had good direction  The movie was amazing i.e.</span></span><br><span class="line"><span class="string">            The movie was average direction was not bad The cinematography was nice. i.e.</span></span><br><span class="line"><span class="string">            The movie was a bit lengthy  otherwise fantastic  etc etc&quot;&quot;&quot;</span></span><br><span class="line">raw_doc = nlp(raw_text)</span><br><span class="line">print(<span class="string">&#x27;The junk value are...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> raw_doc:</span><br><span class="line">    <span class="keyword">if</span> token.pos_==<span class="string">&#x27;X&#x27;</span>:</span><br><span class="line">        print(token.text)</span><br><span class="line">cleaned_doc = [token <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc <span class="keyword">if</span> <span class="keyword">not</span> token.pos_ == <span class="string">&#x27;X&#x27;</span>]</span><br><span class="line">print(cleaned_doc)</span><br></pre></td></tr></table></figure></li><li><p>查看所有标签</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_tags =  &#123;token.pos: token.pos_ <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc&#125;</span><br><span class="line">print(all_tags)</span><br></pre></td></tr></table></figure></li></ul><h2 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a><font color=cornf>Named Entity Recognition</font></h2><ul><li><p>实体命名识别</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">print(doc.ents)</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> doc.ents:</span><br><span class="line">    print(entity.text,<span class="string">&#x27;-------&#x27;</span>,entity.label_)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(Tony Stark, StarkEnterprises, Emily Clark, Microsoft, Manchester, Bible, French)</span><br><span class="line">Tony Stark ------- PERSON</span><br><span class="line">StarkEnterprises ------- ORG</span><br><span class="line">Emily Clark ------- PERSON</span><br><span class="line">Microsoft ------- ORG</span><br><span class="line">Manchester ------- GPE</span><br><span class="line">Bible ------- WORK_OF_ART</span><br><span class="line">French ------- NORP</span><br></pre></td></tr></table></figure><p>每个命名实体都属于一个类别，例如人名，组织或城市等。spacy支持的常见命名实体类别为：</p><ul><li><code>PERSON</code> ：代表人名</li><li><code>GPE</code> ：表示县，城市，州等地方。</li><li><code>ORG</code> ：表示组织或公司</li><li><code>WORK_OF_ART</code> ：表示书籍，电影，歌曲和其他艺术的标题</li><li><code>PRODUCT</code> ：表示车辆，食品，家具等产品。</li><li><code>EVENT</code> ：表示战争，灾难等历史事件…</li><li><code>LANGUAGE</code> ：全球所有公认的语言。</li></ul></li><li><p>可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy <span class="keyword">import</span> displacy</span><br><span class="line">displacy.render(doc,style=<span class="string">&#x27;ent&#x27;</span>,jupyter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png" loading="lazy"></p></li><li><p>提取品牌名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mobile_industry_article=<span class="string">&quot;&quot;&quot; 30 Major mobile phone brands Compete in India – A Case Study of Success and Failures</span></span><br><span class="line"><span class="string">Is the Indian mobile market a terrible War Zone? We have more than 30 brands competing with each other. Let’s find out some insights about the world second-largest mobile bazaar.There is a massive invasion by Chinese mobile brands in India in the last four years. Some of the brands have been able to make a mark while others like Meizu, Coolpad, ZTE, and LeEco are a failure.On one side, there are brands like Sony or HTC that have quit from the Indian market on the other side we have new brands like Realme or iQOO entering the marketing in recent months.The mobile market is so competitive that some of the brands like Micromax, which had over 18% share back in 2014, now have less than 5%. Even the market leader Samsung with a 34% market share in 2014, now has a 21% share whereas Xiaomi has become a market leader. The battle is fierce and to sustain and scale-up is going to be very difficult for any new entrant.new comers in Indian Mobile MarketiQOO –They have recently (March 2020) launched the iQOO 3 in India with its first 5G phone – iQOO 3. The new brand is part of the Vivo or the BBK electronics group that also owns several other brands like Oppo, Oneplus and Realme.Realme – Realme launched the first-ever phone – Realme 1 in November 2018 and has quickly became a popular brand in India. The brand is one of the highest sellers in online space and even reached a 16% market share threatening Xiaomi’s dominance.iVoomi – In 2017, we have seen the entry of some new Chinese mobile brands likeiVoomi which focuses on the sub 10k price range, and is a popular online player. They have an association with Flipkart.Techno &amp;amp; Infinix – Transsion Group’s Tecno and Infinix brands debuted in India in mid-2017 and are focusing on the low end and mid-range phones in the price range of Rs. 5000 to Rs. 12000.10.OR &amp;amp; Lephone – 10.OR has a partnership with Amazon India and is an exclusive online brand with phones like 10.OR D, G and E. However, the brand is not very aggressive currently.Kult – Kult is another player who launched a very aggressively priced Kult Beyond mobile in 2017 and followed up by launching 2-3 more models.However, most of these new brands are finding it difficult to strengthen their footing in India. As big brands like Xiaomi leave no stone unturned to make things difficult.Also, it is worth noting that there is less Chinese players coming to India now. As either all the big brands have already set shop or burnt their hands and retreated to the homeland China.Chinese/ Global  Brands Which failed or are at the Verge of Failing in India?</span></span><br><span class="line"><span class="string">There are a lot more failures in the market than the success stories. Let’s first look at the failures and then we will also discuss why some brands were able to succeed in India.HTC – The biggest surprise this year for me was the failure of HTC in India. The brand has been in the country for many years, in fact, they were the first brand to launch Android mobiles. Finally HTC decided to call it a day in July 2018.LeEco – LeEco looked promising and even threatening to Xiaomi when it came to India. The company launched a series of new phones and smart TVs at affordable rates. Unfortunately, poor financial planning back home caused the brand to fail in India too.LG – The company seems to have lost focus and are doing poorly in all segments. While the budget and mid-range offering are uncompetitive, the high-end models are not preferred by buyers.Sony – Absurd pricing and lack of ability to understand the Indian buyers have caused Sony to shrink mobile operations in India. In the last 2 years, there are far fewer launches and hardly any promotions or hype around the new products.Meizu – Meizu is also a struggling brand in India and is going nowhere with the current strategy. There are hardly any popular mobiles nor a retail presence.ZTE – The company was aggressive till last year with several new phones launching under the Nubia banner, but with recent issues in the US, they have even lost the plot in India.Coolpad – I still remember the first meeting with Coolpad CEO in Mumbai when the brand started operations. There were big dreams and ambitions, but the company has not been able to deliver and keep up with the rivals in the last 1 year.Gionee – Gionee was doing well in the retail, but the infighting in the company and loss of focus from the Chinese parent company has made it a failure. The company is planning a comeback. However, we will have to wait and see when that happens.&quot;&quot;&quot;</span></span><br><span class="line">mobile_doc = nlp(mobile_industry_article)</span><br><span class="line">list_of_org = []</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> mobile_doc.ents:</span><br><span class="line">    <span class="keyword">if</span> entity.label_ == <span class="string">&#x27;ORG&#x27;</span>:</span><br><span class="line">        list_of_org.append(entity.text)</span><br><span class="line">print(list_of_org)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#39;Meizu&#39;, &#39;Sony&#39;, &#39;Vivo&#39;, &#39;Xiaomi&#39;, &#39;Flipkart&#39;, &#39;Techno &amp;amp&#39;, &#39;Infinix – Transsion Group&#39;, &#39;12000.10.OR &amp;amp&#39;, &#39;Lephone&#39;, &#39;Amazon India&#39;, &#39;Global  Brands&#39;, &#39;the Verge of Failing&#39;, &#39;Sony&#39;, &#39;Sony&#39;, &#39;Meizu&#39;, &#39;Meizu&#39;, &#39;Nubia&#39;]</span><br></pre></td></tr></table></figure></li><li><p>自动掩盖实体</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">news_text=<span class="string">&quot;&quot;&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to Hyderabad, according to a media report on Saturday.Yogesh Ashok Yariava, the prime accused in the fraud, flew from Abu Dhabi to Hyderabad on a Vande Bharat repatriation flight on May 11 with around 170 evacuees, the Gulf News reported.Yariava, the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to India, the daily said.</span></span><br><span class="line"><span class="string">The bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).</span></span><br><span class="line"><span class="string">The list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.</span></span><br><span class="line"><span class="string">The aggrieved traders have filed a case with the Bur Dubai police station.</span></span><br><span class="line"><span class="string">The traders said when the dud cheques started bouncing they rushed to the Royal Luck&#x27;s office in Dubai but the shutters were down, even the fraudulent company&#x27;s warehouses were empty.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">news_doc=nlp(news_text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_details</span>(<span class="params">word</span>):</span></span><br><span class="line">  <span class="keyword">if</span> word.ent_type_ ==<span class="string">&#x27;PERSON&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;ORG&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;GPE&#x27;</span>:</span><br><span class="line">    print(word,<span class="string">&#x27;-----&#x27;</span>,word.ent_type_)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; UNKNOWN &#x27;</span></span><br><span class="line">  <span class="keyword">return</span> word.string</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_article</span>(<span class="params">doc</span>):</span></span><br><span class="line">    <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents:</span><br><span class="line">        ent.merge()</span><br><span class="line">        <span class="comment"># Iterate over all spans and merge them into one token. This is done</span></span><br><span class="line">        <span class="comment"># after setting the entities – otherwise, it would cause mismatched indices!</span></span><br><span class="line">    tokens = map(remove_details,doc)</span><br><span class="line">    <span class="comment"># map函数：第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个集合。</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(tokens)</span><br><span class="line">update_article(news_doc)</span><br></pre></td></tr></table></figure><p>打印结果: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to  UNKNOWN , according to a media report on Saturday. UNKNOWN , the prime accused in the fraud, flew from  UNKNOWN to  UNKNOWN on a Vande Bharat repatriation flight on May 11 with around 170 evacuees,  UNKNOWN reported. UNKNOWN , the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to  UNKNOWN , the daily said.\nThe bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).\nThe list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.\nThe aggrieved traders have filed a case with the  UNKNOWN police station.\nThe traders said when the dud cheques started bouncing they rushed to  UNKNOWN office in  UNKNOWN but the shutters were down, even the fraudulent company&#39;s warehouses were empty.&quot;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Rule-based-Matching"><a href="#Rule-based-Matching" class="headerlink" title="Rule based Matching"></a><font color=cornf>Rule based Matching</font></h2><ul><li><p>导入模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> Matcher</span><br></pre></td></tr></table></figure></li><li><p>过程</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221506.png" loading="lazy"></p></li></ul><ul><li><p>模式匹配 <code>Example1</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&#x27;The version : 6 of the app was released about a year back and was not very sucessful. As a comeback, six months ago, version : 7 was released and it took the stage. After that , the app has has the limelight till now. On interviewing some sources, we get to know that they have outlined visiond till version : 12 ,the Ultimate.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"></span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LOWER&quot;</span>:<span class="string">&quot;version&quot;</span>&#125;,&#123;<span class="string">&quot;IS_PUNCT&quot;</span>:<span class="literal">True</span>&#125;,&#123;<span class="string">&quot;LIKE_NUM&quot;</span>:<span class="literal">True</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;VersionFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">desired_matches = mather(my_doc)</span><br><span class="line">desired_matches</span><br></pre></td></tr></table></figure><p>打印desired_matches的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[(6950581368505071052, 1, 4),</span><br><span class="line"> (6950581368505071052, 27, 30),</span><br><span class="line"> (6950581368505071052, 65, 68)]</span><br></pre></td></tr></table></figure><p>打印出找到的token:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> match_id,start,end <span class="keyword">in</span> desired_matches:</span><br><span class="line">    string_id = nlp.vocab.strings[match_id]</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">version : 6</span><br><span class="line">version : 7</span><br><span class="line">version : 12</span><br></pre></td></tr></table></figure></li><li><p>模式识别 <code>Example 2</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot;&quot;&quot;I visited Manali last time. Around same budget trips ? &quot;</span></span><br><span class="line"><span class="string">    I was visiting Ladakh this summer &quot;</span></span><br><span class="line"><span class="string">    I have planned visiting NewYork and other abroad places for next year&quot;</span></span><br><span class="line"><span class="string">    Have you ever visited Kodaikanal? &quot;&quot;&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">mather = Matcher(nlp.vocab)</span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LEMMA&quot;</span>: <span class="string">&quot;visit&quot;</span>&#125;, &#123;<span class="string">&quot;POS&quot;</span>: <span class="string">&quot;PROPN&quot;</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;PlaceFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">matches = mather(doc)</span><br><span class="line">print(<span class="string">&quot; mather found: &quot;</span>,len(matches))</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    print(<span class="string">&#x27;Match Found:&#x27;</span>,doc[start:end].text)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mather found:  4</span><br><span class="line">Match Found: visited Manali</span><br><span class="line">Match Found: visiting Ladakh</span><br><span class="line">Match Found: visiting NewYork</span><br><span class="line">Match Found: visited Kodaikanal</span><br></pre></td></tr></table></figure></li><li><p>复杂的匹配条件: 其中第一个令牌具有POS标记为NOUN或ADJ的条件, 第二个token为<code>engineering</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_pattern = [&#123;<span class="string">&quot;POS&quot;</span>: &#123;<span class="string">&quot;IN&quot;</span>: [<span class="string">&quot;NOUN&quot;</span>, <span class="string">&quot;ADJ&quot;</span>]&#125;&#125;, &#123;<span class="string">&quot;LOWER&quot;</span>: <span class="string">&quot;engineering&quot;</span>&#125;]</span><br></pre></td></tr></table></figure></li></ul><h2 id="Phrase-Matcher"><a href="#Phrase-Matcher" class="headerlink" title="Phrase Matcher"></a><font color=cornf>Phrase Matcher</font></h2><ul><li><p>导入模块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> PhraseMatcher</span><br></pre></td></tr></table></figure></li><li><p>定义模式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab)</span><br><span class="line">terms_list = [<span class="string">&#x27;Bruce Wayne&#x27;</span>, <span class="string">&#x27;Tony Stark&#x27;</span>, <span class="string">&#x27;Batman&#x27;</span>, <span class="string">&#x27;Harry Potter&#x27;</span>, <span class="string">&#x27;Severus Snape&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line"><span class="comment"># 将短语列表转换为doc对象。它更快并且节省时间。make_doc()</span></span><br><span class="line">matcher.add(<span class="string">&#x27;phrase_matcher&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line"></span><br><span class="line">matches = matcher(doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = fictional_char_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure><p>打印结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Batman</span><br><span class="line">Batman</span><br><span class="line">Harry Potter</span><br><span class="line">Harry Potter</span><br><span class="line">Tony Stark</span><br></pre></td></tr></table></figure><p>可以发现小写单词的无法识别出来, 那么做一下改进</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line"><span class="comment"># 如果使用，则将发生不区分大小写的匹配。attr=&#x27;LOWER&#x27;</span></span><br></pre></td></tr></table></figure></li><li><p>举个例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">case_insensitive_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line">my_doc = nlp(<span class="string">&#x27;I wish to visit new york city.&#x27;</span>)</span><br><span class="line">terms_list = [<span class="string">&#x27;New York&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line">case_insensitive_matcher.add(<span class="string">&#x27;mather&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line">my_matches = case_insensitive_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> my_matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure><p>打印结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new york</span><br></pre></td></tr></table></figure></li><li><p>匹配将基于pattern中术语的形状。<code>attr=&#39;SHAPE&#39;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">my_doc = nlp(<span class="string">&#x27;From 8 am , Mr.X will be speaking on your favorite chanel 191.1. Afterward there shall be an exclusive interview with actor Vijay on channel 194.1 . Hope you are having a great day. Call us on 666666&#x27;</span>)</span><br><span class="line">pattern = nlp(<span class="string">&#x27;154.6&#x27;</span>)</span><br><span class="line">pincode_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;SHAPE&#x27;</span>)</span><br><span class="line">pincode_matcher.add(<span class="string">&#x27;pincode_matching&#x27;</span>,<span class="literal">None</span>,pattern)</span><br><span class="line">matches = pincode_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure><p>打印结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">191.1</span><br><span class="line">194.1</span><br></pre></td></tr></table></figure></li></ul><h2 id="Entity-Ruler"><a href="#Entity-Ruler" class="headerlink" title="Entity Ruler"></a><font color=cornf>Entity Ruler</font></h2><ul><li><p>默认情况下无法识别某些名称或组织。可能是因为它们规模很小或稀有。使用EnityRuler, 基于模式词典匹配命名实体, 从而使命名实体识别更加有效</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.pipeline <span class="keyword">import</span> EntityRuler</span><br><span class="line">ruler = EntityRuler(nlp)</span><br><span class="line">pattern=[&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;WORK_OF_ART&quot;</span>, <span class="string">&quot;pattern&quot;</span>: <span class="string">&quot;My guide to statistics&quot;</span>&#125;]</span><br><span class="line">ruler.name = <span class="string">&#x27;new_ruler&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ruler.add_patterns(pattern)</span><br><span class="line">nlp.add_pipe(ruler)</span><br><span class="line"><span class="comment"># 现在，EntityRuler已合并到中nlp。您可以将文本文档传递nlp给以创建spacy doc。</span></span><br><span class="line">doc = nlp(<span class="string">&quot; I recently published my work fanfiction by Dr.X . Right now I&#x27;m studying the book of my friend .You should try My guide to statistics for clear concepts.&quot;</span>)</span><br><span class="line">print([(ent.text,ent.label_) <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents])</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#39;My guide to statistics&#39;, &#39;WORK_OF_ART&#39;)]</span><br></pre></td></tr></table></figure></li></ul><h2 id="Word-Vector-and-Similarity"><a href="#Word-Vector-and-Similarity" class="headerlink" title="Word Vector and Similarity"></a><font color=cornf>Word Vector and Similarity</font></h2><ul><li><p>单词向量: <code>token.has_vector</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_md&quot;</span>)</span><br><span class="line">doc = nlp(<span class="string">&quot;I　am a excellent people&quot;</span>)</span><br><span class="line">doc_another = nlp(<span class="string">&quot;I wish to go to hogwarts lolXD&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc_another:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.vector_norm)<span class="comment"># 表示L2范数</span></span><br><span class="line">    print(<span class="string">&#x27;------------------------------&#x27;</span>)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">I   True</span><br><span class="line">I   6.4231944</span><br><span class="line">------------------------------</span><br><span class="line">wish   True</span><br><span class="line">wish   5.1652417</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">go   True</span><br><span class="line">go   5.05723</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">hogwarts   True</span><br><span class="line">hogwarts   7.4110312</span><br><span class="line">------------------------------</span><br><span class="line">lolXD   False</span><br><span class="line">lolXD   0.0</span><br><span class="line">------------------------------</span><br></pre></td></tr></table></figure></li><li><p>单词相似性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">review_1=nlp(<span class="string">&#x27; The food was amazing&#x27;</span>)</span><br><span class="line">review_2=nlp(<span class="string">&#x27;The food was excellent&#x27;</span>)</span><br><span class="line">review_3=nlp(<span class="string">&#x27;I did not like the food&#x27;</span>)</span><br><span class="line">review_4=nlp(<span class="string">&#x27;It was very bad experience&#x27;</span>)</span><br><span class="line">score_1 = review_1.similarity(review_2)</span><br><span class="line">print(score_1)</span><br><span class="line">score_2 = review_3.similarity(review_4)</span><br><span class="line">print(score_2)</span><br><span class="line"><span class="comment"># 您会看到前两个评论具有很高的相似性评分，因此将属于同一类别（正面）。</span></span><br><span class="line"><span class="comment"># 数值很低则代表完全不相关</span></span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.9566209228174343</span><br><span class="line">0.8461895934074601</span><br></pre></td></tr></table></figure></li></ul><h2 id="Merging-and-Splitting-Tokens-with-retokenize"><a href="#Merging-and-Splitting-Tokens-with-retokenize" class="headerlink" title="Merging and Splitting Tokens with retokenize"></a><font color=cornf>Merging and Splitting Tokens with retokenize</font></h2><ul><li><p>组合令牌：set the <code>POS</code> (part of speech tag) for “John Wick” as <code>PROPN</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从输出中可以看到，“ John”和“ Wick”已被识别为单独的标记。导演的名字“ Chad Stahelski”也是如此</span></span><br><span class="line"><span class="comment"># 但是在这种情况下，如果将“ John Wick”视为单个令牌，将更加容易。</span></span><br><span class="line">text = <span class="string">&quot;John Wick is a 2014 American action thriller film directed by Chad Stahelski&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    attrs = &#123;<span class="string">&quot;POS&quot;</span>:<span class="string">&quot;PROPN&quot;</span>&#125;</span><br><span class="line">    retokenizer.merge(doc[<span class="number">0</span>:<span class="number">2</span>],attrs)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,token.pos_)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">John Wick PROPN</span><br><span class="line">is AUX</span><br><span class="line">a DET</span><br><span class="line">2014 NUM</span><br><span class="line">American ADJ</span><br><span class="line">action NOUN</span><br><span class="line">thriller NOUN</span><br><span class="line">film NOUN</span><br><span class="line">directed VERB</span><br><span class="line">by ADP</span><br><span class="line">Chad PROPN</span><br><span class="line">Stahelski PROPN</span><br></pre></td></tr></table></figure></li><li><p>拆分令牌：将 <code>OnePlus7</code> 拆分成 <code>OnePlus</code> 和 <code>7</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">doc=nlp(<span class="string">&#x27;I purchased the trendy OnePlus7 &#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    <span class="comment"># heads = [(doc[4],0),(doc[4],1)]</span></span><br><span class="line">    <span class="comment"># heads = [doc[0],doc[1]]</span></span><br><span class="line">    heads = [(doc[<span class="number">2</span>],<span class="number">1</span>),(doc[<span class="number">2</span>],<span class="number">0</span>)]</span><br><span class="line">    print(heads)</span><br><span class="line">    retokenizer.split(doc[<span class="number">4</span>],[<span class="string">&quot;OnePlus&quot;</span>,<span class="string">&quot;7&quot;</span>],heads=heads)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text)</span><br></pre></td></tr></table></figure><p>❓ 不知道为啥 <code>heads</code> 瞎写都可以, 但是要满足两个条件: :one:如果要把待拆分的token分成n个,那么heads里的元素也要有n个,否则会报错 :two:heads里, doc的下标不能越界。看了官方文档也没有弄明白😥</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" alt="spacy02" loading="lazy"></p></li></ul><h2 id="Pipeline-components"><a href="#Pipeline-components" class="headerlink" title="Pipeline components "></a><font color=cornf>Pipeline components </font></h2><ul><li><p>查看管道组件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br><span class="line">print(nlp.pipe_names)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.add_pipe(nlp.create_pipe(<span class="string">&#x27;textcat&#x27;</span>),before=<span class="string">&#x27;ner&#x27;</span>)</span><br></pre></td></tr></table></figure><p>如果用<code>juypter notebook</code>跑这段代码，只能跑一次否则就会报错，说这个已经存在了。</p></li><li><p>移除管道组件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.remove_pipe(<span class="string">&#x27;textcat&#x27;</span>)</span><br></pre></td></tr></table></figure></li><li><p>换个名字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nlp.rename_pipe(old_name=<span class="string">&#x27;ner&#x27;</span>,new_name=<span class="string">&#x27;new_ner&#x27;</span>)</span><br><span class="line">nlp.pipe_names</span><br></pre></td></tr></table></figure></li><li><p>一样的结果：<code>nlp.make_doc()</code> 和 <code>nlp()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docs = [nlp(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br><span class="line">docs = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br></pre></td></tr></table></figure></li><li><p>比 <code>nlp()</code> 更快的处理方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docs = list(nlp.pipe(list_of_text_data))</span><br></pre></td></tr></table></figure></li></ul><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a><font color=mediumseagreen>Tutorials</font></h2><ul><li><a href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">[SpaCy Tutorial – Complete Writeup]</a> 主要来源于这篇，写的太全了。不过有些没看懂。</li></ul><h2 id="Official-Documentation"><a href="#Official-Documentation" class="headerlink" title="Official Documentation"></a><font color=mediumseagreen>Official Documentation</font></h2><ul><li><a href="https://spacy.io/usage/visualizers">VIsualization: Displacy</a></li><li><a href="https://spacy.io/usage/linguistic-features#_title">Linguistic Features</a></li><li><a href="https://spacy.io/usage/rule-based-matching#_title">Rule-based matching</a></li><li><a href="https://explosion.ai/demos/matcher?text=A%20match%20is%20a%20tool%20for%20starting%20a%20fire.%20Typically,%20modern%20matches%20are%20made%20of%20small%20wooden%20sticks%20or%20stiff%20paper.%20One%20end%20is%20coated%20with%20a%20material%20that%20can%20be%20ignited%20by%20frictional%20heat%20generated%20by%20striking%20the%20match%20against%20a%20suitable%20surface.%20Wooden%20matches%20are%20packaged%20in%20matchboxes,%20and%20paper%20matches%20are%20partially%20cut%20into%20rows%20and%20stapled%20into%20matchbooks.&model=en_core_web_sm&pattern=%5B%7B%22id%22:1,%22attrs%22:%5B%7B%22name%22:%22LEMMA%22,%22value%22:%22visit%22%7D,%7B%22name%22:%22POS%22,%22value%22:%22PROPN%22%7D%5D%7D%5D">Rule-based Matcher Explorer</a></li></ul><h2 id="CSDN-tutorials"><a href="#CSDN-tutorials" class="headerlink" title="CSDN tutorials"></a><font color=mediumseagreen>CSDN tutorials</font></h2><ul><li><p><a href="https://blog.csdn.net/Chen_he_Zhang/article/details/105345353">Spcay 安装</a></p></li><li><p><a href="https://blog.csdn.net/u012436149/article/details/79321112">使用 spacy 进行自然语言处理（一）</a></p></li><li><p><a href="https://blog.csdn.net/bmicnj/article/details/107189649?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control">python spacy库使用总结【待完善】</a></p></li></ul><h2 id="Bugs"><a href="#Bugs" class="headerlink" title="Bugs"></a><font color=mediumseagreen>Bugs</font></h2><ul><li><a href="https://stackoverflow.com/questions/51412095/spacy-save-custom-pipeline">Can’t find factory for ‘xxxxxxx’</a></li><li><a href="https://stackoverflow.com/questions/57536044/add-multiple-entityruler-with-spacy-valueerror-entity-ruler-already-exists-i">ValueError: ‘entity_ruler’ already exists in pipeline</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;超过95% 的内容来自于&lt;a href=&quot;https://www.machinelearningplus.com/spacy-tutorial-nlp/&quot;&gt;一篇非常全的 spacy 教程&lt;/a&gt; , 剩余5%的来自于我在实践这篇教程中出的一些错误以及没想明白的问题。&lt;/p&gt;</summary>
    
    
    
    <category term="Tutorial" scheme="https://allmainashley.github.io/categories/Tutorial/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Tutorial/Machine-Learning/"/>
    
    
    <category term="NLP" scheme="https://allmainashley.github.io/tags/NLP/"/>
    
    <category term="Spacy" scheme="https://allmainashley.github.io/tags/Spacy/"/>
    
  </entry>
  
  <entry>
    <title>NLP Relevant Knowledge</title>
    <link href="https://allmainashley.github.io/2021/01/09/Notes/Machine%20Learning/NLP%20Relevant%20Knowledge/"/>
    <id>https://allmainashley.github.io/2021/01/09/Notes/Machine%20Learning/NLP%20Relevant%20Knowledge/</id>
    <published>2021-01-09T13:07:16.302Z</published>
    <updated>2021-01-09T13:07:16.302Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><ul><li><p>The Porter Stemming Algorithm：词干提取算法</p><p>The purpose of stemming is to bring variant forms of a word together, not to map a word onto its ‘paradigm’ form.</p><p>波特词干算法是一种处理词干或从标记中除去前缀和后缀以形成标准化形式的算法。</p><p><font color=indianred>References</font>：<a href="https://blog.csdn.net/whuslei/article/details/7398443?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control">英文分词算法</a>、<a href="https://blog.csdn.net/kl28978113/article/details/54574784?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-10&spm=1001.2101.3001.4242">英文分词算法和原理</a>、<a href="http://snowball.tartarus.org/algorithms/porter/diffs.txt">词语处理后的结果</a></p></li><li><p>文档之间的夹角越近，余弦相似度（Cos theta）越高。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The Porter Stemming Algorithm：词干提取算法&lt;/p&gt;
&lt;p&gt;The purpose of stemming is to bring variant forms of a word toget</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Analysis of Questions and Answers in major NLP Datasets</title>
    <link href="https://allmainashley.github.io/2021/01/07/Notes/Machine%20Learning/Analysis%20of%20Questions%20and%20Answers%20in%20major%20NLP%20Datasets/"/>
    <id>https://allmainashley.github.io/2021/01/07/Notes/Machine%20Learning/Analysis%20of%20Questions%20and%20Answers%20in%20major%20NLP%20Datasets/</id>
    <published>2021-01-07T14:12:36.007Z</published>
    <updated>2021-01-07T14:12:36.007Z</updated>
    
    <content type="html"><![CDATA[<p>主要的分析数据集有：RACE、ROCStories、COIN Shared Task 1、TQA、SciQ</p><a id="more"></a><h1 id="对问题类型进行分类"><a href="#对问题类型进行分类" class="headerlink" title="对问题类型进行分类"></a>对问题类型进行分类</h1><p>存在的问题：</p><ul><li><p><font color=mediumseagreen><strong>不是所有问题都有特定的提示词：如 <code>what，how，where</code></strong> </font></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108104147.png" loading="lazy"></p></li><li><p><font color=mediumseagreen><strong>有 <code>what</code> 这个词但是问题类型是 <code>why</code></strong> </font><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108103519.png" loading="lazy"></p><p>既出现 <code>what</code>，也出现 <code>when</code>：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108112548.png" loading="lazy"></p><p><strong>解决方案：只查找大写的 <code>What</code>，这样可以避免某些问题分类错误</strong></p></li><li><p><font color=mediumseagreen><strong>没有明显的 <code>what，how，where</code> 但可以通过 <code>because</code>这类词推断出是<code>why</code>类型的问题</strong></font></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108104633.png" loading="lazy"></p></li></ul><p><font color=indianred>仅通过单词来分，不仅容易分类失误，而且只能很浅显地给问题分类，无法判断该问题属于细节推理、全局推理、文章总结、态度分析或世界外部知识。</font></p><h2 id="RACE"><a href="#RACE" class="headerlink" title="RACE"></a><font color=carolgreen>RACE</font></h2><h3 id="统计结果"><a href="#统计结果" class="headerlink" title="统计结果"></a>统计结果</h3><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108202623.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109094237.png" loading="lazy"></p><h2 id="ROCStories"><a href="#ROCStories" class="headerlink" title="ROCStories "></a><font color=carolgreen>ROCStories </font></h2><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108165549.png" loading="lazy"></p><p>问题类型：给出四个句子作为context，推测出文章的最后一句话。</p><h2 id="COIN-Shared-Task-1"><a href="#COIN-Shared-Task-1" class="headerlink" title="COIN Shared Task 1"></a><font color=carolgreen>COIN Shared Task 1</font></h2><h3 id="统计结果-1"><a href="#统计结果-1" class="headerlink" title="统计结果"></a>统计结果</h3><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108205156.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109094433.png" loading="lazy"></p><h2 id="TQA"><a href="#TQA" class="headerlink" title="TQA"></a><font color=carolgreen>TQA</font></h2><p><strong>问题类型</strong></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210112225356.png" loading="lazy"></p><p><strong>问题子类型</strong></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210112225403.png" alt="myplot3" loading="lazy"></p><p>问题类型共有两种类型。有的问题没有问题子类型。</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109091609.png" loading="lazy"></p><h2 id="SciQ"><a href="#SciQ" class="headerlink" title="SciQ"></a><font color=carolgreen>SciQ</font></h2><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109103332.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109103457.png" loading="lazy"></p><p>由于只选择大写的What, 就会出现部分问题被遗漏:</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109102855.png" loading="lazy"></p><h1 id="对答案类型进行分类"><a href="#对答案类型进行分类" class="headerlink" title="对答案类型进行分类"></a>对答案类型进行分类</h1><h2 id="RACE-1"><a href="#RACE-1" class="headerlink" title="RACE"></a><font color=carolgreen>RACE</font></h2><h3 id="统计结果-2"><a href="#统计结果-2" class="headerlink" title="统计结果"></a>统计结果</h3><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108133411.png" loading="lazy"></p><p>横轴表示每个答案的单词个数有多少，纵轴表示相同答案长度的个数。</p><h2 id="ROCStories-1"><a href="#ROCStories-1" class="headerlink" title="ROCStories "></a><font color=carolgreen>ROCStories </font></h2><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109093633.png" loading="lazy"></p><h2 id="COIN-Shared-Task-1-1"><a href="#COIN-Shared-Task-1-1" class="headerlink" title="COIN Shared Task 1"></a><font color=carolgreen>COIN Shared Task 1</font></h2><h3 id="统计结果-3"><a href="#统计结果-3" class="headerlink" title="统计结果"></a>统计结果</h3><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210108205414.png" loading="lazy"></p><h2 id="TQA-1"><a href="#TQA-1" class="headerlink" title="TQA"></a><font color=carolgreen>TQA</font></h2><p> possible answer options- the number and form will depend on the question type </p><h2 id="SciQ-1"><a href="#SciQ-1" class="headerlink" title="SciQ"></a><font color=carolgreen>SciQ</font></h2><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109104100.png" loading="lazy"></p><h1 id="模型在哪些问题和哪些答案跑得好"><a href="#模型在哪些问题和哪些答案跑得好" class="headerlink" title="模型在哪些问题和哪些答案跑得好"></a>模型在哪些问题和哪些答案跑得好</h1><ul><li><p>在colab上跑所有数据, 跑两个小时就跑不动了</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210109094605.png" loading="lazy"></p></li><li><p>跑部分数据还没有尝试过, 如果按照问题类型分数据, 对怎么分问题类型存在上述问题.</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;主要的分析数据集有：RACE、ROCStories、COIN Shared Task 1、TQA、SciQ&lt;/p&gt;</summary>
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Dataset Analysis" scheme="https://allmainashley.github.io/tags/Dataset-Analysis/"/>
    
    <category term="NLP" scheme="https://allmainashley.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Build MxNet environment on Colab</title>
    <link href="https://allmainashley.github.io/2021/01/06/Notes/Machine%20Learning/Build%20MxNet%20environment%20on%20Colab/"/>
    <id>https://allmainashley.github.io/2021/01/06/Notes/Machine%20Learning/Build%20MxNet%20environment%20on%20Colab/</id>
    <published>2021-01-06T06:42:32.560Z</published>
    <updated>2021-01-06T06:42:32.560Z</updated>
    
    <content type="html"><![CDATA[<p>笔记本CUDA跑不动，Out of Memory, 所以在Colab上跑<a href="https://arxiv.org/abs/1901.09381v2">Dual Co-Matching Network for Multi-choice Reading Comprehension</a>这篇paper。</p><p>又由于bert-embedding似乎有限制，所以用cuda9.2和mxnet-cu92，因为没有试过，不知道其他版本能不能行，所以还是跟着官网来吧。</p><a id="more"></a><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210106145227.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210106145305.png" loading="lazy"></p><h1 id="Colab搭建CUDA9-2环境"><a href="#Colab搭建CUDA9-2环境" class="headerlink" title="Colab搭建CUDA9.2环境"></a>Colab搭建CUDA9.2环境</h1><ul><li>查看cuda版本</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!cat &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;version.txt</span><br><span class="line">!nvcc -V</span><br></pre></td></tr></table></figure><ul><li>安装CUDA9.2</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!wget https:&#x2F;&#x2F;developer.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;9.2&#x2F;Prod2&#x2F;local_installers&#x2F;cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64</span><br><span class="line">!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.148-1_amd64</span><br><span class="line">!apt-key add &#x2F;var&#x2F;cuda-repo-9-2-local&#x2F;7fa2af80.pub</span><br><span class="line">!apt-get update</span><br><span class="line">!apt-get install cuda&#x3D;9.2.148-1</span><br></pre></td></tr></table></figure><p><font color=indianred>references</font>: <a href="https://blog.csdn.net/Xu_Claire/article/details/103112076">Google Colab里安装cuda9.0(或者cuda 8.0)</a>、<a href="https://goosemi.wordpress.com/2018/09/15/how-to-get-cuda-9-2-backend-for-pytorch-0-4-1-on-google-colab/">How to get Cuda 9.2 backend for PyTorch 0.4.1 on Google Colab.</a></p><h1 id="安装MXNet及依赖包"><a href="#安装MXNet及依赖包" class="headerlink" title="安装MXNet及依赖包"></a>安装MXNet及依赖包</h1><ul><li>安装bert-embedding （注意：bert-embedding要在）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install bert-embedding</span><br></pre></td></tr></table></figure><ul><li>安装依赖包</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!apt install libnvrtc9.1</span><br></pre></td></tr></table></figure><ul><li>安装mxnet</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install mxnet-cu92</span><br></pre></td></tr></table></figure><ul><li>升级numpy</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy --upgrade</span><br></pre></td></tr></table></figure><ul><li>安装gluonnlp</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install gluonnlp</span><br></pre></td></tr></table></figure><ul><li>安装cnocr（不确定有没有起作用）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install cnocr --no-dependencies</span><br></pre></td></tr></table></figure><ul><li>挂载到Google Drive上</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from google.colab import drive</span><br><span class="line">drive.mount(&#39;&#x2F;content&#x2F;drive&#x2F;&#39;)</span><br></pre></td></tr></table></figure><ul><li>添加要运行的文件目录</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.chdir(&quot;&#x2F;content&#x2F;drive&#x2F;My Drive&#x2F;Dual Co-Matching Network for Multi-choice Reading Comprehension&#x2F;dcmn&#x2F;src&quot;)</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><p>​    <font color=steelblue>注意：上传到google drive上的文件都是在<code>content/drive</code>目录下的，<code>Dual Co-Matching Network for Multi-choice Reading Comprehension</code>是单独上传的一个文件夹。接下来要运行的<code>main.py</code>是在<code>/content/drive/My Drive/Dual Co-Matching Network for Multi-choice Reading Comprehension/dcmn/src</code>文件目录下的。</font></p><ul><li>执行main.py文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python main.py</span><br></pre></td></tr></table></figure><hr><p>到目前出现了警告，但还是能够持续运行，等运行出来后再继续更新。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[09:51:55] src&#x2F;base.cc:51: Upgrade advisory: this mxnet has been built against cuda library version 9020, which is older than the oldest version tested by CI (10000).  Set MXNET_CUDA_LIB_CHECKING&#x3D;0 to quiet this warning.</span><br></pre></td></tr></table></figure><hr><p>没有后续了，Colab炸了，出不来结果。​🤡​小丑竟是我自己。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;笔记本CUDA跑不动，Out of Memory, 所以在Colab上跑&lt;a href=&quot;https://arxiv.org/abs/1901.09381v2&quot;&gt;Dual Co-Matching Network for Multi-choice Reading Comprehension&lt;/a&gt;这篇paper。&lt;/p&gt;
&lt;p&gt;又由于bert-embedding似乎有限制，所以用cuda9.2和mxnet-cu92，因为没有试过，不知道其他版本能不能行，所以还是跟着官网来吧。&lt;/p&gt;</summary>
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="NLP" scheme="https://allmainashley.github.io/tags/NLP/"/>
    
    <category term="MxNet" scheme="https://allmainashley.github.io/tags/MxNet/"/>
    
    <category term="Colab" scheme="https://allmainashley.github.io/tags/Colab/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV Learning Notes</title>
    <link href="https://allmainashley.github.io/2020/12/26/Notes/OpenCV/OpenCV%20Learning%20Notes/"/>
    <id>https://allmainashley.github.io/2020/12/26/Notes/OpenCV/OpenCV%20Learning%20Notes/</id>
    <published>2020-12-26T03:50:48.055Z</published>
    <updated>2020-12-26T03:50:48.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OpenCV学习笔记"><a href="#OpenCV学习笔记" class="headerlink" title="OpenCV学习笔记"></a>OpenCV学习笔记</h1><blockquote><p><strong>References</strong>：</p><ul><li><p><a href="https://github.com/vipstone/faceai">link01</a></p></li><li><p><a href="http://woshicv2er.com/">link02</a></p></li></ul></blockquote><hr><h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><h2 id="图像入门"><a href="#图像入门" class="headerlink" title="图像入门"></a>图像入门</h2><ul><li><p><code>cv2.imread()</code></p><p>parameter 1: 路径</p><p>parameter 2: 除了一下三个标志，你可以分别简单地传递整数1、0或-1。</p><ul><li><p>cv2.IMREAD_COLOR： 加载彩色图像。任何图像的透明度都会被忽视。它是默认标志。</p></li><li><p>cv2.IMREAD_GRAYSCALE：以灰度模式加载图像</p></li><li><p>cv2.IMREAD_UNCHANGED：加载图像，包括alpha通道</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"></span><br><span class="line">＃加载彩色图像</span><br><span class="line">img = cv2.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>，<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>:warning:即使图像路径错误，它也不会引发任何错误，但是<code>print img</code>会给出<code>None</code></p></li><li><p><code>cv2.imshow()</code></p><p>在窗口中显示图像。窗口自动适合图像尺寸。</p><p>parameter 1: 窗口名称，它是一个字符串</p><p>parameter 2: 对象名称。你可以根据需要创建任意多个窗口，但需使用不同的窗口名称</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>，img）</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p><code>cv2.waitKey()</code>是一个键盘绑定函数。其参数是以<code>毫秒</code>为单位的时间。该函数等待任何键盘事件指定的毫秒。如果您在这段时间内按下任何键，程序将继续运行。如果<code>0</code>被传递，它将无限期地等待一次敲击键。它也可以设置为检测特定的按键，例如，如果按下键 a 等，我们将在下面讨论。</p><blockquote><p>注意 除了键盘绑定事件外，此功能还处理许多其他GUI事件，因此你必须使用它来实际显示图像。</p></blockquote><p>📌<code>cv2.destroyAllWindows()</code>只会破坏我们创建的所有窗口。如果要销毁任何特定的窗口，请使用函数 <code>cv2.destroyWindow</code>()在其中传递确切的窗口名称作为参数。</p><p>:warning: 在特殊情况下，你可以创建一个空窗口，然后再将图像加载到该窗口。在这种情况下，你可以指定窗口是否可调整大小。这是通过功能<code>cv2.namedWindow()</code>完成的。默认情况下，该标志为<code>cv2.WINDOW_AUTOSIZE</code>。但是，如果将标志指定为<code>cv2.WINDOW_NORMAL</code>，则可以调整窗口大小。当图像尺寸过大以及向窗口添加跟踪栏时，这将很有帮助。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cv2.namedWindow(&#39;image&#39;，cv2.WINDOW_NORMAL)</span><br><span class="line">cv2.imshow(&#39;image&#39;，img)</span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure></li><li><p><code>cv2.imwrite()</code></p><p>parameter 1: 文件名</p><p>parameter 2: 要保存的图像对象</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.imwrite(<span class="string">&#x27;messigray.png&#x27;</span>，img)</span><br></pre></td></tr></table></figure></li><li><p><strong>Demo</strong>: 以灰度加载图像，显示图像，按<code>s</code>保存图像并退出，或者按<code>ESC</code>键直接退出而不保存。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>,img)</span><br><span class="line">k = cv2.waitKey(<span class="number">0</span>) &amp; <span class="number">0xFF</span></span><br><span class="line"><span class="keyword">if</span> k == <span class="number">27</span>:         <span class="comment"># 等待ESC退出</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"><span class="keyword">elif</span> k == ord(<span class="string">&#x27;s&#x27;</span>): <span class="comment"># 等待关键字，保存和退出</span></span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;messigray.png&#x27;</span>,img)</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><p>:warning:OpenCV加载的彩色图像处于BGR模式。但是Matplotlib以RGB模式显示。因此，如果使用OpenCV读取彩色图像，则Matplotlib中将无法正确显示彩色图像。</p></li></ul><h2 id="绘图功能"><a href="#绘图功能" class="headerlink" title="绘图功能"></a>绘图功能</h2><ul><li><p><strong>参数列表</strong></p><ul><li>img：您要绘制形状的图像</li><li>color：形状的颜色。对于BGR，将其作为元组传递，例如：(255,0,0)对于蓝色。对于灰度，只需传递标量值即可。</li><li>厚度：线或圆等的粗细。如果对闭合图形（如圆）传递<code>-1</code> ，它将填充形状。<em>默认厚度= 1</em></li><li>lineType：线的类型，是否为8连接线，抗锯齿线等。<em>默认情况下</em>，为8连接线。<code>cv2.LINE_AA</code>给出了抗锯齿的线条，看起来非常适合曲线。</li></ul></li><li><p>画线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># 创建黑色的图像</span></span><br><span class="line">img = np.zeros((<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>), np.uint8)</span><br><span class="line"><span class="comment"># 绘制一条厚度为5的蓝色对角线</span></span><br><span class="line">cv2.line(img,(<span class="number">0</span>,<span class="number">0</span>),(<span class="number">511</span>,<span class="number">511</span>),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>),<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>(0,0) 开始坐标 (511,511) 结束坐标</p></li><li><p>画矩形</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在图像的右上角绘制一个绿色矩形</span></span><br><span class="line">cv2.rectangle(img,(<span class="number">384</span>,<span class="number">0</span>),(<span class="number">510</span>,<span class="number">128</span>),(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>),<span class="number">3</span>)</span><br></pre></td></tr></table></figure></li><li><p>画圆圈</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要绘制一个圆，需要其中心坐标和半径。我们将在上面绘制的矩形内绘制一个圆</span></span><br><span class="line">cv2.circle(img,(<span class="number">447</span>,<span class="number">63</span>), <span class="number">63</span>, (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), <span class="number">-1</span>)</span><br></pre></td></tr></table></figure></li><li><p>要绘制椭圆，</p><p>参数: </p><ul><li>中心位置（x，y）</li><li>轴长度（长轴长度，短轴长度）</li><li>angle是椭圆沿逆时针方向旋转的角度</li><li>startAngle和endAngle表示从主轴沿顺时针方向测量的椭圆弧的开始和结束, 即给出0°到180°半个椭圆。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv2.ellipse(img,(256,256),(100,50),0,0,180,255,-1)</span><br></pre></td></tr></table></figure></li><li><p>画多边形</p><p>要绘制多边形，首先需要顶点的坐标。将这些点组成形状为<code>ROWSx1x2</code>的数组，其中<code>ROWS</code>是顶点数，并且其类型应为int32。在这里，我们绘制了一个带有四个顶点的黄色小多边形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pts = np.array([[<span class="number">10</span>,<span class="number">5</span>],[<span class="number">20</span>,<span class="number">30</span>],[<span class="number">70</span>,<span class="number">20</span>],[<span class="number">50</span>,<span class="number">10</span>]], np.int32)</span><br><span class="line">pts = pts.reshape((<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">cv2.polylines(img,[pts],<span class="literal">True</span>,(<span class="number">0</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br></pre></td></tr></table></figure></li><li><p>向图像添加文本：在图像上写入”OpenCV”</p><ul><li>要写入的文字数据 </li><li>要放置它的位置坐标（即数据开始的左下角)</li><li>字体类型（检查<code>cv2.putText</code>文档以获取受支持的字体）</li><li>字体比例（指定字体大小） </li><li>常规的内容，例如颜色，厚度，线条类型等</li><li>为了获得更好的外观，建议使用lineType = <code>cv2.LINE_AA</code>。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">font = cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line">cv2.putText(img,<span class="string">&#x27;OpenCV&#x27;</span>,(<span class="number">10</span>,<span class="number">500</span>), font, <span class="number">4</span>,(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>),<span class="number">2</span>,cv2.LINE_AA)</span><br></pre></td></tr></table></figure></li></ul><h2 id="图像操作"><a href="#图像操作" class="headerlink" title="图像操作"></a>图像操作</h2><ul><li><p>访问和修改像素值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img = cv.imread(<span class="string">&#x27;messi5.jpg&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>px = img[<span class="number">100</span>,<span class="number">100</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( px )</span><br><span class="line">[<span class="number">157</span> <span class="number">166</span> <span class="number">200</span>]</span><br><span class="line"><span class="comment"># 仅访问蓝色分量</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>blue = img[<span class="number">100</span>,<span class="number">100</span>,<span class="number">0</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( blue )</span><br><span class="line"><span class="number">157</span></span><br></pre></td></tr></table></figure><p>修改像素值: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>img[<span class="number">100</span>,<span class="number">100</span>] = [<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( img[<span class="number">100</span>,<span class="number">100</span>] )</span><br><span class="line">[<span class="number">255</span> <span class="number">255</span> <span class="number">255</span>]</span><br></pre></td></tr></table></figure><p>📌上面的方法通常用于选择数组的区域，例如前5行和后3列。对于单个像素访问，Numpy数组方法<code>array.item()</code>和<code>array.itemset())</code>被认为更好，但是它们始终返回标量。如果要访问所有B，G，R值，则需要分别调用所有的<code>array.item()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 访问 RED 值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img.item(<span class="number">10</span>,<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"><span class="number">59</span></span><br><span class="line"><span class="comment"># 修改 RED 值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img.itemset((<span class="number">10</span>,<span class="number">10</span>,<span class="number">2</span>),<span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img.item(<span class="number">10</span>,<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure></li><li><p>访问图片属性: 行数，列数和通道数，图像数据类型，像素数等</p><ul><li><p>访问形状</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( img.shape )</span><br><span class="line">(<span class="number">342</span>, <span class="number">548</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>:warning:如果图像是灰度的，则返回的元组仅包含行数和列数，因此这是检查加载的图像是灰度还是彩色的好方法。</p></li><li><p>像素总数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( img.size )</span><br><span class="line"><span class="number">562248</span></span><br></pre></td></tr></table></figure></li><li><p>图像数据类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print( img.dtype )</span><br><span class="line">uint8</span><br></pre></td></tr></table></figure></li></ul></li><li><p>图像感兴趣区域ROI</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ball = img[<span class="number">280</span>:<span class="number">340</span>, <span class="number">330</span>:<span class="number">390</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img[<span class="number">273</span>:<span class="number">333</span>, <span class="number">100</span>:<span class="number">160</span>] = ball </span><br></pre></td></tr></table></figure></li><li><p>拆分和合并图像通道</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>b,g,r = cv.split(img)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img = cv.merge((b,g,r))</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = img [:, :, <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 假设你要将所有红色像素都设置为零，则无需先拆分通道。numpy索引更快：</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>img [:, :, <span class="number">2</span>] = <span class="number">0</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="人脸检测"><a href="#人脸检测" class="headerlink" title="人脸检测"></a>人脸检测</h1><ul><li>首先将图片转换为灰度图，用训练好的分类器查找人脸，再给图片画上矩形。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">filepath=<span class="string">&quot;dataset/face02.bmp&quot;</span></span><br><span class="line">img=cv2.imread(filepath)<span class="comment"># 读取图片</span></span><br><span class="line">img_gray=cv2.cv2tColor(img,cv2.COLOR_BGR2GRAY)<span class="comment"># 转换为灰度图</span></span><br><span class="line">classifier=cv2.CascadeClassifier(<span class="string">&quot;E:\haarcascades\haarcascade_frontalface_default.xml&quot;</span>)</span><br><span class="line">color=(<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">faceRecs=classifier.detectMultiScale(img_gray,scaleFactor=<span class="number">1.2</span>,minNeighbors=<span class="number">3</span>,minSize=(<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line"><span class="keyword">if</span> len(faceRecs):</span><br><span class="line">    <span class="keyword">for</span> faceRec <span class="keyword">in</span> faceRecs:</span><br><span class="line">        x,y,w,h=faceRec</span><br><span class="line">        <span class="comment"># 框出人脸</span></span><br><span class="line">        cv2.rectangle(img, (x, y), (x + h, y + w), color, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 左眼</span></span><br><span class="line">        cv2.circle(img, (x + w // <span class="number">4</span>, y + h // <span class="number">4</span> + <span class="number">30</span>), min(w // <span class="number">8</span>, h // <span class="number">8</span>),</span><br><span class="line">                   color)</span><br><span class="line">        <span class="comment"># 右眼</span></span><br><span class="line">        cv2.circle(img, (x + <span class="number">3</span> * w // <span class="number">4</span>, y + h // <span class="number">4</span> + <span class="number">30</span>), min(w // <span class="number">8</span>, h // <span class="number">8</span>),</span><br><span class="line">                   color)</span><br><span class="line">        <span class="comment"># 嘴巴</span></span><br><span class="line">        cv2.rectangle(img, (x + <span class="number">3</span> * w // <span class="number">8</span>, y + <span class="number">3</span> * h // <span class="number">4</span>),</span><br><span class="line">                      (x + <span class="number">5</span> * w // <span class="number">8</span>, y + <span class="number">7</span> * h // <span class="number">8</span>), color)</span><br><span class="line"></span><br><span class="line">    cv2.imshow(<span class="string">&quot;image&quot;</span>, img)  <span class="comment"># 显示图像</span></span><br><span class="line">    c = cv2.waitKey(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    cv2.waitKey(<span class="number">10</span>)</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="Function-Introduction"><a href="#Function-Introduction" class="headerlink" title="Function  Introduction"></a>Function  Introduction</h1><ul><li><p><code>waitKey(0)</code> will display the window infinitely until any keypress (it is suitable for image display).</p></li><li><p><code>waitKey(1)</code> will display a frame for 1 ms, after which display will be automatically closed</p></li><li><p><code>cv2.destroyAllWindows()</code> simply destroys all the windows we created. To destroy any specific window, use the function <code>cv2.destroyWindow()</code> where you pass the exact window name.</p></li></ul><h2 id="My-Understanding"><a href="#My-Understanding" class="headerlink" title="My Understanding"></a>My Understanding</h2><blockquote><ul><li><p><code>waitKey(x)</code>    x毫秒后消失</p></li><li><p><code>cv2.rectangle(img,(x,y),(x+w,y+w),color,2)</code>  </p><p>img: 所选图片；(x,y): 左下角坐标；(x+w,y+w) 右上角坐标；color: 颜色；2：方框的线宽</p></li><li><p>CascadeClassifier：级联分类器</p></li><li><p><code>classifier.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3, minSize=(32, 32)</code></p><p>gray：转换的灰图；scaleFactor：图像缩放比例，可理解为相机的X倍镜；minNeighbors：对特征检测点周边多少有效点同时检测，这样可避免因选取的特征检测点太小而导致遗漏；minSize：特征检测点的最小尺寸</p></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;OpenCV学习笔记&quot;&gt;&lt;a href=&quot;#OpenCV学习笔记&quot; class=&quot;headerlink&quot; title=&quot;OpenCV学习笔记&quot;&gt;&lt;/a&gt;OpenCV学习笔记&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/stron</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="OpenCV" scheme="https://allmainashley.github.io/categories/Notes/OpenCV/"/>
    
    
    <category term="OpenCV" scheme="https://allmainashley.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>Deep Learning in NLP</title>
    <link href="https://allmainashley.github.io/2020/11/16/Notes/Machine%20Learning/Deep%20Learning%20in%20NLP/"/>
    <id>https://allmainashley.github.io/2020/11/16/Notes/Machine%20Learning/Deep%20Learning%20in%20NLP/</id>
    <published>2020-11-16T07:14:34.429Z</published>
    <updated>2020-11-16T07:14:34.429Z</updated>
    
    <content type="html"><![CDATA[<p> Reading notes of《Deep Learning in NLP》✨</p><p>It is almost about natural language processing functions explainations.</p><a id="more"></a><h1 id="Data-Preparation"><a href="#Data-Preparation" class="headerlink" title="Data Preparation"></a>Data Preparation</h1><ul><li><p><strong>Split by Whitespace</strong></p><p>文章被空格分开；</p><p>标点符号和前一个单词连在一起（比如 <code>&#39;dream.&#39;</code>）；</p><p>**<font color=indianre>优点：</font>**部分标点符号被保留（比如<code>&quot;wasn&#39;t&quot;</code>和<code>&#39;armour-like&#39;</code>）</p><p>**<font color=tomato>缺点:</font>**缩写词被分开（比如<code>What&#39;s </code>变为<code>&#39;&quot;What\&#39;s&#39;</code>）；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">text=file.read()</span><br><span class="line">words=text.split()</span><br></pre></td></tr></table></figure></li><li><p><strong>Select Words</strong></p><p>文章以单词形式被分开；</p><p>单词去除了标点符号；</p><p>缺点：<code>armour-like</code>变成两个词 <code>&#39;armour&#39;,&#39;like&#39; </code>、<code>What&#39;s</code>变成<code>&#39;What&#39;,&#39;s&#39;</code>；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">words=re.split(<span class="string">r&#x27;\W+&#x27;</span>,text)</span><br></pre></td></tr></table></figure></li><li><p><strong>Split by Whitespace and Remove Punctuation</strong></p><p>文章被空格分开，并去除标点符号。需要用到<code>string.punctuation</code>,打印的结果是 <font color=LighCoral>*<em>!”#$%&amp;’()</em>+,-./:;&lt;=&gt;?@[]^_`{|}~**</font></p><p><code>What&#39;s</code>变为<code>&#39;Whats&#39;</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">words = text.split()</span><br><span class="line">re_punc=re.compile(<span class="string">&#x27;[%s]&#x27;</span>%re.escape(string.punctuation))</span><br><span class="line">stripped=[re_punc.sub(<span class="string">&#x27;&#x27;</span>,w) <span class="keyword">for</span> w <span class="keyword">in</span> words]</span><br></pre></td></tr></table></figure><p>有些字符无法被打印，我们可以用同样的方法筛去这些字符。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">words = text.split()</span><br><span class="line">re_print=re.compile(<span class="string">&#x27;[%s]&#x27;</span>%re.escape(string.printable))</span><br><span class="line">stripped=[re_print.sub(<span class="string">&#x27;&#x27;</span>,w) <span class="keyword">for</span> w <span class="keyword">in</span> words]</span><br></pre></td></tr></table></figure></li><li><p><strong>Normalizing Case</strong></p><p>把所有词转换为相同形式（小写）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">words = text.split()</span><br><span class="line">words = [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> words]</span><br><span class="line">print(words[:<span class="number">100</span>])</span><br></pre></td></tr></table></figure></li><li><p><strong>sent_tokenize</strong>（使用nltk库）</p><p>文章以句子的形式划分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> sent_tokenize</span><br><span class="line">sentences = sent_tokenize(text)</span><br></pre></td></tr></table></figure></li><li><p><strong>word_tokenize</strong></p><p>文章以词的形式划分（有些标点符号也被划分成立token，但我们可以滤除它们）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> word_tokenize</span><br><span class="line">tokens = word_tokenize(text)</span><br></pre></td></tr></table></figure></li><li><p><strong>Filter Out Punctuation</strong><br>可以通过遍历token’，并只保留那些是字母的token（python内置函数<code>isalpha()</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tokens = word_tokenize(text)</span><br><span class="line">words = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokens <span class="keyword">if</span> word.isalpha()]</span><br></pre></td></tr></table></figure></li><li><p><strong>Filter out Stop Words (and Pipeline)</strong></p><p>stop words对词组深层含义词没什么帮助，它们通常是<code>the</code>、<code>a</code>、<code>is</code>等等。NLTK提供了一系列不同语言版本的停用词，它们可以被这样载入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line">stop_words = stopwords.words(<span class="string">&#x27;english</span></span><br></pre></td></tr></table></figure><p>它们打印出来都是小写，所以在filter out前记得把要处理的文本也变为小写。</p></li><li><p><strong>Stem Words</strong></p><p>Stemming是指将每个词还原为词根或词基的过程。主流的老办法是Porter Stemming algorithm，可在nltk中载入PorterStemmer 类后使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">porter=PorterStemmer()</span><br><span class="line">stemmed=[porter.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> tokens]</span><br></pre></td></tr></table></figure></li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul><li>Load the raw text. </li><li>Split into tokens. </li><li>Convert to lowercase. </li><li>Remove punctuation from each token. </li><li>Filter out remaining tokens that are not alphabetic. </li><li>Filter out tokens that are stop words</li></ul><h2 id="Additional-Text-Cleaning-Considerations"><a href="#Additional-Text-Cleaning-Considerations" class="headerlink" title="Additional Text Cleaning Considerations"></a>Additional Text Cleaning Considerations</h2><ul><li>Handling large documents and large collections of text documents that do not fit into memory. </li><li>Extracting text from markup like HTML, PDF, or other structured document formats. </li><li>Transliteration of characters from other languages into English. </li><li>Decoding Unicode characters into a normalized form, such as UTF8. </li><li>Handling of domain specific words, phrases, and acronyms. </li><li>Handling or removing numbers, such as dates and amounts. </li><li>Locating and correcting common typos and misspellings. </li><li>And much more…</li></ul><h1 id="Bag-of-Words-Model（Bow）"><a href="#Bag-of-Words-Model（Bow）" class="headerlink" title="Bag-of-Words Model（Bow）"></a>Bag-of-Words Model（Bow）</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Input:document Output: a class label</span><br><span class="line">convert documents to fixed-length vectors, the length is the length of the words,the value is a count or frequency of each word in encoded document.</span><br><span class="line">Each word should be encoded as a unique number</span><br></pre></td></tr></table></figure><p>编码不关心顺序，只关心频率，所以有很多方法可以进行编码，sklearn提供了如下三种编码方案。</p><ul><li><p><strong>Word Counts with CountVectorizer</strong></p><ul><li><p>Create <font color=salmon>an instance of the CountVectorizer class</font>. </p></li><li><p>Call the<font color=salmon> fit() function </font>in order to learn a vocabulary from one or more documents. </p></li><li><p>Call the <font color=salmon>transform() function </font>on one or more documents as needed to encode each as a vector.</p></li></ul><blockquote><p>An encoded vector is returned with<font color=chocolate> a length of the entire vocabulary</font> and <font color=chocolate> an integer count for the number of times each word appeared in the document</font>. Because these vectors will contain a lot of zeros, we call them <font color=Crimson><strong>sparse</strong></font>.</p></blockquote><p>使用<code>scipy.sparce</code>可以处理这些系数向量。调用transform()返回的向量将是稀疏向量，你可以通过调用toarray()函数，将它们转换回NumPy数组来查看，并更好地理解发生了什么事。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="comment"># list of text documents</span></span><br><span class="line">text = [<span class="string">&quot;The quick brown fox jumped over the lazy dog.&quot;</span>]</span><br><span class="line"><span class="comment"># create the transform</span></span><br><span class="line">vectorizer = CountVectorizer()</span><br><span class="line"><span class="comment"># tokenize and build vocab</span></span><br><span class="line">vectorizer.fit(text)</span><br><span class="line"><span class="comment"># summarize</span></span><br><span class="line">print(vectorizer.vocabulary_)</span><br><span class="line"><span class="comment"># encode document</span></span><br><span class="line">vector = vectorizer.transform(text)</span><br><span class="line"><span class="comment"># summarize encoded vector</span></span><br><span class="line">print(vector.shape)</span><br><span class="line">print(type(vector))</span><br><span class="line">print(vector.toarray())</span><br></pre></td></tr></table></figure><hr><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ptint(vectorizer.vocabulary_)</span><br><span class="line">print(vector.shape)</span><br><span class="line">print(type(vector))</span><br><span class="line">print(vector.toarray())</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;dog&#39;: 1, &#39;fox&#39;: 2, &#39;over&#39;: 5, &#39;brown&#39;: 0, &#39;quick&#39;: 6, &#39;the&#39;: 7, &#39;lazy&#39;: 4, &#39;jumped&#39;: 3&#125;</span><br><span class="line">(1, 8)</span><br><span class="line">&lt;class &#39;scipy.sparse.csr.csr_matrix&#39;&gt;</span><br><span class="line">[[1 1 1 1 1 1 1 2]]</span><br></pre></td></tr></table></figure><p>所有单词都是默认小写，标点符号已被去掉，向量长度为8，编码向量是稀疏矩阵。</p><p>可以用同一个vectorizer去计算不同文章的sparse vector。比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text2=[<span class="string">&quot;the puppy&quot;</span>]</span><br><span class="line">vector2=vectorizer.transform(text2)</span><br><span class="line">print(vector2.toarray())</span><br></pre></td></tr></table></figure></li><li><p><strong>Word Frequencies with TfidfVectorizer</strong></p><p>有些词，比如the，出现次数太多了以及就不大了。所以，一种替代方案是计算词频，一个主流办法是 TF-IDF（即Term Frequency - Inverse Document Frequency）</p><ul><li><strong>Term Frequency</strong>: This summarizes how often a given word appears within a document. </li><li><strong>Inverse Document Frequency</strong>: This downscales words that appear a lot across documents.（这是对文档中出现频率较高的词进行降频）</li></ul><p>TF-IDF是词频分数，尽量突出的是比较有意思的词，比如在一篇文档中频繁出现，但在不同文档中没有出现。</p><p><a href="https://zhuanlan.zhihu.com/p/31197209">link</a></p><blockquote><p>第一步，计算词频</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201116213953.png" loading="lazy"></p><p>考虑到文章有长短之分，为了便于不同文章的比较，进行”词频”标准化.</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201116214144.png" loading="lazy"></p><p>第二步，计算逆文档频率：</p><p>这时，需要一个语料库（corpus），用来模拟语言的使用环境。</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201116214304.jpg" loading="lazy"></p><p>如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以要加1，是为了避免分母为0（即所有文档都不包含该词）。log表示对得到的值取对数。</p><p>第三步，计算TF-IDF：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201116214234.png" loading="lazy"></p><p>可以看到，TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。所以，自动提取关键词的算法就很清楚了，就是<strong>计算出文档的每个词的TF-IDF值，然后按降序排列，取排在最前面的几个词。</strong></p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a><strong>优缺点</strong></h2><p>TF-IDF的优点是简单快速，而且容易理解。缺点是有时候用<strong>词频</strong>来衡量文章中的一个词的重要性不够全面，有时候重要的词出现的可能不够多，而且这种计算无法体现位置信息，无法体现词在上下文的重要性。如果要体现词的上下文结构，那么你可能需要使用word2vec算法来支持。</p></blockquote></li><li><p><strong>HashingVectorizer</strong></p><p>vocabulary可能很大，所以可以使用hash的方法把他们转换为装束，这样词汇也不是定长的了，缺点是hash是单向的，也就没有办法把他们从编码转换成词语了。作者想想有一些启发式的方法，你可以根据估计的词汇量大小来挑选哈希长度和碰撞的概率（例如75%的负载系数）。</p><p>编码文档的值默认对应于-1到1范围内的归一化字数，但可以通过改变默认配置使其成为简单的整数。</p></li></ul><h1 id="Prepare-Data-With-Keras"><a href="#Prepare-Data-With-Keras" class="headerlink" title="Prepare Data With Keras"></a>Prepare Data With Keras</h1><p> Keras provides the text to word sequence() function that you can use to split text into a list of words. By default, this function automatically does 3 things: </p><ul><li>Splits words by space. </li><li>Encoding with one hot </li><li>Filters out punctuation. </li><li>Converts text to lowercase (lower=True)</li></ul><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> text_to_word_sequence</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> one_hot</span><br><span class="line"></span><br><span class="line">text=<span class="string">&#x27;The quick brown fox jumped over the lazy dog.&#x27;</span></span><br><span class="line"><span class="comment"># words=text_to_word_sequence(text)</span></span><br><span class="line"><span class="comment"># vocab_size=len(words)</span></span><br><span class="line"><span class="comment"># print(vocab_size)</span></span><br><span class="line"></span><br><span class="line">words=set(text_to_word_sequence(text))  <span class="comment"># 去除重复的单词</span></span><br><span class="line"><span class="comment"># print(text_to_word_sequence(text))</span></span><br><span class="line"><span class="comment"># print(words)</span></span><br><span class="line">vocab_size=len(words)</span><br><span class="line">print(vocab_size)</span><br><span class="line">result=one_hot(text,round(vocab_size*<span class="number">1.3</span>))  <span class="comment"># ?</span></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><hr><ul><li><strong>hashing_trick</strong></li></ul><p>A limitation of integer and count base encodings is that they must maintain a vocabulary of words and their mapping to integers.An alternative to this approach is to use a one-way hash function to convert words to integers.</p><p>Keras provides the hashing trick() function that tokenizes and then integer encodes the document, just like the one hot() function.</p><hr><ul><li><p><strong>Tokenizer</strong></p><p>Once fit, the Tokenizer provides 4 attributes that you can use to query what has been learned about your documents: </p><ul><li>word counts: A dictionary mapping of words and their occurrence counts when the Tokenizer was fit. </li><li>word docs: A dictionary mapping of words and the number of documents that reach appears in. </li><li>word index: A dictionary of words and their uniquely assigned integers.</li><li>document count: A dictionary mapping and the number of documents they appear in calculated during the fit.</li></ul></li></ul><hr><p>The texts to matrix() function on the Tokenizer can be used to create one vector per document provided per input. The length of the vectors is the total size of the vocabulary. </p><ul><li>binary: Whether or not each word is present in the document. This is the default. </li><li>count: The count of each word in the document. </li><li>tfidf: The Text Frequency-Inverse DocumentFrequency (TF-IDF) scoring for each word in the document. </li><li>freq: The frequency of each word as a ratio of words within each document. We can put all of this together with a worked example</li></ul><hr><ul><li>A vocabulary of known words. </li><li>A measure of the presence of known words.</li></ul><h1 id="Bags-of-Words"><a href="#Bags-of-Words" class="headerlink" title="Bags of Words"></a>Bags of Words</h1><p><strong>Counter</strong>, which is a dictionary mapping of words and their count that allows us to easily update and query</p><hr><p>texts to matrix() </p><ul><li>binary 被标记为0或1</li><li>count 每个单词出现次数</li><li>tfidf 词频和逆词频</li><li>freq 词频</li></ul><hr><p><strong>Word Embedding</strong></p><p>用向量空间表示词语。</p><hr><p>Word2Vec模型中，主要有Skip-Gram和CBOW两种模型，从直观上理解，Skip-Gram是给定input word来预测上下文。而CBOW是给定上下文，来预测input word。本篇文章仅讲解Skip-Gram模型。</p><p>Both models are focused on learning about words given their local usage context, where the<br>context is defined by a window of neighboring words. This window is a configurable parameter<br>of the model.<br>The size of the sliding window has a strong effect on the resulting vector similarities.<br>Large windows tend to produce more topical similarities […], while smaller windows<br>tend to produce more functional and syntactic similarities.</p><hr><p><strong>Embedding Layer</strong></p><p>input dim: This is the size of the vocabulary in the text data.</p><p>output dim: This is the size of the vector space in which words will be embedded.</p><p>input length: This is the length of input sequences.</p><p>The output of the Embedding layer is a 2D vector with one embedding for each word in the input sequence of words (input document). If you wish to connect a Dense layer directly to an Embedding layer, you must first flatten the 2D output matrix to a 1D vector using the Flatten layer. Now, let’s see how we can use an Embedding layer in practice.</p><hr><p><a href="https://zhuanlan.zhihu.com/p/55412623">link: text_to sequences</a></p><p><code>texts_to_sequences</code>输出的是根据对应关系输出的向量序列，是不定长的，跟句子的长度有关系。</p><ul><li>word_counts：词频统计结果</li><li>word_index：词和index的对应关系</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line">text1=<span class="string">&#x27;Some ThING to eat !&#x27;</span></span><br><span class="line">text2=<span class="string">&#x27;some thing to drink .&#x27;</span></span><br><span class="line">texts=[text1,text2]</span><br><span class="line">print(texts)</span><br><span class="line"><span class="comment">#out:[&#x27;Some ThING to eat !&#x27;, &#x27;some thing to drink .&#x27;]</span></span><br><span class="line">tokenizer = Tokenizer(num_words=<span class="number">100</span>) <span class="comment">#num_words:None或整数,处理的最大单词数量。少于此数的单词丢掉</span></span><br><span class="line">tokenizer.fit_on_texts(texts)</span><br><span class="line">print( tokenizer.word_counts) </span><br><span class="line"><span class="comment">#out:OrderedDict([(&#x27;some&#x27;, 2), (&#x27;thing&#x27;, 2), (&#x27;to&#x27;, 2), (&#x27;eat&#x27;, 1), (&#x27;drink&#x27;, 1)])</span></span><br><span class="line">print( tokenizer.word_index) </span><br><span class="line"><span class="comment">#out:&#123;&#x27;some&#x27;: 1, &#x27;thing&#x27;: 2, &#x27;to&#x27;: 3, &#x27;eat&#x27;: 4, &#x27;drink&#x27;: 5&#125;</span></span><br><span class="line">sequences = tokenizer.texts_to_sequences(texts)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">print(sequences)</span><br><span class="line"><span class="comment">#out:[[1, 2, 3, 4], [1, 2, 3, 5]] 转换为序列，注意这里句子等长，所以输出一样，但是不等长句子输出的长度是不一样的</span></span><br><span class="line">print(<span class="string">&#x27;Found %s unique tokens.&#x27;</span> % len(word_index))</span><br><span class="line"><span class="comment">#out:Found 5 unique tokens.</span></span><br></pre></td></tr></table></figure><p><code>pad_sequences</code>,对上面生成的不定长序列进行补全。可以手动设定每个句子的最大长度参数，大于这个长度截断，小于这个长度填充。<strong>注意</strong>：默认补全和截断都是在句子前面进行填充和截断。这里是用0进行填充，也就是空格，这也是为什么上面序列index起始是1的原因。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接上面的代码</span></span><br><span class="line">SEQ_LEN = <span class="number">10</span></span><br><span class="line">data = pad_sequences(sequences, maxlen=SEQ_LEN)</span><br><span class="line">print(data)</span><br><span class="line"><span class="comment">#out:[[0 0 0 0 0 0 1 2 3 4]</span></span><br><span class="line"><span class="comment"># [0 0 0 0 0 0 1 2 3 5]]</span></span><br></pre></td></tr></table></figure><p><code>texts_to matrix</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#（也可以直接得到 one-hot 二进制表示。）这个分词器也支持除 one-hot 编码外的其他向量化模式</span></span><br><span class="line">one_hot_results = tokenizer.texts_to_matrix(samples, mode=<span class="string">&#x27;binary&#x27;</span>)</span><br></pre></td></tr></table></figure><hr><p><strong>Summary</strong></p><ul><li>Embedding层有一系列整数序列，可以使用更加复杂的词袋模型。Keras提供了one hot函数，对每个词创建了hash值。<code>Embedding(vocab_size, 8, input_length=max_length)</code> 该Embedding层有一个大小为50的vocabulary，和一个大小为4的input，输出词向量的维度是8。如果要把Embedding层放入Dense里，则需要把max_length个8维向量Flatten() 展平，再存入Dense层中。</li></ul><blockquote><p><code>Embedding(input_dim, output_dim, embeddings_initializer=&#39;uniform&#39;, embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)</code></p><ul><li><strong>input_dim</strong>: int &gt; 0。词汇表大小， 即，最大整数 index + 1。</li><li><strong>output_dim</strong>: int &gt;= 0。词向量的维度。</li><li><strong>embeddings_initializer</strong>: <code>embeddings</code> 矩阵的初始化方法 (详见 <a href="https://keras.io/zh/initializers/">initializers</a>)。</li><li><strong>embeddings_regularizer</strong>: <code>embeddings</code> matrix 的正则化方法 (详见 <a href="https://keras.io/zh/regularizers/">regularizer</a>)。</li><li><strong>embeddings_constraint</strong>: <code>embeddings</code> matrix 的约束函数 (详见 <a href="https://keras.io/zh/constraints/">constraints</a>)。</li><li><strong>mask_zero</strong>: 是否把 0 看作为一个应该被遮蔽的特殊的 “padding” 值。 这对于可变长的 <a href="https://keras.io/zh/layers/recurrent/">循环神经网络层</a> 十分有用。 如果设定为 <code>True</code>，那么接下来的所有层都必须支持 masking，否则就会抛出异常。 如果 mask_zero 为 <code>True</code>，作为结果，索引 0 就不能被用于词汇表中 （input_dim 应该与 vocabulary + 1 大小相同）。</li><li><strong>input_length</strong>: 输入序列的长度，当它是固定的时。 如果你需要连接 <code>Flatten</code> 和 <code>Dense</code> 层，则这个参数是必须的 （没有它，dense 层的输出尺寸就无法计算）。</li></ul></blockquote><p><code>tokenizer.texts_to_sequences()</code>：编码为整数向量序列</p><p><a href="https://blog.csdn.net/Gobsd/article/details/56485177">numpy中array和asarray的区别</a></p><hr><p>无监督预训练word vectors在NLP中效果很好</p><p>对于文本分类任务，使用CNN的预训练静态word vectors做得很好。</p><hr><p>A standard deep learning model for text classification and sentiment analysis uses a word embedding layer and one-dimensional convolutional neural network</p><p><strong>N-gram是直接统计不同的N个词之间组合在一起的概率</strong></p><p><strong>CNN是通过学习得到不同词组合的每个kernel的权重，加权和来达到某种分类或者其他目的</strong></p><p><a href="https://blog.csdn.net/yizhuanlu9607/article/details/78084266">‘r’ 和 ‘rt’、’w’ 和 ‘wt’的区别</a><br>r：Python  将会按照编码格式进行解析，read() 操作返回的是str</p><p>rb：也即 binary  mode，read()  操作返回的是bytes</p><p><a href="https://blog.csdn.net/xgh1951/article/details/80392411">python中dump 和dumps load和loads的区别</a></p><p> 除了文档说的话，没有什么可添加的。如果要将JSON转储到文件/套接字或其他文件中，则应使用<code>dump()</code>。如果只需要它作为字符串（用于打印，解析等），则使用<code>dumps()</code>（转储字符串）<a href="https://stackoverflow.com/questions/36059194/what-is-the-difference-between-json-dump-and-json-dumps-in-python">link</a></p><hr><p><a href="https://blog.csdn.net/sinat_34474705/article/details/74458605">numpy.array</a></p><ul><li>Python中提供了list容器，可以当作数组使用。但列表中的元素可以是任何对象，因此列表中保存的是对象的指针，这样一来，为了保存一个简单的列表[1,2,3]。就需要三个指针和三个整数对象。对于数值运算来说，这种结构显然不够高效。</li><li>Python虽然也提供了array模块，但其只支持一维数组，不支持多维数组，也没有各种运算函数。因而不适合数值运算。</li><li>NumPy的出现弥补了这些不足。</li></ul><hr><ul><li><p>什么是n-gram模型？<a href="https://zhuanlan.zhihu.com/p/32829048">link</a></p><p>文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。</p><blockquote><p> 该模型基于这样一种假设，第N个词的出现只与前面N-1个词相关，而与其它任何词都不相关，整句的概率就是各个词出现概率的乘积。这些概率可以通过直接从语料中统计N个词同时出现的次数得到。常用的是二元的Bi-Gram和三元的Tri-Gram。</p></blockquote><p>常见应用：搜索引擎（Google或者Baidu）、或者输入法的猜想或者提示</p></li></ul><p>texts_to_sequences</p><p>texts_to_matrix</p><hr><p>no formal specifications</p><p>An alternative approach to specifying the model of the language is to learn it from examples.</p><p>较简单的模型可能会看一个短词序列的上下文，而较大的模型可能会在句子或段落的层次上工作。最常见的是，语言模型在词的水平。</p><p>Language modeling is the art of determining the probability of a sequence of words</p><p>语言模型很重要。</p><p>Neural Language Model 比经典方法更好 when models are incorporated into larger models on challenging tasks like speech recognition and machine translation。key reason：the method’s ability to generalize.</p><p>通过以下方式解决n-gram数据稀疏性问题 将单词参数化为向量（单词嵌入），并将其作为输入到 一个神经网络。</p><p>n-gram？</p><p>distributed representation approach</p><ol><li>将词汇中的每个单词与分布式单词特征向量关联起来。</li><li>用特征向量来表示词序列的联合概率函数，其特征向量为这些词的顺序。</li><li>同时学习单词特征向量和概率函数。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt; Reading notes of《Deep Learning in NLP》✨&lt;/p&gt;
&lt;p&gt;It is almost about natural language processing functions explainations.&lt;/p&gt;</summary>
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Tensorflow" scheme="https://allmainashley.github.io/tags/Tensorflow/"/>
    
    <category term="NLP" scheme="https://allmainashley.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib、Pandas常用函数</title>
    <link href="https://allmainashley.github.io/2020/10/25/Notes/Machine%20Learning/Data%20Preprocessing%20Tips/"/>
    <id>https://allmainashley.github.io/2020/10/25/Notes/Machine%20Learning/Data%20Preprocessing%20Tips/</id>
    <published>2020-10-25T05:03:05.039Z</published>
    <updated>2020-10-25T05:03:05.039Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><ul><li><p><a href="https://blog.csdn.net/Jinlong_Xu/article/details/70175107">plot kind参数表</a></p><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">label</td><td align="left">用于图例的标签</td></tr><tr><td align="left">ax</td><td align="left">要在其上进行绘制的matplotlib subplot对象。如果没有设置，则使用当前matplotlib subplot</td></tr><tr><td align="left">style</td><td align="left">将要传给matplotlib的风格字符串(for example: ‘ko–’)</td></tr><tr><td align="left">alpha</td><td align="left">图表的填充不透明(0-1)</td></tr><tr><td align="left">kind</td><td align="left">可以是’line’, ‘bar’, ‘barh’, ‘kde’</td></tr><tr><td align="left">logy</td><td align="left">在Y轴上使用对数标尺</td></tr><tr><td align="left">use_index</td><td align="left">将对象的索引用作刻度标签</td></tr><tr><td align="left">rot</td><td align="left">旋转刻度标签(0-360)</td></tr><tr><td align="left">xticks</td><td align="left">用作X轴刻度的值</td></tr><tr><td align="left">yticks</td><td align="left">用作Y轴刻度的值</td></tr><tr><td align="left">xlim</td><td align="left">X轴的界限</td></tr><tr><td align="left">ylim</td><td align="left">Y轴的界限</td></tr><tr><td align="left">grid</td><td align="left">显示轴网格线</td></tr></tbody></table></li><li><p><a href="https://blog.csdn.net/changzoe/article/details/78845756">subplot2grid()</a></p></li><li><p><a href="https://blog.csdn.net/GAN_player/article/details/78543643">调整子图间距</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig.tight_layout()<span class="comment">#调整整体空白    </span></span><br><span class="line">plt.subplots_adjust(wspace =<span class="number">0</span>, hspace =<span class="number">0</span>)<span class="comment">#调整子图间距</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h1><ul><li><p>value_counts()：对Series里的所有值进行计数并且从大到小排序。</p></li><li><p><a href="https://blog.csdn.net/ARPOSPF/article/details/80407370">tsv文件和csv文件的区别</a></p><p><code>tsv</code>文件以tab制表符分隔，而<code>csv</code>文件以comma分隔。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Matplotlib&quot;&gt;&lt;a href=&quot;#Matplotlib&quot; class=&quot;headerlink&quot; title=&quot;Matplotlib&quot;&gt;&lt;/a&gt;Matplotlib&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.ne</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    
    <category term="Tips" scheme="https://allmainashley.github.io/tags/Tips/"/>
    
    <category term="Matplotlib" scheme="https://allmainashley.github.io/tags/Matplotlib/"/>
    
    <category term="Pandas" scheme="https://allmainashley.github.io/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>Genetic Algorithms</title>
    <link href="https://allmainashley.github.io/2020/10/22/Notes/Machine%20Learning/Genetic%20Algorithms/"/>
    <id>https://allmainashley.github.io/2020/10/22/Notes/Machine%20Learning/Genetic%20Algorithms/</id>
    <published>2020-10-22T12:06:20.610Z</published>
    <updated>2020-10-22T12:06:20.610Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>摘自《The nature of code》一书的<a href="https://natureofcode.com/book/chapter-9-the-evolution-of-code/">第九章</a></p></blockquote><h1 id="Traditional-Genetic-Algorithm"><a href="#Traditional-Genetic-Algorithm" class="headerlink" title="Traditional Genetic Algorithm"></a>Traditional Genetic Algorithm</h1><ul><li><font color=LighCoral><strong>Why Use Genetic Algorithms?</strong></font></li></ul><p><strong>brute force</strong> algorithm needs is not a reasonable strategy for arriving randomly at “to be or not to be that is the question”. Enter genetic algorithms, which will show that we can still start with random phrases and find the solution through simulated evolution.</p><ul><li><p><font color=LighCoral><strong>Darwinian Natural Selection</strong></font></p><ul><li><strong>Heredity.</strong> That means their traits are passed down to their children in the next generation of creatures.</li><li><strong>Variation.</strong> Without any variety in the population, the children will always be identical to the parents and to each other. New combinations of traits can never occur and nothing can evolve. (即 基因重组)</li><li><strong>Selection.</strong> There must be a mechanism by which some members of a population have the opportunity to be parents and pass down their genetic information and some do not.</li></ul></li></ul><h2 id="The-Genetic-Algorithm-Part-I-Creating-a-population"><a href="#The-Genetic-Algorithm-Part-I-Creating-a-population" class="headerlink" title="The Genetic Algorithm, Part I: Creating a population"></a><font color=Coral><strong>The Genetic Algorithm, Part I: Creating a population</strong></font></h2><ul><li><p><strong>genotype.</strong> This is what gets passed down from generation to generation</p></li><li><p><strong>phenotype.</strong> This is the expression of that data.</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021193246.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021191549.png" loading="lazy"></p><p>The nice thing about our monkey-typing example is that there is <strong>no difference between genotype and phenotype</strong>. The DNA data itself is a string of characters and the expression of that data is that very string.</p><p><code>Create a population of N elements, each with randomly generated DNA.</code></p><h2 id="The-Genetic-Algorithm-Part-II-Selection"><a href="#The-Genetic-Algorithm-Part-II-Selection" class="headerlink" title="The Genetic Algorithm, Part II: Selection"></a><font color=Coral><strong>The Genetic Algorithm, Part II: Selection</strong></font></h2><ul><li><p><strong>Evaluate fitness.</strong> The function will produce a numeric score to describe the fitness of a given member of the population</p></li><li><p><strong>Create a mating pool.</strong> “Which two members of the population scored the highest? You two will make all the children for the next generation.” This is probably one of the easier methods to program; however, it flies in the face of the principle of variation. If two members of the population (out of perhaps thousands) are the only ones available to reproduce, the next generation will have little variety and this may stunt the evolutionary process.  (Lose Variation 失去多样性)</p><p>A better solution for the mating pool is to use a <strong>probabilistic</strong> method, which we’ll call the “wheel of fortune” (also known as the “roulette wheel”).</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021195550.png" loading="lazy"></p><p><strong><font color=LightCoral>The first thing we’ll want to do is normalize all the scores.</font></strong></p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021200025.png" loading="lazy"></p><ul><li><p><strong><font color=Indianred>Why do we need genes with low possibilities ?</font></strong></p><p>Spin the wheel and you’ll notice that Element B has the highest chance of being selected, followed by A, then D, then E, and finally C. This probability-based selection according to fitness is an excellent approach. One, it guarantees that the highest-scoring elements will be most likely to reproduce. Two, it does not entirely eliminate any variation from the population. Unlike with the elitist method, even the lowest-scoring element (in this case C) has a chance to pass its information down to the next generation. It’s quite possible (and often the case) that even low-scoring elements have a tiny nugget of genetic code that is truly useful and should not entirely be eliminated from the population. For example, in the case of evolving “to be or not to be”, we might have the following elements.</p><p><strong>A: to be or not to go<br>B: to be or not to pi<br>C: xxxxxxxxxxxxxxxxbe</strong></p><p>As you can see, elements A and B are clearly the most fit and would have the highest score. But neither contains the correct characters for the end of the phrase. Element C, even though it would receive a very low score, happens to have the genetic data for the end of the phrase. And so while we would want A and B to be picked to generate the majority of the next generation, we would still want C to have a small chance to participate in the reproductive process.</p></li></ul><h2 id="The-Genetic-Algorithm-Part-III-Reproduction"><a href="#The-Genetic-Algorithm-Part-III-Reproduction" class="headerlink" title="The Genetic Algorithm, Part III: Reproduction"></a><strong><font color=Coral>The Genetic Algorithm, Part III: Reproduction</font></strong></h2><ul><li><p><strong>Crossover.</strong> Crossover involves creating a child out of the genetic code of two parents. In the case of the monkey-typing example, let’s assume we’ve picked two phrases from the mating pool (as outlined in our selection step).</p><ul><li><p>Perhaps the most obvious way (let’s call this the 50/50 method) would be to take the first two characters from A and the second two from B, leaving us with: (五五开)</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021201040.png" loading="lazy"></p></li><li><p>A variation of this technique is to pick a random midpoint. In other words, we don’t have to pick exactly half of the code from each parent.  This is preferable to the 50/50 approach, since we increase the variety of possibilities for the next generation.（随机中点，增加了多样性）</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021201339.png" loading="lazy"></p></li><li><p>Another possibility is to randomly select a parent for each character in the child string. You can think of this as flipping a coin four times: heads take from parent A, tails from parent B. Here we could end up with many different results such as: PLRY, FLRK, FLRY, FORY, etc.</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021201454.png" loading="lazy"></p><p><strong><font color=Indianred>This strategy will produce essentially the same results as the random midpoint method; however, if the order of the genetic information plays some role in expressing the phenotype, you may prefer one solution over the other.</font></strong></p></li></ul></li><li><p><strong>Mutation.</strong> Mutation is an optional step, as there are some cases in which it is unnecessary. However, it exists because of the Darwinian principle of variation. However, there can only be so much variety when seeding the first generation, and mutation allows us to introduce <strong>additional variety</strong> throughout the evolutionary process itself.</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201021201913.png" loading="lazy"></p><p>Mutation is described in terms of a <em>rate</em>. A given genetic algorithm might have a mutation rate of 5% or 1% or 0.1%, etc. Let’s assume we just finished with crossover and ended up with the child FORY. If we have a mutation rate of 1%, this means that for each character in the phrase generated from crossover, there is a 1% chance that it will mutate. What does it mean for a character to mutate? In this case, we define mutation as picking a new random character. A 1% probability is fairly low, and most of the time mutation will not occur at all in a four-character string (96% of the time to be more precise). However, when it does, the mutated character is replaced with a randomly generated one (see Figure 9.6).Certainly, a very high mutation rate (such as, say, 80%) would negate the evolutionary process itself. If the majority of a child’s genes are generated randomly, then we cannot guarantee that the more “fit” genes occur with greater frequency with each successive generation. (Mutation rate cannot be too high.) </p></li></ul><h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><pre><code>SETUP:Step 1: Initialize. Create a population of N elements, each with randomly generated DNA.LOOP:Step 2: Selection. Evaluate the fitness of each element of the population and build a mating pool.Step 3: Reproduction. Repeat N times:           a) Pick two parents with probability according to relative fitness.           b) Crossover—create a “child” by combining the DNA of these two parents.           c) Mutation—mutate the child’s DNA based on a given probability.           d) Add the new child to a new population.Step 4. Replace the old population with the new population and return to Step 2.</code></pre><p>​    </p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;摘自《The nature of code》一书的&lt;a href=&quot;https://natureofcode.com/book/chapter-9-the-evolution-of-code/&quot;&gt;第九章&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Algorithms" scheme="https://allmainashley.github.io/categories/Notes/Algorithms/"/>
    
    
    <category term="遗传算法" scheme="https://allmainashley.github.io/tags/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 学习笔记</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/MySQL/MYSQL%20tips/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/MySQL/MYSQL%20tips/</id>
    <published>2020-09-29T16:15:53.057Z</published>
    <updated>2020-09-29T16:15:53.057Z</updated>
    
    <content type="html"><![CDATA[<h1 id="被MYSQL日常虐到满地打滚"><a href="#被MYSQL日常虐到满地打滚" class="headerlink" title="被MYSQL日常虐到满地打滚"></a>被MYSQL日常虐到满地打滚</h1><ul><li><input checked="" disabled="" type="checkbox"> <a href="https://blog.csdn.net/exception_sir/article/details/82111014">how to uodate your MYSQL password</a>：but I stil dont’know why the first two method doesn’t work</li><li><input checked="" disabled="" type="checkbox"> <a href="https://www.cnblogs.com/microcat/p/6610963.html">how to start and close MYSQL</a></li><li><input checked="" disabled="" type="checkbox"> 每个语句要加分号</li><li><input disabled="" type="checkbox"> <a href="">I can’t find <strong><em>my.ini</em></strong> config file</a></li></ul><blockquote><p><code>(用管理员权限打开cmd) cd C:\Program Files\MySQL\MySQL Server 8.0\bin  mysqld --console　(不知道为啥net start mysql没用)</code></p><p>然后打开mysql命令行</p><p><code>ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;;(不知道为啥前两种没用)</code></p></blockquote><ul><li><input checked="" disabled="" type="checkbox"> my.ini</li></ul><blockquote><p>“C:\Program Files\MySQL\MySQL Server 8.0\bin\mysql.exe” “–defaults-file=C:\ProgramData\MySQL\MySQL Server 8.0\my.ini” “-uroot” “-p” “–default-character-set=utf8mb4”</p></blockquote><ul><li><input checked="" disabled="" type="checkbox"> 数据连接</li></ul><blockquote><p><code>private String dbUrl=&quot;jdbc:mysql://localhost:3306/system?useUnicode=true&amp;characterEncoding=utf8&quot;;   //数据库连接地址 //数据库名称：system 指定Unicode编码 字符集utf8 private String dbUser=&quot;root&quot;; private String dbPassword=&quot;root&quot;; private String jdbcName= &quot;com.mysql.cj.jdbc.Driver&quot;; //去找mysql-connect包 public Connection getCon()&#123;     try&#123;         Class.forName(jdbcName);    //找到jdbc包     &#125; catch (ClassNotFoundException e) &#123;         e.printStackTrace();     &#125;     Connection conn=null;     try&#123;         conn= DriverManager.getConnection(dbUrl,dbUser,dbPassword)     &#125; catch (SQLException throwables) &#123;         throwables.printStackTrace();     &#125;     return conn;    //返回连接的对象 &#125;</code></p></blockquote><ul><li><input checked="" disabled="" type="checkbox"> PreparedStatement</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;被MYSQL日常虐到满地打滚&quot;&gt;&lt;a href=&quot;#被MYSQL日常虐到满地打滚&quot; class=&quot;headerlink&quot; title=&quot;被MYSQL日常虐到满地打滚&quot;&gt;&lt;/a&gt;被MYSQL日常虐到满地打滚&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;input checked=&quot;</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="MySQL" scheme="https://allmainashley.github.io/categories/Notes/MySQL/"/>
    
    
  </entry>
  
  <entry>
    <title>Tensorflow Natural Language Processing</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Nature%20Language%20Processing/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Nature%20Language%20Processing/</id>
    <published>2020-09-29T16:15:53.027Z</published>
    <updated>2020-09-29T16:15:53.027Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><h1 id="Basic-Intro"><a href="#Basic-Intro" class="headerlink" title="Basic Intro"></a>Basic Intro</h1><h2 id="Using-APIs"><a href="#Using-APIs" class="headerlink" title="Using APIs"></a><font color=LightCoral>Using APIs</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"></span><br><span class="line">sentenses=[</span><br><span class="line">    <span class="string">&#x27;I love my dog&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;I love my cat&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;You love my dog!&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tokenizer=Tokenizer(num_words=<span class="number">100</span>)</span><br><span class="line">tokenizer.fit_on_texts(sentenses)   <span class="comment"># take in the data and encodes it</span></span><br><span class="line">word_index=tokenizer.word_index     <span class="comment"># key:word  index:the token of the word</span></span><br><span class="line">print(word_index)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;love&#39;: 1, &#39;my&#39;: 2, &#39;i&#39;: 3, &#39;dog&#39;: 4, &#39;cat&#39;: 5, &#39;you&#39;: 6&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>num_words</strong>：需要保留的最大词数，基于词频。只有最常出现的 <code>num_words</code> 词会被保留。（unique word） <a href="https://keras.io/zh/preprocessing/text/#tokenizer">详情</a></li><li>**tokenizer.fit_on_texts()**：分词器方法，实现分词</li><li><code>tokenizer</code>会为您自动除去标点符号(punctutation)，感叹号(exclamation)并未出现在<code>word_index</code>中。并且大写会自动改成小写。</li></ul><h2 id="Text-to-sequences"><a href="#Text-to-sequences" class="headerlink" title="Text to sequences"></a><font color=LightCoral>Text to sequences</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"></span><br><span class="line">sentenses=[</span><br><span class="line">    <span class="string">&#x27;I love my dog&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;I love my cat&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;You love my dog!&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Do you think my dog is amazing?&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tokenizer=Tokenizer(num_words=<span class="number">100</span>)</span><br><span class="line">tokenizer.fit_on_texts(sentenses)   <span class="comment"># take in the data and encodes it</span></span><br><span class="line">word_index=tokenizer.word_index     <span class="comment"># key:word  index:the token of the word</span></span><br><span class="line"></span><br><span class="line">sequences=tokenizer.texts_to_sequences(sentenses)</span><br><span class="line"></span><br><span class="line">print(word_index)</span><br><span class="line">print(sequences)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;my&#39;: 1, &#39;love&#39;: 2, &#39;dog&#39;: 3, &#39;i&#39;: 4, &#39;you&#39;: 5, &#39;cat&#39;: 6, &#39;do&#39;: 7, &#39;think&#39;: 8, &#39;is&#39;: 9, &#39;amazing&#39;: 10&#125;</span><br><span class="line">[[4, 2, 1, 3], [4, 2, 1, 6], [5, 2, 1, 3], [7, 5, 8, 1, 3, 9, 10]]</span><br></pre></td></tr></table></figure><hr><p>在上面那段代码的后面加上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">test_data=[</span><br><span class="line">    <span class="string">&#x27;I really love my dog&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;my dog loves my manatee&#x27;</span></span><br><span class="line">]</span><br><span class="line">test_seq=tokenizer.texts_to_sequences(test_data)</span><br><span class="line">print(test_seq)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[4, 2, 1, 3], [1, 3, 1]]</span><br></pre></td></tr></table></figure><p>结论：我们需要训练很多数据，否则可能就会像上面一样得出<code>my dog my</code>,或者遗失<code>really</code>的句子。</p><hr><p>如果我们用一个特殊标识来代表不认识的单词而不是忽略它，结果又会怎么样呢？</p><p>修改tokenizer：<code>tokenizer=Tokenizer(num_words=100,oov_token=&quot;&lt;OOV&gt;&quot;)</code></p><p>打印结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;&lt;OOV&gt;&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;my&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;love&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;dog&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;i&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;you&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;cat&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;do&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;think&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;is&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;amazing&#x27;</span>: <span class="number">11</span>&#125;</span><br><span class="line">[[<span class="number">5</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure><h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a><font color=LightCoral>Padding</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sequences=tokenizer.texts_to_sequences(sentenses)</span><br><span class="line"></span><br><span class="line">padded1=pad_sequences(sequences)</span><br><span class="line">padded2=pad_sequences(sequences,padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line">padded3=pad_sequences(sequences,padding=<span class="string">&#x27;post&#x27;</span>,maxlen=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">print(padded1)</span><br><span class="line">print(padded2)</span><br><span class="line">print(padded3)</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[[ 0  0  0  5  3  2  4]</span><br><span class="line"> [ 0  0  0  5  3  2  7]</span><br><span class="line"> [ 0  0  0  6  3  2  4]</span><br><span class="line"> [ 8  6  9  2  4 10 11]]</span><br><span class="line"> </span><br><span class="line">[[ 5  3  2  4  0  0  0]</span><br><span class="line"> [ 5  3  2  7  0  0  0]</span><br><span class="line"> [ 6  3  2  4  0  0  0]</span><br><span class="line"> [ 8  6  9  2  4 10 11]]</span><br><span class="line"> </span><br><span class="line">[[ 5  3  2  4  0]</span><br><span class="line"> [ 5  3  2  7  0]</span><br><span class="line"> [ 6  3  2  4  0]</span><br><span class="line"> [ 9  2  4 10 11]]</span><br></pre></td></tr></table></figure><ul><li><p><strong>pad_sequences</strong>：将多个序列截断或补齐为相同长度。<a href="https://keras.io/zh/preprocessing/sequence/">详情</a></p></li><li><p><strong>padding</strong>：字符串，’pre’ 或 ‘post’ ，在序列的前端补齐还是在后端补齐。</p></li><li><p><strong>maxlen</strong>：整数，所有序列的最大长度。</p></li></ul><h1 id="Sarcasm，Really"><a href="#Sarcasm，Really" class="headerlink" title="Sarcasm，Really"></a>Sarcasm，Really</h1><p>数据集：<a href="https://rishabhmisra.github.io/publications/">CCO public domain dataset</a>：sarcasm detection（嘲讽检测）</p><p>新闻标题数据集用于讽刺检测：<a href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home">News Headlines Dataset For Sarcasm Detection</a></p><p>Each record consists of three attributes:</p><ul><li><code>is_sarcastic</code>: 1 if the record is sarcastic otherwise 0</li><li><code>headline</code>: the headline of the news article</li><li><code>article_link</code>: link to the original news article. Useful for collecting supplementary data</li></ul><p>注意：Laurence为了方便把数据集稍作修改了</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200818154142.jpg" loading="lazy"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;sarcasm.json&#x27;</span>,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    datastore=json.load(f)      <span class="comment"># 返回一个包含三种数据的列表</span></span><br><span class="line"></span><br><span class="line">sentences = []</span><br><span class="line">labels = []</span><br><span class="line">urls = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> datastore:</span><br><span class="line">    sentences.append(item[<span class="string">&#x27;headline&#x27;</span>])</span><br><span class="line">    labels.append(item[<span class="string">&#x27;is_sarcastic&#x27;</span>])</span><br><span class="line">    urls.append(item[<span class="string">&#x27;article_link&#x27;</span>])</span><br><span class="line"></span><br><span class="line">tokenizer=Tokenizer(oov_token=<span class="string">&quot;&lt;OOV&gt;&quot;</span>)</span><br><span class="line">tokenizer.fit_on_texts(sentences)</span><br><span class="line">word_index=tokenizer.word_index</span><br><span class="line"></span><br><span class="line">sequences=tokenizer.texts_to_sequences(sentences)</span><br><span class="line">padded=pad_sequences(sequences,padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(padded[<span class="number">0</span>])</span><br><span class="line">print(padded.shape)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434</span><br><span class="line">     0     0     0     0     0     0     0     0     0     0     0     0</span><br><span class="line">     0     0     0     0     0     0     0     0     0     0     0     0</span><br><span class="line">     0     0     0     0]</span><br><span class="line">(26709, 40)</span><br></pre></td></tr></table></figure><p>共有<code>26709</code>个不重复的单词，最长的标题有<code>40</code>个单词。这些单词按照词频从高到低排序。</p><h1 id="IMDB-dataset"><a href="#IMDB-dataset" class="headerlink" title="IMDB dataset"></a>IMDB dataset</h1><h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a><font color=DarkOrange>Preprocessing</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(tf.__version__)   </span></span><br><span class="line">tf.enable_eager_execution()     </span><br><span class="line">imdb,info=tfds.load(<span class="string">&quot;imdb_reviews&quot;</span>,with_info=<span class="literal">True</span>,as_supervised=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_data, test_data = imdb[<span class="string">&#x27;train&#x27;</span>], imdb[<span class="string">&#x27;test&#x27;</span>]</span><br><span class="line"></span><br><span class="line">training_sentences = []</span><br><span class="line">training_labels = []</span><br><span class="line">testing_sentences = []</span><br><span class="line">testing_labels = []</span><br><span class="line"></span><br><span class="line"><span class="comment">#在Python2中应该用s.numpy()而不是str(s.tonumpy())</span></span><br><span class="line"><span class="keyword">for</span> s,l <span class="keyword">in</span> train_data:</span><br><span class="line">  training_sentences.append(str(s.tonumpy()).decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">  training_labels.append(l.numpy())</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> s,l <span class="keyword">in</span> test_data:</span><br><span class="line">  testing_sentences.append(s.numpy().decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">  testing_labels.append(l.numpy())</span><br><span class="line">  </span><br><span class="line">training_labels_final = np.array(training_labels)</span><br><span class="line">testing_labels_final = np.array(testing_labels)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p><code> pip install tensorflow-datasets</code>：下载tensorflow_datasets数据集</p></li><li><p><code> tf.enable_eager_execution()</code>：启用急切执行。如果tensorflow的版本号是1.x ，请加上这一行</p></li><li><p><code>imdb_reviews</code>：大电影评论数据集。这是用于二进制情感分类的数据集，其包含的数据比以前的基准数据集要多得多。我们提供了25,000套极地电影评论供培训，而25,000套则用于测试。也有其他未标记的数据可供使用。</p><ul><li><a href="https://www.tensorflow.org/datasets/api_docs/python/tfds/load"><code>tfds.load</code></a> 是构建并加载<code>tf.data.Dataset</code>最简单的方式。</li><li>使用 <code>with_info = True</code> 加载 <code>DatasetInfo</code></li><li><code>as_supervised</code>：bool ，如果为True ，则根据<code>builder.info.supervised_keys</code> ，返回的<code>tf.data.Dataset</code>将具有2元组结构<code>(input, label)</code> 。如果为False（默认值），则返回的<code>tf.data.Dataset</code>将具有包含所有功能的字典。</li></ul></li><li><p><code>s.numpy())</code>：将张量转化为<strong>numpy</strong>矩阵 <a href="https://blog.csdn.net/pengge0433/article/details/79459679">Pytorch中的variable, tensor与numpy相互转化的方法</a> ,对于tensorflow可以做类比。</p><p>​                 </p></li></ul><h2 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a><font color=DarkOrange>Tokenizer</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">vocab_size = <span class="number">10000</span></span><br><span class="line">embedding_dim = <span class="number">16</span></span><br><span class="line">max_length = <span class="number">120</span></span><br><span class="line">trunc_type=<span class="string">&#x27;post&#x27;</span></span><br><span class="line">oov_tok = <span class="string">&quot;&lt;OOV&gt;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)</span><br><span class="line">tokenizer.fit_on_texts(training_sentences)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">sequences = tokenizer.texts_to_sequences(training_sentences)</span><br><span class="line">padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)</span><br><span class="line"></span><br><span class="line">testing_sequences = tokenizer.texts_to_sequences(testing_sentences)</span><br><span class="line">testing_padded = pad_sequences(testing_sequences,maxlen=max_length)</span><br><span class="line"></span><br><span class="line">reverse_word_index=dict([(value,key) <span class="keyword">for</span> (key,value) <span class="keyword">in</span> word_index.items])</span><br><span class="line"><span class="comment"># 或者使用reverse_index_word</span></span><br></pre></td></tr></table></figure><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a><font color=DarkOrange>Model</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">6</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,optimizer=<span class="string">&#x27;adam&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>打印模型概述信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential_1&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">embedding_1 (Embedding)      (None, 120, 16)           160000    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)          (None, 1920)              0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 6)                 11526     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_3 (Dense)              (None, 1)                 7         </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 171,533</span><br><span class="line">Trainable params: 171,533</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure><h2 id="Model-Fit"><a href="#Model-Fit" class="headerlink" title="Model Fit"></a><font color=DarkOrange>Model Fit</font></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_epochs &#x3D; 10</span><br><span class="line">model.fit(padded, training_labels_final, epochs&#x3D;num_epochs, validation_data&#x3D;(testing_padded, testing_labels_final))</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 8ms&#x2F;step - loss: 0.4986 - accuracy: 0.7381 - val_loss: 0.3440 - val_accuracy: 0.8483</span><br><span class="line">Epoch 2&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 0.2420 - accuracy: 0.9058 - val_loss: 0.3643 - val_accuracy: 0.8416</span><br><span class="line">Epoch 3&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 0.0935 - accuracy: 0.9770 - val_loss: 0.4440 - val_accuracy: 0.8294</span><br><span class="line">Epoch 4&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 8ms&#x2F;step - loss: 0.0222 - accuracy: 0.9972 - val_loss: 0.5412 - val_accuracy: 0.8236</span><br><span class="line">Epoch 5&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.5868 - val_accuracy: 0.8277</span><br><span class="line">Epoch 6&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 9ms&#x2F;step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8285</span><br><span class="line">Epoch 7&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.6804 - val_accuracy: 0.8303</span><br><span class="line">Epoch 8&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 4.7313e-04 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8304</span><br><span class="line">Epoch 9&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 6s 8ms&#x2F;step - loss: 2.6091e-04 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 0.8297</span><br><span class="line">Epoch 10&#x2F;10</span><br><span class="line">782&#x2F;782 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 8ms&#x2F;step - loss: 1.5703e-04 - accuracy: 1.0000 - val_loss: 0.7937 - val_accuracy: 0.8306</span><br></pre></td></tr></table></figure><h2 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">e = model.layers[<span class="number">0</span>]</span><br><span class="line">weights = e.get_weights()[<span class="number">0</span>]</span><br><span class="line">print(weights.shape) <span class="comment"># shape: (vocab_size, embedding_dim)</span></span><br></pre></td></tr></table></figure><h2 id="Visualizeing"><a href="#Visualizeing" class="headerlink" title="Visualizeing"></a>Visualizeing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">out_v = io.open(<span class="string">&#x27;vecs.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">out_m = io.open(<span class="string">&#x27;meta.tsv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> word_num <span class="keyword">in</span> range(<span class="number">1</span>, vocab_size):</span><br><span class="line">  word = reverse_word_index[word_num]</span><br><span class="line">  embeddings = weights[word_num]</span><br><span class="line">  out_m.write(word + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">  out_v.write(<span class="string">&#x27;\t&#x27;</span>.join([str(x) <span class="keyword">for</span> x <span class="keyword">in</span> embeddings]) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">out_v.close()</span><br><span class="line">out_m.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  files.download(<span class="string">&#x27;vecs.tsv&#x27;</span>)</span><br></pre></td></tr></table></figure><p><a href="http://projector.tensorflow.org/">传送门</a>：点击<code>load</code>，第一个上传<code>vecs.tsv</code>，第二个上传<code>meta.tsv</code>。点击<code>Sphereize data</code>能使其球形化。</p><h1 id="RNN-amp-GRU-amp-LSTM"><a href="#RNN-amp-GRU-amp-LSTM" class="headerlink" title="RNN &amp; GRU &amp; LSTM"></a>RNN &amp; GRU &amp; LSTM</h1><center>        <img    src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201202211216.png">    <br>    <div style="color:gray;padding: 10px;">RNN</div> </center><center>        <img    src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20201202212117.png">    <br>    <div style="color:gray;padding: 10px;">LSTM</div> </center>]]></content>
    
    
      
      
    <summary type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;h1 id=&quot;Basic-Intro&quot;&gt;&lt;a href=&quot;#Basic-Intro&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Tensorflow" scheme="https://allmainashley.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow 卷积网络</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Convolutional%20Neural%20Networks/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Convolutional%20Neural%20Networks/</id>
    <published>2020-09-29T16:15:53.018Z</published>
    <updated>2020-09-29T16:15:53.018Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="https://keras.io/zh">kears中文文档</a></p><p><font color=DarkOrange><code>* 代表optional，在搭建判断是猫还是狗的卷积神经网络中,不是必备步骤。</code></font></p><h1 id="Dogs-vs-Cats"><a href="#Dogs-vs-Cats" class="headerlink" title="Dogs vs. Cats"></a>Dogs vs. Cats</h1><p><a href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip">数据集下载地址</a></p><h2 id="Pretreatment"><a href="#Pretreatment" class="headerlink" title="Pretreatment"></a>Pretreatment</h2><h3 id="Unzip-datas"><a href="#Unzip-datas" class="headerlink" title="Unzip datas"></a><font color=Salmon>Unzip datas</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">local_zip = <span class="string">&#x27;/tmp/cats_and_dogs_filtered.zip&#x27;</span></span><br><span class="line">zip_ref = zipfile.ZipFile(local_zip, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">zip_ref.extractall(<span class="string">&#x27;/tmp&#x27;</span>)</span><br><span class="line">zip_ref.close()</span><br></pre></td></tr></table></figure><h3 id="Define-Directories"><a href="#Define-Directories" class="headerlink" title="Define Directories"></a><font color=Salmon>Define Directories</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">base_dir = <span class="string">&#x27;/tmp/cats_and_dogs_filtered&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接路径</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">&#x27;train&#x27;</span>) </span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our training cat/dog pictures</span></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">&#x27;cats&#x27;</span>)</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">&#x27;dogs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our validation cat/dog pictures</span></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">&#x27;cats&#x27;</span>)</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">&#x27;dogs&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="Load-into-Python-lists"><a href="#Load-into-Python-lists" class="headerlink" title="* Load into Python lists"></a><font color=Salmon>* Load into Python lists</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_cat_fnames = os.listdir( train_cats_dir ) <span class="comment">#os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表</span></span><br><span class="line">train_dog_fnames = os.listdir( train_dogs_dir )</span><br><span class="line"></span><br><span class="line">print(train_cat_fnames[:<span class="number">10</span>])</span><br><span class="line">print(train_dog_fnames[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">打印结果：</span></span><br><span class="line"><span class="string">[&#x27;cat.277.jpg&#x27;, &#x27;cat.424.jpg&#x27;, &#x27;cat.809.jpg&#x27;, &#x27;cat.148.jpg&#x27;, &#x27;cat.114.jpg&#x27;, &#x27;cat.264.jpg&#x27;, &#x27;cat.392.jpg&#x27;, &#x27;cat.355.jpg&#x27;, &#x27;cat.671.jpg&#x27;, &#x27;cat.562.jpg&#x27;]</span></span><br><span class="line"><span class="string">[&#x27;dog.928.jpg&#x27;, &#x27;dog.88.jpg&#x27;, &#x27;dog.470.jpg&#x27;, &#x27;dog.782.jpg&#x27;, &#x27;dog.346.jpg&#x27;, &#x27;dog.383.jpg&#x27;, &#x27;dog.728.jpg&#x27;, &#x27;dog.979.jpg&#x27;, &#x27;dog.389.jpg&#x27;, &#x27;dog.71.jpg&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Print-picture-numbers"><a href="#Print-picture-numbers" class="headerlink" title="* Print picture numbers"></a><font color=Salmon>* Print picture numbers</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;total training cat images :&#x27;</span>, len(os.listdir(      train_cats_dir ) ))</span><br><span class="line">print(<span class="string">&#x27;total training dog images :&#x27;</span>, len(os.listdir(      train_dogs_dir ) ))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;total validation cat images :&#x27;</span>, len(os.listdir( validation_cats_dir ) ))</span><br><span class="line">print(<span class="string">&#x27;total validation dog images :&#x27;</span>, len(os.listdir( validation_dogs_dir ) ))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">打印结果：</span></span><br><span class="line"><span class="string">total training cat images : 1000</span></span><br><span class="line"><span class="string">total training dog images : 1000</span></span><br><span class="line"><span class="string">total validation cat images : 500</span></span><br><span class="line"><span class="string">total validation dog images : 500</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="* Visualization"></a><font color=Salmon>* Visualization</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters for our graph; we&#x27;ll output images in a 4x4 configuration</span></span><br><span class="line">nrows = <span class="number">4</span></span><br><span class="line">ncols = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">pic_index = <span class="number">0</span> <span class="comment"># Index for iterating over images</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up matplotlib fig, and size it to fit 4x4 pics</span></span><br><span class="line">fig = plt.gcf() <span class="comment"># Get Current Figure</span></span><br><span class="line">fig.set_size_inches(ncols*<span class="number">4</span>, nrows*<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">pic_index+=<span class="number">8</span></span><br><span class="line"></span><br><span class="line">next_cat_pix = [os.path.join(train_cats_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_cat_fnames[ pic_index<span class="number">-8</span>:pic_index] </span><br><span class="line">               ]</span><br><span class="line"></span><br><span class="line">next_dog_pix = [os.path.join(train_dogs_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_dog_fnames[ pic_index<span class="number">-8</span>:pic_index]</span><br><span class="line">               ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, img_path <span class="keyword">in</span> enumerate(next_cat_pix+next_dog_pix):</span><br><span class="line">  <span class="comment"># Set up subplot; subplot indices start at 1</span></span><br><span class="line">  sp = plt.subplot(nrows, ncols, i + <span class="number">1</span>)</span><br><span class="line">  sp.axis(<span class="string">&#x27;Off&#x27;</span>) <span class="comment"># Don&#x27;t show axes (or gridlines)</span></span><br><span class="line"></span><br><span class="line">  img = mpimg.imread(img_path)</span><br><span class="line">  plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="Build-model"><a href="#Build-model" class="headerlink" title="Build model"></a><font color=Salmon>Build model</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># Note the input shape is the desired size of the image 150x150 with 3 bytes color</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>), </span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># Flatten the results to feed into a DNN</span></span><br><span class="line">    tf.keras.layers.Flatten(), </span><br><span class="line">    <span class="comment"># 512 neuron hidden layer</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">    <span class="comment"># Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (&#x27;cats&#x27;) and 1 for the other (&#x27;dogs&#x27;)</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)  </span><br><span class="line">]</span><br><span class="line">    </span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>打印模型概述信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential_2&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">conv2d_6 (Conv2D)            (None, 148, 148, 16)      448       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_6 (MaxPooling2 (None, 74, 74, 16)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_7 (Conv2D)            (None, 72, 72, 32)        4640      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_7 (MaxPooling2 (None, 36, 36, 32)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_8 (Conv2D)            (None, 34, 34, 64)        18496     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_8 (MaxPooling2 (None, 17, 17, 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_2 (Flatten)          (None, 18496)             0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_4 (Dense)              (None, 512)               9470464   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_5 (Dense)              (None, 1)                 513       </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 9,494,561</span><br><span class="line">Trainable params: 9,494,561</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><h3 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a><font color=Salmon>Compile</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><h3 id="Create-image-generator"><a href="#Create-image-generator" class="headerlink" title="Create image generator"></a><font color=Salmon>Create image generator</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># All images will be rescaled by 1./255.</span></span><br><span class="line">train_datagen = ImageDataGenerator( rescale = <span class="number">1.0</span>/<span class="number">255.</span> )</span><br><span class="line">test_datagen  = ImageDataGenerator( rescale = <span class="number">1.0</span>/<span class="number">255.</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line"><span class="comment"># Flow training images in batches of 20 using train_datagen generator</span></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(train_dir,</span><br><span class="line">                                                    batch_size=<span class="number">20</span>,</span><br><span class="line">                                                    class_mode=<span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">                                                    target_size=(<span class="number">150</span>, <span class="number">150</span>))     </span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line"><span class="comment"># Flow validation images in batches of 20 using test_datagen generator</span></span><br><span class="line"><span class="comment"># --------------------</span></span><br><span class="line">validation_generator =  test_datagen.flow_from_directory(validation_dir,</span><br><span class="line">                                                         batch_size=<span class="number">20</span>,</span><br><span class="line">                                                         class_mode  = <span class="string">&#x27;binary&#x27;</span>,</span><br><span class="line">                                                         target_size = (<span class="number">150</span>, <span class="number">150</span>))</span><br></pre></td></tr></table></figure><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(train_generator,</span><br><span class="line">                    validation_data=validation_generator,</span><br><span class="line">                    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">                    epochs=<span class="number">15</span>,</span><br><span class="line">                    validation_steps=<span class="number">50</span>,</span><br><span class="line">                    verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0300 - accuracy: 0.9925 - val_loss: 1.9040 - val_accuracy: 0.7120</span><br><span class="line">Epoch 2&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0350 - accuracy: 0.9890 - val_loss: 1.7071 - val_accuracy: 0.7210</span><br><span class="line">Epoch 3&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0188 - accuracy: 0.9925 - val_loss: 2.0725 - val_accuracy: 0.6950</span><br><span class="line">Epoch 4&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0291 - accuracy: 0.9915 - val_loss: 2.3252 - val_accuracy: 0.7080</span><br><span class="line">Epoch 5&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0303 - accuracy: 0.9940 - val_loss: 2.1299 - val_accuracy: 0.7340</span><br><span class="line">Epoch 6&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0193 - accuracy: 0.9930 - val_loss: 2.0416 - val_accuracy: 0.7400</span><br><span class="line">Epoch 7&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0197 - accuracy: 0.9925 - val_loss: 2.1636 - val_accuracy: 0.7300</span><br><span class="line">Epoch 8&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0251 - accuracy: 0.9925 - val_loss: 2.4540 - val_accuracy: 0.7360</span><br><span class="line">Epoch 9&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0180 - accuracy: 0.9955 - val_loss: 2.7262 - val_accuracy: 0.7260</span><br><span class="line">Epoch 10&#x2F;15</span><br><span class="line">100&#x2F;100 - 60s - loss: 0.0163 - accuracy: 0.9960 - val_loss: 2.8085 - val_accuracy: 0.7040</span><br><span class="line">Epoch 11&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0400 - accuracy: 0.9905 - val_loss: 2.6529 - val_accuracy: 0.7270</span><br><span class="line">Epoch 12&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0193 - accuracy: 0.9945 - val_loss: 2.8958 - val_accuracy: 0.7220</span><br><span class="line">Epoch 13&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0204 - accuracy: 0.9950 - val_loss: 3.2313 - val_accuracy: 0.7250</span><br><span class="line">Epoch 14&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 9.9441e-05 - accuracy: 1.0000 - val_loss: 3.5450 - val_accuracy: 0.7270</span><br><span class="line">Epoch 15&#x2F;15</span><br><span class="line">100&#x2F;100 - 55s - loss: 0.0781 - accuracy: 0.9905 - val_loss: 3.2831 - val_accuracy: 0.6940</span><br></pre></td></tr></table></figure><h2 id="Running-the-model"><a href="#Running-the-model" class="headerlink" title="Running the model"></a>Running the model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line">uploaded=files.upload()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> uploaded.keys():</span><br><span class="line"> </span><br><span class="line">  <span class="comment"># predicting images</span></span><br><span class="line">  path=<span class="string">&#x27;/content/&#x27;</span> + fn</span><br><span class="line">  img=image.load_img(path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">  </span><br><span class="line">  x=image.img_to_array(img)</span><br><span class="line">  x=np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">  images = np.vstack([x])</span><br><span class="line">  </span><br><span class="line">  classes = model.predict(images, batch_size=<span class="number">10</span>)</span><br><span class="line">  </span><br><span class="line">  print(classes[<span class="number">0</span>])</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> classes[<span class="number">0</span>]&gt;<span class="number">0</span>:</span><br><span class="line">    print(fn + <span class="string">&quot; is a dog&quot;</span>)</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    print(fn + <span class="string">&quot; is a cat&quot;</span>)</span><br></pre></td></tr></table></figure><p>通过裁剪图片，可以改变分类的结果。</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200808160234.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200808160235.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200808160236.png" loading="lazy"></p><h2 id="Evaluating-Accuracy-and-Loss-for-the-Model"><a href="#Evaluating-Accuracy-and-Loss-for-the-Model" class="headerlink" title="Evaluating Accuracy and Loss for the Model"></a>Evaluating Accuracy and Loss for the Model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Retrieve a list of list results on training and test data</span></span><br><span class="line"><span class="comment"># sets for each training epoch</span></span><br><span class="line"><span class="comment">#-----------------------------------------------------------</span></span><br><span class="line">acc      = history.history[     <span class="string">&#x27;accuracy&#x27;</span> ]</span><br><span class="line">val_acc  = history.history[ <span class="string">&#x27;val_accuracy&#x27;</span> ]</span><br><span class="line">loss     = history.history[    <span class="string">&#x27;loss&#x27;</span> ]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span> ]</span><br><span class="line"></span><br><span class="line">epochs   = range(len(acc)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation accuracy per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot  ( epochs,     acc )</span><br><span class="line">plt.plot  ( epochs, val_acc )</span><br><span class="line">plt.title (<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation loss per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot  ( epochs,     loss )</span><br><span class="line">plt.plot  ( epochs, val_loss )</span><br><span class="line">plt.title (<span class="string">&#x27;Training and validation loss&#x27;</span>   )</span><br></pre></td></tr></table></figure><p><font color=SteelBlue>Training</font>  and <font color=DarkOrange>Validation</font></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200808155700.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200809150008.png" loading="lazy"></p><h2 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h2><p><font color=Green>**How to build a Dogs vs. Cats classifier? **</font></p><ul><li><input checked="" disabled="" type="checkbox"> Unzip datas. 解压数据</li><li><input checked="" disabled="" type="checkbox"> Define Directories. 指定文件夹 </li><li><input checked="" disabled="" type="checkbox"> Build the model. 搭建模型 （model.Sequential)</li><li><input checked="" disabled="" type="checkbox"> Compile the model. 编译模型</li><li><input checked="" disabled="" type="checkbox"> Create image generator. 创建图像生成器（标准化数据、flow_from_directory读文件）</li><li><input checked="" disabled="" type="checkbox"> Train the model. 训练模型（注意：是model.fit_generator)</li><li><input checked="" disabled="" type="checkbox"> Running the model. （测试新图片）</li><li><input checked="" disabled="" type="checkbox"> Evaluating Accuracy and Loss for the Model. （评估准确性和损失）</li></ul><h1 id="Augmentation"><a href="#Augmentation" class="headerlink" title="Augmentation"></a>Augmentation</h1><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200809150119.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200809150120.png" loading="lazy"></p><p>如图：在20个epoches后，训练集的准确性接近1，而验证集的准确性并没有提升，说明此时已经出现了过拟合。</p><p><a href="https://keras.io/zh/preprocessing/image/">ImageDataGenerator 详情</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=(<span class="number">1.</span>/<span class="number">255</span>),</span><br><span class="line">    rotation_range=<span class="number">40</span>,  </span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><blockquote><ul><li><p><strong>rescale</strong>: 重缩放因子。默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）。</p></li><li><p><strong>rotation_range</strong>: 整数。随机旋转的度数范围。</p></li><li><p><strong>width_shift_range</strong>: 浮点数、一维数组或整数</p><ul><li>float: 如果 &lt;1，则是除以总宽度的值，或者如果 &gt;=1，则为像素值。</li><li>1-D 数组: 数组中的随机元素。</li><li>int: 来自间隔 <code>(-width_shift_range, +width_shift_range)</code> 之间的整数个像素。</li><li><code>width_shift_range=2</code> 时，可能值是整数 <code>[-1, 0, +1]</code>，与 <code>width_shift_range=[-1, 0, +1]</code> 相同；而 <code>width_shift_range=1.0</code> 时，可能值是 <code>[-1.0, +1.0)</code> 之间的浮点数。</li></ul></li><li><p><strong>height_shift_range</strong>: 浮点数、一维数组或整数</p><ul><li>float: 如果 &lt;1，则是除以总宽度的值，或者如果 &gt;=1，则为像素值。</li><li>1-D array-like: 数组中的随机元素。</li><li>int: 来自间隔 <code>(-height_shift_range, +height_shift_range)</code> 之间的整数个像素。</li><li><code>height_shift_range=2</code> 时，可能值是整数 <code>[-1, 0, +1]</code>，与 <code>height_shift_range=[-1, 0, +1]</code> 相同；而 <code>height_shift_range=1.0</code> 时，可能值是 <code>[-1.0, +1.0)</code> 之间的浮点数。</li></ul></li><li><p><strong>shear_range</strong>: 浮点数。剪切强度（以弧度逆时针方向剪切角度）。</p></li><li><p><strong>zoom_range</strong>: 浮点数 或 <code>[lower, upper]</code>。随机缩放范围。如果是浮点数，<code>[lower, upper] = [1-zoom_range, 1+zoom_range]</code>。</p></li><li><p><strong>horizontal_flip</strong>: 布尔值。随机水平翻转。 </p></li><li><p><strong>fill_mode</strong>: {“constant”, “nearest”, “reflect” or “wrap”} 之一。默认为 ‘nearest’。输入边界以外的点根据给定的模式填充：</p><ul><li><p>‘constant’: kkkkkkkk|abcd|kkkkkkkk (cval=k)</p></li><li><p>‘nearest’: aaaaaaaa|abcd|dddddddd</p></li><li><p>‘reflect’: abcddcba|abcd|dcbaabcd</p></li><li><p>‘wrap’: abcdabcd|abcd|abcdabcd</p></li></ul></li></ul></blockquote><p>修改了ImageDataGenerator后：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200810114345.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200810114437.png" loading="lazy"></p><p>可以看出，如果只对训练集的ImageDataGenerator做出修改，会使得验证集波动过大，所以要对训练集和验证集的ImageDataGenerator做出同样的修改。</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200809154401.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200809154408.png" loading="lazy"></p><h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><blockquote><p>准备资料：</p><p><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a></p><p><a href="http://image-net.org/">Image datasets</a></p></blockquote><h2 id="InceptionV3"><a href="#InceptionV3" class="headerlink" title="InceptionV3"></a><font color=DarkOrange>InceptionV3</font></h2><p><a href="https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5">下载地址</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">local_weights_file = <span class="string">&#x27;inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 预训练模型</span></span><br><span class="line">pre_trained_model = InceptionV3(input_shape = (<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>), </span><br><span class="line">                                include_top = <span class="literal">False</span>, </span><br><span class="line">                                weights = <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 读取网络权值</span></span><br><span class="line">pre_trained_model.load_weights(local_weights_file)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 冻结层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> pre_trained_model.layers:</span><br><span class="line">  layer.trainable = <span class="literal">False</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># pre_trained_model.summary()# 因为概述信息太长，故将这一行注释掉</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 看一下最后一层形状</span></span><br><span class="line">last_layer = pre_trained_model.get_layer(<span class="string">&#x27;mixed7&#x27;</span>)<span class="comment"># 获得InceptionV3网络mixed7卷积层</span></span><br><span class="line">print(<span class="string">&#x27;last layer output shape: &#x27;</span>, last_layer.output_shape)</span><br><span class="line">last_output = last_layer.output</span><br></pre></td></tr></table></figure><p>打印信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">last layer output shape:  (None, 7, 7, 768)</span><br></pre></td></tr></table></figure><p>补充：</p><ul><li><p><code>include_top</code>：布尔值，是否将最上层的完全连接层作为网络的最后一层。默认为<code>True</code>。</p><p><code>weights</code>：（<code>None</code>随机初始化）， <code>imagenet</code>（在ImageNet上进行预训练）或要加载的weights文件的路径之一。默认为<code>imagenet</code>。</p></li><li><p><code>keras.models.load_model()</code>:  读取网络、权重<br><code>keras.models.load_weights()</code> : 仅读取权重</p></li><li><p>设置<code>layer.trainable</code>为<code>False</code>将所有图层的权重从可训练变为不可训练。这称为“冻结”层：<font color=Rainbow>冻结层的状态在训练期间不会更新</font>（使用训练<code>fit()</code>或使用依赖于<code>trainable_weights</code>应用渐变更新的任何自定义循环进行训练时）。<a href="https://keras.io/guides/transfer_learning/">详情</a></p></li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a><font color=DarkOrange>Model</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flatten the output layer to 1 dimension</span></span><br><span class="line">x = layers.Flatten()(last_output)</span><br><span class="line"><span class="comment"># Add a fully connected layer with 1,024 hidden units and ReLU activation</span></span><br><span class="line">x = layers.Dense(<span class="number">1024</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)                </span><br><span class="line"><span class="comment"># Add a final sigmoid layer for classification</span></span><br><span class="line">x = layers.Dense  (<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)(x)           </span><br><span class="line"></span><br><span class="line">model = Model( pre_trained_model.input, x) </span><br><span class="line"></span><br><span class="line">model.compile(optimizer = RMSprop(lr=<span class="number">0.0001</span>), </span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><h2 id="ImageDataGenerator"><a href="#ImageDataGenerator" class="headerlink" title="ImageDataGenerator"></a><font color=DarkOrange>ImageDataGenerator</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">local_zip = <span class="string">&#x27;cats_and_dogs_filtered.zip&#x27;</span></span><br><span class="line"></span><br><span class="line">zip_ref = zipfile.ZipFile(local_zip, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"></span><br><span class="line">zip_ref.extractall()</span><br><span class="line">zip_ref.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define our example directories and files</span></span><br><span class="line">base_dir = <span class="string">&#x27;cats_and_dogs_filtered&#x27;</span></span><br><span class="line"></span><br><span class="line">train_dir = os.path.join( base_dir, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">validation_dir = os.path.join( base_dir, <span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">&#x27;cats&#x27;</span>) <span class="comment"># Directory with our training cat pictures</span></span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">&#x27;dogs&#x27;</span>) <span class="comment"># Directory with our training dog pictures</span></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">&#x27;cats&#x27;</span>) <span class="comment"># Directory with our validation cat pictures</span></span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">&#x27;dogs&#x27;</span>)<span class="comment"># Directory with our validation dog pictures</span></span><br><span class="line"></span><br><span class="line">train_cat_fnames = os.listdir(train_cats_dir)</span><br><span class="line">train_dog_fnames = os.listdir(train_dogs_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add our data-augmentation parameters to ImageDataGenerator</span></span><br><span class="line">train_datagen = ImageDataGenerator(rescale = <span class="number">1.</span>/<span class="number">255.</span>,</span><br><span class="line">                                   rotation_range = <span class="number">40</span>,</span><br><span class="line">                                   width_shift_range = <span class="number">0.2</span>,</span><br><span class="line">                                   height_shift_range = <span class="number">0.2</span>,</span><br><span class="line">                                   shear_range = <span class="number">0.2</span>,</span><br><span class="line">                                   zoom_range = <span class="number">0.2</span>,</span><br><span class="line">                                   horizontal_flip = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that the validation data should not be augmented!</span></span><br><span class="line">test_datagen = ImageDataGenerator( rescale = <span class="number">1.0</span>/<span class="number">255.</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow training images in batches of 20 using train_datagen generator</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(train_dir,</span><br><span class="line">                                                    batch_size = <span class="number">20</span>,</span><br><span class="line">                                                    class_mode = <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line">                                                    target_size = (<span class="number">150</span>, <span class="number">150</span>))     </span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow validation images in batches of 20 using test_datagen generator</span></span><br><span class="line">validation_generator =  test_datagen.flow_from_directory( validation_dir,</span><br><span class="line">                                                          batch_size  = <span class="number">20</span>,</span><br><span class="line">                                                          class_mode  = <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line">                                                          target_size = (<span class="number">150</span>, <span class="number">150</span>))</span><br></pre></td></tr></table></figure><h2 id="Model-Fit"><a href="#Model-Fit" class="headerlink" title="Model Fit"></a><font color=DarkOrange>Model Fit</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">            train_generator,</span><br><span class="line">            validation_data = validation_generator,</span><br><span class="line">            steps_per_epoch = <span class="number">100</span>,</span><br><span class="line">            epochs = <span class="number">20</span>,</span><br><span class="line">            validation_steps = <span class="number">50</span>,</span><br><span class="line">            verbose = <span class="number">2</span>)</span><br></pre></td></tr></table></figure><ul><li>Keras <code>Model</code> 上的 <code>fit()</code> 方法返回一个 <code>History</code> 对象。<code>History.history</code> 属性是一个记录了连续迭代的训练/验证（如果存在）损失值和评估值的字典。</li><li><code>plt.legend(loc=&#39;位置&#39;) </code>: 0表示<code>&#39;best&#39;</code>。 <a href="https://mofanpy.com/tutorials/data-manipulation/plt/legend/">详情</a></li><li><code>plt.figure</code>: 定义一个图像窗口。 <a href="https://mofanpy.com/tutorials/data-manipulation/plt/figure/">详情</a></li></ul><p>可以看出验证集的准确率飘忽不定，这是因为模型过拟合了。接下来我们使用<strong>Dropout</strong> (随机失活) 来减少过拟合</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200814091339.png" loading="lazy"></p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a><font color=DarkOrange>Dropout</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flatten the output layer to 1 dimension</span></span><br><span class="line">x = layers.Flatten()(last_output)</span><br><span class="line"><span class="comment"># Add a fully connected layer with 1,024 hidden units and ReLU activation</span></span><br><span class="line">x = layers.Dense(<span class="number">1024</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># Add a dropout rate of 0.2</span></span><br><span class="line">x = layers.Dropout(<span class="number">0.2</span>)(x)                  </span><br><span class="line"><span class="comment"># Add a final sigmoid layer for classification</span></span><br><span class="line">x = layers.Dense  (<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)(x)           </span><br><span class="line"></span><br><span class="line">model = Model( pre_trained_model.input, x) </span><br><span class="line"></span><br><span class="line">model.compile(optimizer = RMSprop(lr=<span class="number">0.0001</span>), </span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, </span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200814091340.png" loading="lazy"></p><h1 id="Multiclass-Classification"><a href="#Multiclass-Classification" class="headerlink" title="Multiclass Classification"></a>Multiclass Classification</h1><p><a href="http://www.laurencemoroney.com/rock-paper-scissors-dataset/">Rock Paper Scissors</a></p><h2 id="ImageDataGenerator-1"><a href="#ImageDataGenerator-1" class="headerlink" title="ImageDataGenerator"></a><font color=MediumAquaMarine>ImageDataGenerator</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">train_datagen= ImageDataGenerator(</span><br><span class="line">      rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">  rotation_range=<span class="number">40</span>,</span><br><span class="line">      width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      shear_range=<span class="number">0.2</span>,</span><br><span class="line">      zoom_range=<span class="number">0.2</span>,</span><br><span class="line">      horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">      fill_mode=<span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">)</span><br><span class="line">test_datagen=ImageDataGenerator(</span><br><span class="line">  rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">  rotation_range=<span class="number">40</span>,</span><br><span class="line">      width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      shear_range=<span class="number">0.2</span>,</span><br><span class="line">      zoom_range=<span class="number">0.2</span>,</span><br><span class="line">      horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">      fill_mode=<span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_generator=train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">300</span>,<span class="number">300</span>),</span><br><span class="line">    batch_size=<span class="number">126</span>,</span><br><span class="line">    class_mode=<span class="string">&#x27;categorical&#x27;</span>    <span class="comment"># 这不再是二分类所以，class_mode要更改为categorical</span></span><br><span class="line">)</span><br><span class="line">validation_generator=test_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">300</span>, <span class="number">300</span>),</span><br><span class="line">    batch_size=<span class="number">126</span>,</span><br><span class="line">    class_mode=<span class="string">&#x27;categorical&#x27;</span>  <span class="comment"># 这不再是二分类所以，class_mode要更改为categorical</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="Model-1"><a href="#Model-1" class="headerlink" title="Model"></a><font color=MediumAquaMarine>Model</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model=tf.keras.Sequential(</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">300</span>,<span class="number">300</span>,<span class="number">3</span>)),</span><br><span class="line">    tf.keras.layers.MaxPool2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>,activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="Compile-1"><a href="#Compile-1" class="headerlink" title="Compile"></a><font color=MediumAquaMarine>Compile</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,<span class="comment">#这里也要修改为 categorical_crossentropy</span></span><br><span class="line">              optimizer=RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure><h2 id="Model-Fit-1"><a href="#Model-Fit-1" class="headerlink" title="Model Fit"></a><font color=MediumAquaMarine>Model Fit</font></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    train_generator, </span><br><span class="line">    epochs=<span class="number">25</span>, </span><br><span class="line">    steps_per_epoch=<span class="number">20</span>, </span><br><span class="line">    validation_data = validation_generator,</span><br><span class="line">    verbose = <span class="number">1</span>, </span><br><span class="line">    validation_steps=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200813122410.png" loading="lazy"></p><h1 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h1><h2 id="Week2-Exercise1"><a href="#Week2-Exercise1" class="headerlink" title=" Week2 Exercise1 "></a> Week2 Exercise1 </h2><h3 id="Spilt-Data"><a href="#Spilt-Data" class="headerlink" title="Spilt Data"></a><font color=LightSalmon>Spilt Data</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_data</span>(<span class="params">SOURCE, TRAINING, TESTING, SPLIT_SIZE</span>):</span></span><br><span class="line"><span class="comment"># YOUR CODE STARTS HERE</span></span><br><span class="line">    dataset = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> unitData <span class="keyword">in</span> os.listdir(SOURCE):</span><br><span class="line">        data = SOURCE + unitData<span class="comment"># data指的是每个文件的路径</span></span><br><span class="line">        <span class="keyword">if</span> (os.path.getsize(data) &gt; <span class="number">0</span>):</span><br><span class="line">            dataset.append(unitData)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">&#x27;Skipped &#x27;</span> + unitData)</span><br><span class="line">            print(<span class="string">&#x27;Invalid file size! i.e Zero length.&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    train_data_length = int(len(dataset) * SPLIT_SIZE)<span class="comment"># 训练集占的图片数量</span></span><br><span class="line">    test_data_length = int(len(dataset) - train_data_length)<span class="comment"># 测试集占的图片数量</span></span><br><span class="line">    shuffled_set = random.sample(dataset, len(dataset))</span><br><span class="line">    train_set = shuffled_set[<span class="number">0</span>:train_data_length]</span><br><span class="line">    test_set = shuffled_set[-test_data_length:]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> unitData <span class="keyword">in</span> train_set:</span><br><span class="line">        temp_train_data = SOURCE + unitData</span><br><span class="line">        final_train_data = TRAINING + unitData</span><br><span class="line">        copyfile(temp_train_data, final_train_data)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> unitData <span class="keyword">in</span> test_set:</span><br><span class="line">        temp_test_data = SOURCE + unitData</span><br><span class="line">        final_test_data = TESTING + unitData</span><br><span class="line">        copyfile(temp_train_data, final_test_data)</span><br><span class="line"><span class="comment"># YOUR CODE ENDS HERE</span></span><br><span class="line"></span><br><span class="line">CAT_SOURCE_DIR = <span class="string">&quot;/tmp/PetImages/Cat/&quot;</span></span><br><span class="line">TRAINING_CATS_DIR = <span class="string">&quot;/tmp/cats-v-dogs/training/cats/&quot;</span></span><br><span class="line">TESTING_CATS_DIR = <span class="string">&quot;/tmp/cats-v-dogs/testing/cats/&quot;</span></span><br><span class="line">DOG_SOURCE_DIR = <span class="string">&quot;/tmp/PetImages/Dog/&quot;</span></span><br><span class="line">TRAINING_DOGS_DIR = <span class="string">&quot;/tmp/cats-v-dogs/training/dogs/&quot;</span></span><br><span class="line">TESTING_DOGS_DIR = <span class="string">&quot;/tmp/cats-v-dogs/testing/dogs/&quot;</span></span><br><span class="line"></span><br><span class="line">split_size = <span class="number">.9</span></span><br><span class="line">split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)</span><br><span class="line">split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)</span><br></pre></td></tr></table></figure><ul><li><p>输出所有文件和文件夹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> dirs = os.listdir( path ):</span><br><span class="line"><span class="keyword">print</span> file</span><br></pre></td></tr></table></figure></li><li><p>返回文件大小，如果文件不存在就返回错误</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.path.getsize(path)</span><br></pre></td></tr></table></figure></li><li><p>为了提取出N个不同元素的样本用来做进一步的操作，可以使用 <code>random.sample()</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.sample(values, <span class="number">2</span>)</span><br><span class="line">[<span class="number">6</span>, <span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.sample(values, <span class="number">2</span>)</span><br><span class="line">[<span class="number">4</span>, <span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.sample(values, <span class="number">3</span>)</span><br><span class="line">[<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.sample(values, <span class="number">3</span>)</span><br><span class="line">[<span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>如果你仅仅只是想打乱序列中元素的顺序，可以使用 <code>random.shuffle()</code> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.shuffle(values)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>values</span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random.shuffle(values)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>values</span><br><span class="line">[<span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure></li></ul><h3 id="Recap-1"><a href="#Recap-1" class="headerlink" title="Recap"></a><font color=LightCoral>Recap</font></h3><ul><li><input checked="" disabled="" type="checkbox"> 给每个图片文件指定路径 <code>data = SOURCE + unitData</code></li><li><input checked="" disabled="" type="checkbox"> 如果图片文件大小大于零，就加入dataset   <code>os.path.getsize(path)</code></li><li><input checked="" disabled="" type="checkbox"> 计算出训练集和测试分别所占的图片数 <code>int(len(dataset)*SPLIT_SIZE)</code></li><li><input checked="" disabled="" type="checkbox"> 打乱数据集 <code>random.sample()</code>，这里可以用<code>random.shuffle</code>代替</li><li><input checked="" disabled="" type="checkbox"> 将数据集分别分给训练集和测试集 <code>[0:train_data_length]</code>，<code>[-test_data_length:]</code></li><li><input checked="" disabled="" type="checkbox"> 将图片从Source文件夹复制到Training和testing文件夹下</li></ul><h3 id="Plot-loss-And-Accuracy"><a href="#Plot-loss-And-Accuracy" class="headerlink" title=" Plot loss And Accuracy"></a><font color=LightSalmon> Plot loss And Accuracy</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.image  <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc=history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">val_acc=history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss=history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs=range(len(acc)) <span class="comment"># Get number of epochs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation accuracy per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;r&#x27;</span>, <span class="string">&quot;Training Accuracy&quot;</span>)<span class="comment"># 横轴、纵轴、颜色、label</span></span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, <span class="string">&quot;Validation Accuracy&quot;</span>) <span class="comment"># 横轴、纵轴、颜色、label</span></span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line"><span class="comment"># Plot training and validation loss per epoch</span></span><br><span class="line"><span class="comment">#------------------------------------------------</span></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;r&#x27;</span>, <span class="string">&quot;Training Loss&quot;</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;b&#x27;</span>, <span class="string">&quot;Validation Loss&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Desired output. Charts with training and validation metrics. No crash :)</span></span><br></pre></td></tr></table></figure><ul><li><p>是<code>acc</code>还是<code>accuracy</code>，取决于<code>model.compile(optimizer=RMSprop(lr=0.001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;acc&#39;])</code> 的这个<code>metrics</code>是<code>acc</code>还是<code>accuracy</code></p></li><li><p>色彩：支持的颜色缩写是单个字母代码</p><table><thead><tr><th>字符</th><th>颜色</th></tr></thead><tbody><tr><td><code>&#39;b&#39;</code></td><td>蓝色</td></tr><tr><td><code>&#39;g&#39;</code></td><td>绿色</td></tr><tr><td><code>&#39;r&#39;</code></td><td>红</td></tr><tr><td><code>&#39;c&#39;</code></td><td>青色</td></tr><tr><td><code>&#39;m&#39;</code></td><td>品红</td></tr><tr><td><code>&#39;y&#39;</code></td><td>黄色</td></tr><tr><td><code>&#39;k&#39;</code></td><td>黑色</td></tr><tr><td><code>&#39;w&#39;</code></td><td>白色</td></tr></tbody></table><p>或者这样也可以：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epochs=range(len(acc))</span><br><span class="line">plt.plot(epochs,acc)</span><br><span class="line">plt.plot(epochs,val_acc)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs,loss )</span><br><span class="line">plt.plot(epochs,val_loss)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.figure()</span><br></pre></td></tr></table></figure></li></ul><h2 id="Week2-Exercise4"><a href="#Week2-Exercise4" class="headerlink" title="Week2 Exercise4"></a>Week2 Exercise4</h2><h3 id="Get-Data"><a href="#Get-Data" class="headerlink" title="Get Data"></a><font color=LightSalmon>Get Data</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">filename</span>):</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">You will need to write code that will read the file passed into this function. The first line contains the column headers so you should ignore it. Each successive line contians 785 comma separated values between 0 and 255. The first value is the label.The rest are the pixel values for that picture.The function will return 2 np.array types. One with all the labels.One with all the images. Tips: If you read a full line (as &#x27;row&#x27;) then row[0] has the label,and row[1:785] has the 784 pixel values. Take a look at np.array_split to turn the 784 pixels into 28x28. You are reading in strings, but need the values to be floats.Check out np.array().astype for a conversion</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>    </span><br><span class="line">    <span class="keyword">with</span> open(filename) <span class="keyword">as</span> training_file:</span><br><span class="line">    <span class="comment"># Your code starts here</span></span><br><span class="line">        csv_reader = csv.reader(training_file, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">        first_line = <span class="literal">True</span></span><br><span class="line">        temp_labels= []</span><br><span class="line">        temp_images = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">        <span class="comment"># Makes first iteration of loop for first row do nothing.</span></span><br><span class="line">        <span class="comment"># That&#x27;s how you skip the first row with headers.</span></span><br><span class="line">            <span class="keyword">if</span> first_line: </span><br><span class="line">                first_line = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp_labels.append(row[<span class="number">0</span>])</span><br><span class="line">                image_data = row[<span class="number">1</span>:<span class="number">785</span>] </span><br><span class="line">                image_array = np.array_split(image_data, <span class="number">28</span>) <span class="comment"># Make 28 x 28</span></span><br><span class="line">                temp_images.append(image_array)</span><br><span class="line">        </span><br><span class="line">        images = np.array(temp_images).astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">        labels = np.array(temp_labels).astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">      <span class="comment"># Your code ends here</span></span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br><span class="line"></span><br><span class="line">path_sign_mnist_train = <span class="string">f&quot;<span class="subst">&#123;getcwd()&#125;</span>/../tmp2/sign_mnist_train.csv&quot;</span></span><br><span class="line">path_sign_mnist_test = <span class="string">f&quot;<span class="subst">&#123;getcwd()&#125;</span>/../tmp2/sign_mnist_test.csv&quot;</span></span><br><span class="line">training_images, training_labels = get_data(path_sign_mnist_train)</span><br><span class="line">testing_images, testing_labels = get_data(path_sign_mnist_test)</span><br><span class="line"></span><br><span class="line">print(training_images.shape)</span><br><span class="line">print(training_labels.shape)</span><br><span class="line">print(testing_images.shape)</span><br><span class="line">print(testing_labels.shape)</span><br></pre></td></tr></table></figure><ul><li><p><code>with open() as</code>：<a href="https://blog.csdn.net/MsSpark/article/details/86745391?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159737196419195162501901%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=159737196419195162501901&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v3~pc_rank_v3-1-86745391.pc_ecpm_v3_pc_rank_v3&utm_term=with+open+as+f%E7%94%A8%E6%B3%95&spm=1018.2118.3001.4187">详情</a></p></li><li><p><code>csv_reader = csv.reader</code>：读取csv文件</p><p><code>Dialect.delimiter</code>：一个用于分隔字段的单字符字符串。默认为<code>&#39;,&#39;</code>。</p></li><li><p><code>First_line</code>用于跳过第一行，也可以用<code>   next(csv_reader, None)  # skip the headers</code></p><p>第一行往往是标题，所以需要被跳过</p></li><li><p><code>numpy.array_split </code>：将数组拆分为大小相等的多个子数组</p></li><li><p><code>numpy.array(temp_array).astype()</code>：<a href="https://blog.csdn.net/A632189007/article/details/77989287">数据类型转换</a></p></li></ul><p>CSV的文件应该是：</p><table><thead><tr><th>标签（Label）</th><th>像素值1</th><th>像素值2</th><th>…</th><th>像素值785</th></tr></thead><tbody><tr><td><code>row[1][0]</code> 图片1</td><td><code>row[1][1]</code></td><td><code>row[1][2]</code></td><td>…</td><td><code>row[1][785]</code></td></tr><tr><td><code>row[2][0]</code> 图片2</td><td></td><td></td><td></td><td></td></tr><tr><td>…</td><td></td><td></td><td></td><td></td></tr><tr><td><code>row[n][0]</code> 图片n</td><td></td><td></td><td></td><td></td></tr></tbody></table><h3 id="Recap-2"><a href="#Recap-2" class="headerlink" title="Recap"></a><font color=LightCoral>Recap</font></h3><ul><li><input checked="" disabled="" type="checkbox"> 打开csv文件 <code>csv.reader()</code></li><li><input checked="" disabled="" type="checkbox"> 读取csv文件每一行，记得跳过第一行</li><li><input checked="" disabled="" type="checkbox"> 每一行的加入到<code>temp_labels</code>的数据集中，剩下的全是<code>image_data</code>，再将<code>image_data</code>分成28份<code>image_array</code>，每一份都加入到<code>temp_images</code>的数据集中</li><li><input checked="" disabled="" type="checkbox"> 更改数据类型，<code>numpy.array(temp_array).astype()</code></li></ul><h3 id="Add-Dimensional"><a href="#Add-Dimensional" class="headerlink" title="Add Dimensional"></a><font color=LightSalmon>Add Dimensional</font></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In this section you will have to add another dimension to the data</span></span><br><span class="line"><span class="comment"># So, for example, if your array is (10000, 28, 28)</span></span><br><span class="line"><span class="comment"># You will need to make it (10000, 28, 28, 1)</span></span><br><span class="line"><span class="comment"># Hint: np.expand_dims</span></span><br><span class="line"></span><br><span class="line">training_images = np.expand_dims(training_images, axis=<span class="number">-1</span>)</span><br><span class="line">testing_images =  np.expand_dims(testing_images, axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure><ul><li><p><code>np.expand_dims</code>：增加一个维度。axis=1代表扩展行，axis=0代表扩展列,axis=-1代表扩展最后一个参数。<a href="https://blog.csdn.net/qq_31829611/article/details/89293113?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">详情</a></p><p> 但是为啥要增加维度呢？我也不知道。啥时候解决了这个问题我再来填坑。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://keras.io/zh&quot;&gt;kears中文文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;font color=DarkOra</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Tensorflow" scheme="https://allmainashley.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Tensorflow 基础编程</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Basic%20Programming/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Tensorflow%20Basic%20Programming/</id>
    <published>2020-09-29T16:15:53.009Z</published>
    <updated>2020-09-29T16:15:53.009Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>机器学习和以往的编程的区别：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200804141544.png" loading="lazy"></p><blockquote><p>What we’ll do is we can get a bunch of examples from what we want to see, and then have the computer figure out the rules.</p></blockquote><p><font color=LighSlateGray>注意：我们所打上的标签（Labels）是Answers，而不是Rules。</font></p><p><a href="https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master">Google Colab上的所有代码</a></p><h1 id="The-‘Hello-Word’-in-neural-networks"><a href="#The-‘Hello-Word’-in-neural-networks" class="headerlink" title="The ‘Hello Word’ in neural networks"></a>The ‘Hello Word’ in neural networks</h1><p><code>model = keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])</code></p><p><font color=DarkOrange>Dense： define a layer of connected neurons </font></p><p><font color=DarkOrange>Sequencial：Succesive（连续不断的） layer</font></p><hr><p><code>model.compile(optimizer=&#39;sgd&#39;,loss=&#39;mean_squared_error&#39;)</code></p><p><font color=DarkOrange>SGD：Stochastic Gradient Descent（随机梯度下降）</font></p><p><font color=DarkOrange>Mean Squared Error：均方误差</font></p><p>补充资料：</p><p><a href="https://www.cnblogs.com/guoyaohua/p/8542554.html">深度学习——优化器算法Optimizer详解（BGD、SGD、MBGD、Momentum、NAG、Adagrad、Adadelta、RMSprop、Adam）</a></p><hr><p><code>xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)</code><br><code>ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)</code></p><p><font color=DarkOrange>X和Y的值</font></p><hr><p><code>model.fit(xs,ys,epochs=500)</code></p><p><font color=DarkOrange>代入创建好的模型中，迭代500次</font></p><hr><p><code>print(model.predict([10.0]))</code></p><p><font color=DarkOrange>完成后，输入新的数据，并让模型预测结果</font></p><hr><p><font color=DarkOrange>打印了500个，最后一个结果是</font></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6</span>/<span class="number">6</span> [==============================] - <span class="number">0</span>s <span class="number">492</span>us/step - loss: <span class="number">5.0427e-05</span></span><br><span class="line">[[<span class="number">18.979282</span>]]</span><br></pre></td></tr></table></figure><h2 id="The-complete-code"><a href="#The-complete-code" class="headerlink" title="The complete code"></a>The complete code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">model = keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>,input_shape=[<span class="number">1</span>])])</span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;sgd&#x27;</span>,loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line">xs = np.array([<span class="number">-1.0</span>,<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>],dtype=float)</span><br><span class="line">ys = np.array([<span class="number">-3.0</span>,<span class="number">-1.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">7.0</span>],dtype=float)</span><br><span class="line"></span><br><span class="line">model.fit(xs,ys,epochs=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">print(model.predict([<span class="number">10.0</span>]))</span><br></pre></td></tr></table></figure><h2 id="Why-not-19？"><a href="#Why-not-19？" class="headerlink" title="Why not 19？"></a><font color=Red>Why not 19？</font></h2><ul><li><p>The first is that you trained it using a very little data. (数据少)</p></li><li><p>When using neural network, as they try to figure out the answer for everything, they deal in probability. (概率)</p></li></ul><h1 id="Fashion-mnist"><a href="#Fashion-mnist" class="headerlink" title="Fashion mnist"></a>Fashion mnist</h1><p>Fashion-MNIST包含70k张图片，10种衣物，并且每张都是28x28灰度图像（数据量更小，但人眼依然可以识别）。</p><p>它是在Tensorflow这个API中的数据集。</p><p><code>mnist = keras.datasets.fashion_mnist</code></p><p><font color=DarkOrange>Declare an object of  type MNIST （声明变量）</font> </p><hr><p><code>(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</code></p><p><font color=DarkOrange>Loading it from the Keras database, and on this object, if we called <code>load_data</code> method, it will return 4 lists to us, <code>the training data </code>, <code>the training labels </code>, <code>the testing data</code> and  <code>the testing labels</code>. </font></p><p><font color=darkorange>调用函数，返回四个列表，训练集，训练集标签，测试集，测试集标签。</font></p><h2 id="Choose-an-ankle-boot-picture，its-label-is-09，why-are-numbers？"><a href="#Choose-an-ankle-boot-picture，its-label-is-09，why-are-numbers？" class="headerlink" title=" Choose an ankle boot picture，its label is 09，why are numbers？"></a><font color=Red> Choose an ankle boot picture，its label is <code>09</code>，why are numbers？</font></h2><ul><li><p>Computer do better with numbers  （计算机处理数字处理地更好）</p></li><li><p>Reduce bias 减少偏见。如果用英语标注，会偏向English Speakers. ）</p><p>（啊这，可是主流的编程语言不都是用英语写的嘛。但是换成数字确实免去了转换的麻烦）</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805232405.jpg" loading="lazy"></p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),  </span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax) </span><br><span class="line">])</span><br></pre></td></tr></table></figure><p><font color=DarkOrange>第一层是扁平层，每个图片的像素是28x28，把这个28x28的正方形变成一个简单的 linear array。</font></p><p>举个例子：把这个 (height, width, channel) 的三维数据压缩成长度为 (height × width × channel, 1) 的一维数组。</p><p><font color=DarkOrange>第二层是隐藏层，这一层有128个神经元。</font></p><p><font color=DarkOrange>#第三层是输出层，因为有10种衣物，所以得到的应该是10个概率，且和为1。</font></p><hr><h2 id="The-complete-code-1"><a href="#The-complete-code-1" class="headerlink" title="The complete code"></a>The complete code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">mnist = keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印第0个样本的值</span></span><br><span class="line">plt.imshow(training_images[<span class="number">0</span>])</span><br><span class="line">print(training_labels[<span class="number">0</span>])</span><br><span class="line">print(training_images[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">training_images = training_images/<span class="number">255.0</span></span><br><span class="line">test_images = test_images/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型搭建</span></span><br><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),  <span class="comment">#每个图片的像素是28x28</span></span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">    keras.layers.Dense(<span class="number">10</span>,activation=tf.nn.softmax) <span class="comment">#因为有10种衣物，所以应该得到的是他们各自的概率</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型编译</span></span><br><span class="line">model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(),loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型拟合</span></span><br><span class="line">model.fit(training_images,training_labels,epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">model.evaluate(test_images,test_labels)</span><br></pre></td></tr></table></figure><h2 id="Callback"><a href="#Callback" class="headerlink" title="Callback"></a>Callback</h2><p>调用一个回调函数，检查指标，如果这个指标合格的话，你可以在该点取消训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myCallback</span>(<span class="params">tf.keras.callbacks.Callback</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span>(<span class="params">self, epoch, logs=&#123;&#125;</span>):</span>     <span class="comment"># 在迭代结束时调用</span></span><br><span class="line">        <span class="keyword">if</span>(logs.get(<span class="string">&#x27;loss&#x27;</span>)&lt;<span class="number">0.4</span>):</span><br><span class="line">            print(<span class="string">&quot;\nLoss is low so cancelling training!&quot;</span>)</span><br><span class="line">            self.model.stop_training = <span class="literal">True</span>  <span class="comment"># 如果loss&lt;0.4,就停止训练</span></span><br></pre></td></tr></table></figure><p><code>callbacks = myCallback()</code></p><p><font color=DarkOrange>实例化刚刚创建的类</font></p><p><code>model.fit(training_images,training_labels,epochs=5,callbacks=[callbacks])</code></p><p><font color=DarkOrange>修改<code>model.fit </code>函数，使用回调参数，并传递它的类实例</font></p><p><font color=LightSlateGray>看看结果：</font></p><p><code>60000/60000 [==============================] - 3s 42us/step - loss: 0.3787</code><br><code>Loss is low so cancelling training!</code></p><h1 id="Convolutional-neural-networks"><a href="#Convolutional-neural-networks" class="headerlink" title="Convolutional neural networks"></a>Convolutional neural networks</h1><p>使用卷积神经网络（用滤波器遍历图片）代替逐张照片逐个像素遍历。</p><p><code>tf.keras.layers.Conv2D(64,(3,3),activation=&#39;relu&#39;,input_shape=(28,28,1))</code></p><p><font color=DarkOrange>Conv2D：第一层是卷积层</font></p><p><font color=DarkOrange>(3,3)：过滤器的大小是 3x3</font></p><p><font color=DarkOrange>activation=’relu’：激活函数是relu，意味着负值将会被抛弃</font></p><p><font color=DarkOrange>input_shape=(28,28,1)：输入形状和之前一样，是 28x28。额外的1个意味着我们正在用1个字节去来加计算颜色深度（color depth），因为是灰度图像，所以只需要1个字节（如果是彩色图像，则需要3个字节）</font></p><hr><p><code>tf.keras.layers.MaxPooling2D(2,2),</code></p><p><font color=DarkOrange>MaxPooling2D：第二层是池化层，方式是最大值池化，其尺寸是 2x2</font></p><p>···其余依此类推。</p><p>经过两个卷积层和两个池化层之后，content简化了很多。</p><hr><p><code>model.summary()</code></p><p><font color=DarkOrange>This allows you to inspect the layers of the model, and see the journey of the image through the convolutions. （打印模型概述信息）</font></p><p>打印信息如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">conv2d (Conv2D)              (None, 26, 26, 64)        640       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten (Flatten)            (None, 1600)              0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (None, 128)               204928    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 10)                1290      </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 243,786</span><br><span class="line">Trainable params: 243,786</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure><p>注意这个Output Shape：</p><ul><li><p><font color=HotPink>输入形状：28×28</font></p></li><li><p><font color=HotPink>第一层：28-3+1=26（因为是valid填充 且 fliter是3x3）</font></p></li><li><p><font color=HotPink>第二层：26÷2（MaxPooling的大小是2x2，所以stride也是2）=13</font></p></li><li><p><font color=HotPink>第三层：13-3+1=11（因为是valid填充 且 fliter是3x3）</font></p></li><li><p><font color=HotPink>第四层：11÷2=5······1（MaxPooling的大小是2x2，所以stride也是2）</font></p></li><li><p><font color=HotPink>第五层：扁平化，5×5×64 = 1600</font></p></li><li><p><font color=HotPink>输出层：有10个分类，所以输出层的形状是10</font></p></li></ul><blockquote><p>计算公式：n_w与n_h同理。</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200806232259.png" loading="lazy"></p></blockquote><p>训练集最后一行结果：</p><p><code>10000/10000 [==============================] - 2s 199us/sample - loss: 0.2787</code></p><p>测试集最后一行结果：</p><p><code>10000/10000 [==============================] - 2s 199us/sample - loss: 0.2787</code></p><h2 id="The-complete-code-2"><a href="#The-complete-code-2" class="headerlink" title="The complete code"></a>The complete code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导包</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">mnist = keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">training_images=training_images.reshape(<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">training_images=training_images/<span class="number">255.0</span></span><br><span class="line">test_images=test_images.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)</span><br><span class="line">test_images=test_images/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型搭建</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPool2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型编译</span></span><br><span class="line">model.compile(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型概述信息</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型拟合</span></span><br><span class="line">model.fit(training_images,training_labels,epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">test_loss=model.evaluate(test_images,test_labels)</span><br></pre></td></tr></table></figure><h1 id="Visualizing-the-convolutions-and-pooling"><a href="#Visualizing-the-convolutions-and-pooling" class="headerlink" title="Visualizing the convolutions and pooling"></a>Visualizing the convolutions and pooling</h1><p>如果是打印多张图片需要在最末尾加一个<code>plt.show</code></p><h2 id="The-complete-code-3"><a href="#The-complete-code-3" class="headerlink" title="The complete code"></a>The complete code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导包</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">mnist = keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建模型</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>,input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPool2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>,activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">print(test_labels[:<span class="number">100</span>])    <span class="comment"># 打印出前100个标签</span></span><br><span class="line">f, axarr = plt.subplots(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">FIRST_IMAGE=<span class="number">0</span></span><br><span class="line">SECOND_IMAGE=<span class="number">23</span></span><br><span class="line">THIRD_IMAGE=<span class="number">28</span></span><br><span class="line">CONVOLUTION_NUMBER=<span class="number">1</span></span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers]</span><br><span class="line">activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,<span class="number">4</span>):  </span><br><span class="line">  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">0</span>,x].imshow(f1[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">0</span>,x].grid(<span class="literal">False</span>)</span><br><span class="line">  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">1</span>,x].imshow(f2[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">1</span>,x].grid(<span class="literal">False</span>)</span><br><span class="line">  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))[x]</span><br><span class="line">  axarr[<span class="number">2</span>,x].imshow(f3[<span class="number">0</span>, : , :, CONVOLUTION_NUMBER], cmap=<span class="string">&#x27;inferno&#x27;</span>)</span><br><span class="line">  axarr[<span class="number">2</span>,x].grid(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805175355.png" loading="lazy"></p><h1 id="Walking-through-convolutions"><a href="#Walking-through-convolutions" class="headerlink" title="Walking through convolutions"></a>Walking through convolutions</h1><blockquote><p>补充资料：</p><p>安装cv2：<code>pip install opencv-python</code></p><p>网速问题可以试试镜像：<code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple opencv-python</code></p><p>misc模块，提供一些基本的图像相关的读写函数，可以很轻松的读取本地图像文件到Python程序里，也可将数据输出到图像文件。misc模块自带一些灰度图像ascent和彩色的face图，可以scipy.misc.ascent()直接获取爬楼梯ascent图数据到Python程序里，用scipy.misc.face()获取一副 raccoon浣熊face图，这两个函数的返回值都是Numpy的ndarray数组。 face图像是个彩色图像，其数据是个三维数组，是个1024x768的图像，而图像中每个像素的值又是一个数组，分别对应该像素颜色的红、绿、蓝分量。ascent图像是个灰度图像，其数据是个二维数组，分别对应图像中每个像素的灰度值。<a href="http://liao.cpython.org/scipy02/">详情</a></p><p>plt.imshow()函数负责对图像进行处理，并显示其格式，但是不能显示。其后跟着plt.show()才能显示出来。<a href="https://blog.csdn.net/qq_39938666/article/details/85786413">详情</a></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">i=misc.ascent() <span class="comment"># 灰度图像</span></span><br><span class="line">plt.grid(<span class="literal">False</span>) <span class="comment"># 生成网络</span></span><br><span class="line">plt.gray() <span class="comment"># 灰度图像</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(i)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 此时图像被存储为numpy array</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805181004.png" loading="lazy"></p><h2 id="The-complete-code-4"><a href="#The-complete-code-4" class="headerlink" title="The complete code"></a>The complete code</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导包</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> misc</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">i=misc.ascent() <span class="comment"># 灰度图像</span></span><br><span class="line">plt.grid(<span class="literal">False</span>) <span class="comment"># 生成网络</span></span><br><span class="line">plt.gray()      <span class="comment"># 灰度图像</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.imshow(i)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">i_trainsformed = np.copy(i) <span class="comment"># 此时图像被存储为numpy array</span></span><br><span class="line">size_x = i_trainsformed.shape[<span class="number">0</span>]<span class="comment"># size_x:第0维的长度</span></span><br><span class="line">size_y = i_trainsformed.shape[<span class="number">1</span>] <span class="comment"># size_y:第1维的长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个3×3的filter，以下是三种不同的filter</span></span><br><span class="line"><span class="comment"># filter = [[0,1,0],[1,-4,1],[0,1,0]]</span></span><br><span class="line"><span class="comment"># filter = [[-1,-2,-1],[0,0,0],[1,2,1]]</span></span><br><span class="line">filter = [[<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">-2</span>,<span class="number">0</span>,<span class="number">2</span>],[<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br><span class="line">weight = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建卷积神经网络，注意x和y的范围</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>,size_x<span class="number">-1</span>):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">1</span>,size_y<span class="number">-1</span>):</span><br><span class="line">        convolution = <span class="number">0.0</span></span><br><span class="line">        convolution = convolution + (i[x<span class="number">-1</span>,y<span class="number">-1</span>] * filter[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">        convolution = convolution + (i[x,y<span class="number">-1</span>] * filter[<span class="number">0</span>][<span class="number">1</span>])</span><br><span class="line">        convolution = convolution + (i[x+<span class="number">1</span>,y<span class="number">-1</span>] * filter[<span class="number">0</span>][<span class="number">2</span>])</span><br><span class="line">        convolution = convolution + (i[x<span class="number">-1</span>,y] * filter[<span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line">        convolution = convolution + (i[x,y] * filter[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">        convolution = convolution + (i[x+<span class="number">1</span>,y] * filter[<span class="number">1</span>][<span class="number">2</span>])</span><br><span class="line">        convolution = convolution + (i[x<span class="number">-1</span>,y+<span class="number">1</span>] * filter[<span class="number">2</span>][<span class="number">0</span>])</span><br><span class="line">        convolution = convolution + (i[x,y+<span class="number">1</span>] * filter[<span class="number">2</span>][<span class="number">1</span>])</span><br><span class="line">        convolution = convolution + (i[x+<span class="number">1</span>,y+<span class="number">1</span>] * filter[<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line">        <span class="comment"># relu层：</span></span><br><span class="line">        <span class="keyword">if</span>(convolution&lt;<span class="number">0</span>):</span><br><span class="line">            convolution=<span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span>(convolution&gt;<span class="number">255</span>):</span><br><span class="line">            convolution=<span class="number">255</span></span><br><span class="line">        i_trainsformed[x,y]=convolution</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印卷积化后的图片</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.gray()</span><br><span class="line">plt.imshow(i_trainsformed)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 池化</span></span><br><span class="line">new_x = int(size_x/<span class="number">2</span>)</span><br><span class="line">new_y = int(size_y/<span class="number">2</span>)</span><br><span class="line">newImage = np.zeros((new_x,new_y))</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>,size_x,<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">0</span>,size_y,<span class="number">2</span>):</span><br><span class="line">        pixels = []</span><br><span class="line">        pixels.append(i_trainsformed[x,y])</span><br><span class="line">        pixels.append(i_trainsformed[x+<span class="number">1</span>,y])</span><br><span class="line">        pixels.append(i_trainsformed[x,y+<span class="number">1</span>])</span><br><span class="line">        pixels.append(i_trainsformed[x+<span class="number">1</span>,y+<span class="number">1</span>])</span><br><span class="line">        pixels.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">        newImage[int(x/<span class="number">2</span>),int(y/<span class="number">2</span>)] = pixels[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印池化后的图片</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.gray()</span><br><span class="line">plt.imshow(i_trainsformed)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>不同<code>filter</code>对应的结果按顺序如图所示：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805232408.png" loading="lazy"></p><p><font color=Salmon>第一个：效果并不明显</font></p><hr><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805232406.png" loading="lazy"></p><p><font color=Salmon>第二个：检测垂直边缘</font></p><hr><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805232409.png" loading="lazy"></p><p><font color=Salmon>第三个：检测水平边缘</font></p><hr><p>池化结果：</p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200805232407.png" loading="lazy"></p><p><font color=Salmon>从坐标轴来看，这些被保留的特征更加紧密，我用的是第三个filter，你也可以试试别的filter。</font></p><p><font color=Salmon>（因为池化的缘故，只保留了图片的部分特征，所以这个图变糊了）</font></p><hr><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p><font color=green><strong>通过卷积和池化，大大减少了通过神经网络的信息。通过分离和识别特征，你还能得到更高的精度</strong></font></p><h1 id="Image-Generator"><a href="#Image-Generator" class="headerlink" title="Image Generator"></a>Image Generator</h1><blockquote><p>Image Generator 是tensorflow的一个API。你可以把它指向一个目录，然后它的子目录会会为你自动生成标签。例如，考虑这个目录结构，你有一个图片目录，有训练和验证集的子目录，当你把人和马的子目录放在这些父目录中，并且存储相应的图像时，Image Generator可以为这些图片创建一个feeder，并且为你自动标记。<a href="https://blog.csdn.net/mieleizhi0522/article/details/82191331">相关资料</a></p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200806224653.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200806224709.png" loading="lazy"></p><hr><h2 id="The-complete-code-5"><a href="#The-complete-code-5" class="headerlink" title="The complete code"></a>The complete code</h2><blockquote><p><a href="https://colab.research.google.com/drive/1ah5ni6r2PHMpn6ytttWrRY6AyCFk9N-j#scrollTo=RXZT2UsyIVe">完整代码 Goolgle Colab版</a> </p><p><a href="https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip">训练集下载</a></p><p><a href="https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip">验证集下载</a></p><p><font color=Red><strong>建议在Google Colab上运行</strong></font></p></blockquote><h3 id="Data-Processing"><a href="#Data-Processing" class="headerlink" title="Data Processing"></a>Data Processing</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 解压数据集</span></span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line">local_zip = <span class="string">&#x27;/tmp/horse-or-human.zip&#x27;</span></span><br><span class="line">zip_ref = zipfile.ZipFile(local_zip, <span class="string">&#x27;r&#x27;</span>) <span class="comment"># 用于读写ZIP文件的类</span></span><br><span class="line">zip_ref.extractall(<span class="string">&#x27;/tmp/horse-or-human&#x27;</span>)  <span class="comment"># 将存档中的所有成员提取到当前工作目录</span></span><br><span class="line">local_zip = <span class="string">&#x27;/tmp/validation-horse-or-human.zip&#x27;</span></span><br><span class="line">zip_ref = zipfile.ZipFile(local_zip, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">zip_ref.extractall(<span class="string">&#x27;/tmp/validation-horse-or-human&#x27;</span>) <span class="comment"># 将存档中的所有成员提取到当前工作目录</span></span><br><span class="line">zip_ref.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our training horse pictures</span></span><br><span class="line">train_horse_dir = os.path.join(<span class="string">&#x27;horse-or-human/horses&#x27;</span>)</span><br><span class="line"><span class="comment"># Directory with our training human pictures</span></span><br><span class="line">train_human_dir = os.path.join(<span class="string">&#x27;horse-or-human/humans&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Directory with our training horse pictures</span></span><br><span class="line">validation_horse_dir = os.path.join(<span class="string">&#x27;/tmp/validation-horse-or-human/horses&#x27;</span>)</span><br><span class="line"><span class="comment"># Directory with our training human pictures</span></span><br><span class="line">validation_human_dir = os.path.join(<span class="string">&#x27;/tmp/validation-horse-or-human/humans&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印前10个图片名</span></span><br><span class="line">train_horse_names = os.listdir(train_horse_dir)     <span class="comment"># 用于返回指定的文件夹包含的文件或文件夹的名字的列表。</span></span><br><span class="line">print(train_horse_names[:<span class="number">10</span>])</span><br><span class="line">train_human_names = os.listdir(train_human_dir)</span><br><span class="line">print(train_human_names[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">validation_horse_hames = os.listdir(validation_horse_dir)</span><br><span class="line">print(validation_horse_hames[:<span class="number">10</span>])</span><br><span class="line">validation_human_names = os.listdir(validation_human_dir)</span><br><span class="line">print(validation_human_names[:<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印图片总数量</span></span><br><span class="line">print(<span class="string">&#x27;total training horse images:&#x27;</span>, len(os.listdir(train_horse_dir)))</span><br><span class="line">print(<span class="string">&#x27;total training human images:&#x27;</span>, len(os.listdir(train_human_dir)))</span><br><span class="line">print(<span class="string">&#x27;total validation horse images:&#x27;</span>, len(os.listdir(validation_horse_dir)))</span><br><span class="line">print(<span class="string">&#x27;total validation human images:&#x27;</span>, len(os.listdir(validation_human_dir)))</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> mpimg</span><br><span class="line"><span class="comment"># Parameters for our graph; we&#x27;ll output images in a 4x4 configuration</span></span><br><span class="line">nrows = <span class="number">4</span></span><br><span class="line">ncols = <span class="number">4</span></span><br><span class="line"><span class="comment"># Index for iterating over images</span></span><br><span class="line">pic_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 随机生成图片</span></span><br><span class="line"><span class="comment"># Set up matplotlib fig, and size it to fit 4x4 pics</span></span><br><span class="line">fig = plt.gcf() <span class="comment"># 获取当前数字。如果没有当前数字，则使用创建一个新数字 figure()。</span></span><br><span class="line">fig.set_size_inches(ncols * <span class="number">4</span>, nrows * <span class="number">4</span>)   <span class="comment"># 以英寸为单位设置图形尺寸</span></span><br><span class="line"></span><br><span class="line">pic_index += <span class="number">8</span></span><br><span class="line">next_horse_pix = [os.path.join(train_horse_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_horse_names[pic_index<span class="number">-8</span>:pic_index]]</span><br><span class="line">next_human_pix = [os.path.join(train_human_dir, fname) </span><br><span class="line">                <span class="keyword">for</span> fname <span class="keyword">in</span> train_human_names[pic_index<span class="number">-8</span>:pic_index]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, img_path <span class="keyword">in</span> enumerate(next_horse_pix+next_human_pix):</span><br><span class="line">  <span class="comment"># Set up subplot; subplot indices start at 1</span></span><br><span class="line">  sp = plt.subplot(nrows, ncols, i + <span class="number">1</span>)</span><br><span class="line">  sp.axis(<span class="string">&#x27;Off&#x27;</span>) <span class="comment"># Don&#x27;t show axes (or gridlines)</span></span><br><span class="line"></span><br><span class="line">  img = mpimg.imread(img_path)</span><br><span class="line">  plt.imshow(img)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 搭建模型</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    <span class="comment"># Note the input shape is the desired size of the image 300x300 with 3 bytes color</span></span><br><span class="line">    <span class="comment"># This is the first convolution</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">300</span>, <span class="number">300</span>, <span class="number">3</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    <span class="comment"># The second convolution</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># The third convolution</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># The fourth convolution</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># The fifth convolution</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># Flatten the results to feed into a DNN</span></span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    <span class="comment"># 512 neuron hidden layer</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    <span class="comment"># Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class (&#x27;horses&#x27;) and 1 for the other (&#x27;humans&#x27;)</span></span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">### 打印模型概述信息</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">### 编译模型</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 在分类时尚衣物(fashion mnist)时，loss是分类交叉熵(sparse_categorical_crossentropy)</span></span><br><span class="line"><span class="comment"># 在此处做的是二分类，所以用二值交叉熵(binary_crossentropy)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 数据预处理</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># All images will be rescaled by 1./255</span></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1</span>/<span class="number">255</span>)</span><br><span class="line">validation_datagen = ImageDataGenerator(rescale=<span class="number">1</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow training images in batches of 128 using train_datagen generator</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">        <span class="string">&#x27;/tmp/horse-or-human/&#x27;</span>,  <span class="comment"># This is the source directory for training images</span></span><br><span class="line">        target_size=(<span class="number">300</span>, <span class="number">300</span>),  <span class="comment"># All images will be resized to 300x300</span></span><br><span class="line">        batch_size=<span class="number">128</span>,</span><br><span class="line">        <span class="comment"># Since we use binary_crossentropy loss, we need binary labels</span></span><br><span class="line">        class_mode=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow training images in batches of 128 using train_datagen generator</span></span><br><span class="line">validation_generator = validation_datagen.flow_from_directory(</span><br><span class="line">        <span class="string">&#x27;/tmp/validation-horse-or-human/&#x27;</span>,  <span class="comment"># This is the source directory for training images</span></span><br><span class="line">        target_size=(<span class="number">300</span>, <span class="number">300</span>),  <span class="comment"># All images will be resized to 300x300</span></span><br><span class="line">        batch_size=<span class="number">32</span>,</span><br><span class="line">        <span class="comment"># Since we use binary_crossentropy loss, we need binary labels</span></span><br><span class="line">        class_mode=<span class="string">&#x27;binary&#x27;</span>)</span><br></pre></td></tr></table></figure><p>打印模型概述信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">conv2d (Conv2D)              (None, 298, 298, 16)      448       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten (Flatten)            (None, 78400)             0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense (Dense)                (None, 512)               40141312  </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 1)                 513       </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 40,165,409</span><br><span class="line">Trainable params: 40,165,409</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 模型拟合</span></span><br><span class="line">hitory = model.fit_generator(</span><br><span class="line">    train_generator,     <span class="comment"># 从训练目录中流式传输图像，我们一共有1024张图片，每批128个，一共需要8批</span></span><br><span class="line">    steps_per_epoch=<span class="number">8</span>,   <span class="comment"># 因为一共需要8批，所以每次epoch都需要8个steps</span></span><br><span class="line">    epochs=<span class="number">15</span>,           <span class="comment"># 迭代15次</span></span><br><span class="line">    validation_data=validation_generator,   <span class="comment"># 验证集</span></span><br><span class="line">    validation_steps=<span class="number">8</span>,  <span class="comment"># 验证集一共有256张图片，每批32个，一共需要8批</span></span><br><span class="line">    verbose=<span class="number">2</span>            <span class="comment"># verbose: 0, 1 或 2。日志显示模式。 0 = 安静模式, 1 = 进度条, 2 = 每轮一行。</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 10s 1s&#x2F;step - loss: 1.2514 - accuracy: 0.5595 - val_loss: 0.7164 - val_accuracy: 0.5000</span><br><span class="line">Epoch 2&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 934ms&#x2F;step - loss: 0.6435 - accuracy: 0.6007 - val_loss: 0.4255 - val_accuracy: 0.8359</span><br><span class="line">Epoch 3&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 930ms&#x2F;step - loss: 0.7979 - accuracy: 0.5818 - val_loss: 0.6263 - val_accuracy: 0.5820</span><br><span class="line">Epoch 4&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 984ms&#x2F;step - loss: 0.6299 - accuracy: 0.7500 - val_loss: 1.7047 - val_accuracy: 0.5156</span><br><span class="line">Epoch 5&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 919ms&#x2F;step - loss: 0.4249 - accuracy: 0.8665 - val_loss: 0.9030 - val_accuracy: 0.7500</span><br><span class="line">Epoch 6&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 928ms&#x2F;step - loss: 0.4901 - accuracy: 0.7887 - val_loss: 2.9393 - val_accuracy: 0.5312</span><br><span class="line">Epoch 7&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 942ms&#x2F;step - loss: 0.3563 - accuracy: 0.8743 - val_loss: 0.5138 - val_accuracy: 0.8711</span><br><span class="line">Epoch 8&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 939ms&#x2F;step - loss: 0.1760 - accuracy: 0.9221 - val_loss: 1.0816 - val_accuracy: 0.8438</span><br><span class="line">Epoch 9&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 934ms&#x2F;step - loss: 0.2974 - accuracy: 0.8776 - val_loss: 0.7862 - val_accuracy: 0.8203</span><br><span class="line">Epoch 10&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 915ms&#x2F;step - loss: 0.1401 - accuracy: 0.9488 - val_loss: 2.0065 - val_accuracy: 0.7344</span><br><span class="line">Epoch 11&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 936ms&#x2F;step - loss: 0.2258 - accuracy: 0.9199 - val_loss: 0.6971 - val_accuracy: 0.8711</span><br><span class="line">Epoch 12&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 987ms&#x2F;step - loss: 0.3130 - accuracy: 0.9102 - val_loss: 0.7559 - val_accuracy: 0.8516</span><br><span class="line">Epoch 13&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 942ms&#x2F;step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 1.4367 - val_accuracy: 0.8281</span><br><span class="line">Epoch 14&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 8s 938ms&#x2F;step - loss: 0.0438 - accuracy: 0.9867 - val_loss: 1.6447 - val_accuracy: 0.8320</span><br><span class="line">Epoch 15&#x2F;15</span><br><span class="line">8&#x2F;8 [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;] - 7s 937ms&#x2F;step - loss: 0.1036 - accuracy: 0.9611 - val_loss: 0.9236 - val_accuracy: 0.8672</span><br></pre></td></tr></table></figure><h3 id="Running-the-model"><a href="#Running-the-model" class="headerlink" title="Running the model"></a>Running the model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"></span><br><span class="line">uploaded = files.upload()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fn <span class="keyword">in</span> uploaded.keys():</span><br><span class="line"> </span><br><span class="line">  <span class="comment"># predicting images</span></span><br><span class="line">  path = <span class="string">&#x27;/content/&#x27;</span> + fn</span><br><span class="line">  img = image.load_img(path, target_size=(<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line">  x = image.img_to_array(img)</span><br><span class="line">  x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  images = np.vstack([x])</span><br><span class="line">  classes = model.predict(images, batch_size=<span class="number">10</span>)</span><br><span class="line">  print(classes[<span class="number">0</span>])</span><br><span class="line">  <span class="keyword">if</span> classes[<span class="number">0</span>]&gt;<span class="number">0.5</span>:</span><br><span class="line">    print(fn + <span class="string">&quot; is a human&quot;</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    print(fn + <span class="string">&quot; is a horse&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> img_to_array, load_img</span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s define a new Model that will take an image as input, and will output</span></span><br><span class="line"><span class="comment"># intermediate representations for all layers in the previous model after</span></span><br><span class="line"><span class="comment"># the first.</span></span><br><span class="line">successive_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[<span class="number">1</span>:]]</span><br><span class="line"><span class="comment">#visualization_model = Model(img_input, successive_outputs)</span></span><br><span class="line">visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)</span><br><span class="line"><span class="comment"># Let&#x27;s prepare a random input image from the training set.</span></span><br><span class="line">horse_img_files = [os.path.join(train_horse_dir, f) <span class="keyword">for</span> f <span class="keyword">in</span> train_horse_names]</span><br><span class="line">human_img_files = [os.path.join(train_human_dir, f) <span class="keyword">for</span> f <span class="keyword">in</span> train_human_names]</span><br><span class="line">img_path = random.choice(horse_img_files + human_img_files)</span><br><span class="line"></span><br><span class="line">img = load_img(img_path, target_size=(<span class="number">300</span>, <span class="number">300</span>))  <span class="comment"># this is a PIL image</span></span><br><span class="line">x = img_to_array(img)  <span class="comment"># Numpy array with shape (150, 150, 3)</span></span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)  <span class="comment"># Numpy array with shape (1, 150, 150, 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Rescale by 1/255</span></span><br><span class="line">x /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Let&#x27;s run our image through our network, thus obtaining all</span></span><br><span class="line"><span class="comment"># intermediate representations for this image.</span></span><br><span class="line">successive_feature_maps = visualization_model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># These are the names of the layers, so can have them as part of our plot</span></span><br><span class="line">layer_names = [layer.name <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[<span class="number">1</span>:]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now let&#x27;s display our representations</span></span><br><span class="line"><span class="keyword">for</span> layer_name, feature_map <span class="keyword">in</span> zip(layer_names, successive_feature_maps):</span><br><span class="line">  <span class="keyword">if</span> len(feature_map.shape) == <span class="number">4</span>:</span><br><span class="line">    <span class="comment"># Just do this for the conv / maxpool layers, not the fully-connected layers</span></span><br><span class="line">    n_features = feature_map.shape[<span class="number">-1</span>]  <span class="comment"># number of features in feature map</span></span><br><span class="line">    <span class="comment"># The feature map has shape (1, size, size, n_features)</span></span><br><span class="line">    size = feature_map.shape[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># We will tile our images in this matrix</span></span><br><span class="line">    display_grid = np.zeros((size, size * n_features))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_features):</span><br><span class="line">      <span class="comment"># Postprocess the feature to make it visually palatable</span></span><br><span class="line">      x = feature_map[<span class="number">0</span>, :, :, i]</span><br><span class="line">      x -= x.mean()</span><br><span class="line">      x /= x.std()</span><br><span class="line">      x *= <span class="number">64</span></span><br><span class="line">      x += <span class="number">128</span></span><br><span class="line">      x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">      <span class="comment"># We&#x27;ll tile each filter into this big horizontal grid</span></span><br><span class="line">      display_grid[:, i * size : (i + <span class="number">1</span>) * size] = x</span><br><span class="line">    <span class="comment"># Display the grid</span></span><br><span class="line">    scale = <span class="number">20.</span> / n_features</span><br><span class="line">    plt.figure(figsize=(scale * n_features, scale))</span><br><span class="line">    plt.title(layer_name)</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(display_grid, aspect=<span class="string">&#x27;auto&#x27;</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173717.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173729.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173750.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173806.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173839.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173931.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807173948.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807174030.png" loading="lazy"></p><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200807174043.png" loading="lazy"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;机器学习和以往的编程的区别：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/AllMainAsh</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Tensorflow" scheme="https://allmainashley.github.io/tags/Tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Octave 学习笔记</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Octave%20Notes/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Octave%20Notes/</id>
    <published>2020-09-29T16:15:52.998Z</published>
    <updated>2020-09-29T16:15:52.998Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Basic-operations"><a href="#Basic-operations" class="headerlink" title="Basic operations"></a>Basic operations</h1><table><thead><tr><th>基本运算</th><th>运算法则</th></tr></thead><tbody><tr><td><code>+</code></td><td>加法</td></tr><tr><td><code>-</code></td><td>减法</td></tr><tr><td><code>× </code></td><td>乘法</td></tr><tr><td><code>÷</code></td><td>除法</td></tr><tr><td><code>^</code></td><td>指数</td></tr><tr><td><code>sqrt()</code></td><td>根号</td></tr></tbody></table><ul><li><code>%</code>表示注释</li></ul><table><thead><tr><th>公式</th><th>作用</th></tr></thead><tbody><tr><td><code>==</code></td><td>equal</td></tr><tr><td><code>~=</code></td><td>not equal</td></tr><tr><td><code>&amp;&amp;</code></td><td>与</td></tr><tr><td><code>||</code></td><td>或</td></tr><tr><td><code>xor</code></td><td>异或</td></tr></tbody></table><ul><li><p><code>PS1(&#39;&gt;&gt;&gt;&#39;)</code> 将提示符 更改为<code>&gt;&gt;&gt;</code></p></li><li><p>逻辑与：同真为真，否则为假</p></li></ul><ul><li><code>;</code> 句末输出分号，防止打印输出(supress the print output)</li></ul><ul><li><p>输出一般变量，直接输入变量名即可</p></li><li><p>对于复杂的变量，可以使用<code>disp(a)</code>来输出变量<code>a</code>，也可以使用C语言的旧式语法<code>disp(sprintf(&#39;2 decimals:%0.2f&#39;,a))</code>就输出保留两位小数后的变量ａ啦</p></li><li><p><code>format long</code> 让字符串显示默认的位数</p><p>　</p></li></ul><h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><table><thead><tr><th>公式</th><th>作用</th></tr></thead><tbody><tr><td><code>a=[1 2;3 4;5 6]</code></td><td>生成三行两列矩阵</td></tr><tr><td><code>a=[1;2;3]</code></td><td>生成向量</td></tr><tr><td><code>v=[1:0.1:2]</code></td><td>从1到2,步长为0.1的行向量</td></tr><tr><td><code>v=[1:6]</code></td><td>从1到6的行向量</td></tr><tr><td><code>ones(2,3)</code></td><td>两行三列全１矩阵</td></tr><tr><td><code>2*ones(2,3)</code></td><td>全2矩阵</td></tr><tr><td><code>zeros(1,3)</code></td><td>全0矩阵</td></tr><tr><td><code>rand(1,3)</code></td><td>随机矩阵(0~1)</td></tr><tr><td><code>w=randn(1,3)</code></td><td>高斯随机变量，服从正态分布</td></tr><tr><td><code>hist(w)</code></td><td>会绘制出w的直方图</td></tr><tr><td><code>hist(w,50)</code></td><td>横轴细分成50份</td></tr><tr><td><code>eye(4)</code></td><td>生成4x4的单位矩阵</td></tr><tr><td><code>help functio_name</code></td><td>帮助</td></tr></tbody></table><ul><li><p>等价于第一条</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a&#x3D;[1 2;</span><br><span class="line">  3 4;</span><br><span class="line">  5,6]</span><br></pre></td></tr></table></figure></li><li><p><code>v=[1;2;3]</code>    <code>v=[1 2 3]</code></p></li></ul><p>  输出结果： </p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1   2   3</span><br></pre></td></tr></table></figure>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 </span><br><span class="line">2 </span><br><span class="line">3</span><br></pre></td></tr></table></figure><h1 id="Move-data-around"><a href="#Move-data-around" class="headerlink" title="Move data around"></a>Move data around</h1><table><thead><tr><th>公式</th><th>作用</th></tr></thead><tbody><tr><td><code>size(A)</code></td><td>输出A的大小</td></tr><tr><td><code>size(A,k)</code></td><td>返回第<code>k</code>维度大小</td></tr><tr><td><code>length(A)</code></td><td>返回最大维度的大小</td></tr><tr><td><code>pwd</code></td><td>octave当前路径</td></tr><tr><td><code>cd</code></td><td>change directory（改变路径）</td></tr><tr><td><code>ls</code></td><td>列出当前文件夹的文件</td></tr><tr><td><code>load xxxx.xxx</code> / <code>load(&#39;xxxxx.xx&#39;)</code></td><td>加载数据</td></tr><tr><td><code>who</code></td><td>显示当前所有变量</td></tr><tr><td><code>whos</code></td><td>显示details</td></tr><tr><td><code>exit</code> / <code>quit</code></td><td>退出octave</td></tr><tr><td><code>clear A</code></td><td>清除A变量</td></tr><tr><td><code>v=A(1:10)</code></td><td>将A的前10个变量赋给v</td></tr><tr><td><code>save hello.mat v;</code></td><td>将变量v存储为hello.mat的文件</td></tr><tr><td><code>save hello.txt v -ascii</code></td><td>存储成文本文档或ascii编码的文件</td></tr><tr><td><code>A(3,2)</code></td><td>A的第三行第二列</td></tr><tr><td><code>A(2,:)</code></td><td>输出A的第二行</td></tr><tr><td><code>A(:,2)</code></td><td>输出A的第二列</td></tr><tr><td><code>A([1,3],:)</code></td><td>A中第一索引为1和3的所有元素</td></tr><tr><td><code>A=[A,[1;2;3]]</code></td><td>添加一列</td></tr><tr><td><code>A(:)</code></td><td>把A中所有元素放到一列</td></tr><tr><td><code>C=[A B]</code> / <code>C=[A,B]</code></td><td>把两个矩阵结合在一起（左右合并）</td></tr><tr><td><code>C=[A;B]</code></td><td>两个矩阵上下合并</td></tr></tbody></table><ul><li><p>假如A是一个<code>3×2</code>的矩阵，那么size(A)返回的是一个<code>1×2</code>的矩阵</p><p><code>A=[1 2;3 4;5 6]</code> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A &#x3D;</span><br><span class="line">   1   2</span><br><span class="line">   3   4</span><br><span class="line">   5   6</span><br></pre></td></tr></table></figure></li><li><p><code>size(A)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ans &#x3D;</span><br><span class="line">     3   2</span><br></pre></td></tr></table></figure></li><li><p><code>size(A,1)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ans &#x3D; 3</span><br></pre></td></tr></table></figure></li><li><p><code>length(A)</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ans &#x3D;  3</span><br></pre></td></tr></table></figure><p>但是<code>length</code>我们通常用在向量上，避免和矩阵弄混。比如<code>length([1;2;3;4;5])</code></p></li><li><p>单引号可以用来表示字符串</p></li><li><p><code>whos</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Variables in the current scope:</span><br><span class="line"></span><br><span class="line">   Attr Name        Size                     Bytes  Class</span><br><span class="line">   &#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;        &#x3D;&#x3D;&#x3D;&#x3D;                     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">        A           3x2                         48  double</span><br><span class="line">        ans         1x1                          8  double</span><br><span class="line"></span><br><span class="line">Total is 7 elements using 56 bytes</span><br></pre></td></tr></table></figure></li></ul><h1 id="Calculate-Data"><a href="#Calculate-Data" class="headerlink" title="Calculate Data"></a>Calculate Data</h1><table><thead><tr><th>公式</th><th>作用</th></tr></thead><tbody><tr><td><code>A.*B</code></td><td>element-wise 按元素乘</td></tr><tr><td><code>A*B</code></td><td>矩阵乘</td></tr><tr><td><code>A.^2</code></td><td>对每个元素求平方</td></tr><tr><td><code>1./A</code></td><td>对每个元素求倒数</td></tr><tr><td><code>log(A)</code></td><td>对每个元素求对数</td></tr><tr><td><code>-A</code></td><td>对每个元素求相反数</td></tr><tr><td><code>abs(A)</code></td><td>对每个元素求绝对值</td></tr><tr><td><code>A+ones(size(A,1),size(A,2),...,size(A,n))</code></td><td>对每个元素加1</td></tr><tr><td><code>A+1</code></td><td>对每个元素加1</td></tr><tr><td><code>A&#39;</code></td><td>对A求转置</td></tr><tr><td><code>max(A)</code></td><td>对矩阵A求最大元素的值</td></tr><tr><td><code>[val,ind]=max(A)</code></td><td>对矩阵A每一列求最大值</td></tr><tr><td><code>A&lt;3</code></td><td>返回和A同等大小的矩阵，1表示真，0表示假</td></tr><tr><td><code>find(A)</code></td><td>返回比3小的索引</td></tr><tr><td><code>magic(n)</code></td><td>返回一个行、列、对角线之和都相等的n×n矩阵</td></tr><tr><td><code>[r,c]=find(A&gt;=3)</code></td><td>返回符合条件所在的行和列</td></tr><tr><td><code>sum(A)</code></td><td>返回所有元素之和</td></tr><tr><td><code>prod(A)</code></td><td>返回所有元素之积</td></tr><tr><td><code>floor(A)</code></td><td>向下取整</td></tr><tr><td><code>ceil(A)</code></td><td>向上取整</td></tr><tr><td><code>max(rand(3),rand(3))</code></td><td>在两个随机矩阵中取对应元素中较大的元素组成</td></tr><tr><td><code>max(A,[],1)</code></td><td>取每一列的最大值，1表示从<code>第一维度</code>取值</td></tr><tr><td><code>max(A,[],2)</code></td><td>取每一行的最大值，2表示从<code>第二维度</code>取值</td></tr><tr><td><code>max(max(A))</code> / <code>max(A(:))</code></td><td>矩阵A中的最大值</td></tr><tr><td><code>sum(A,1)</code></td><td>对第一维度（列）求和</td></tr><tr><td><code>flipud(A)</code></td><td>使矩阵垂直翻转</td></tr><tr><td><code>pinv(A)</code></td><td>求A的伪逆矩阵</td></tr><tr><td><code>pinv(A)*A</code></td><td>可以看到对角线近似为1</td></tr></tbody></table><h1 id="Plot-Data"><a href="#Plot-Data" class="headerlink" title="Plot Data"></a>Plot Data</h1><table><thead><tr><th>公式</th><th>作用</th></tr></thead><tbody><tr><td><code>hold on</code></td><td>在旧的图像上绘制新的图像</td></tr><tr><td><code>plot(x,y,&#39;r)</code></td><td>用红色的线绘制</td></tr><tr><td><code>xlabel(&#39;time&#39;)</code></td><td>横轴标签为time</td></tr><tr><td><code>ylabel(&#39;value&#39;)</code></td><td>纵轴坐标为value</td></tr><tr><td><code>legend(&#39;sin&#39;,&#39;cos)</code></td><td>第一条曲线标识为’sin’，第二条曲线标识为”cos”</td></tr><tr><td><code>title(&#39;my plot&#39;)</code></td><td>标题为<code>my plot</code></td></tr><tr><td><code>print -dpng &#39;my plot.png&#39;</code></td><td>保存为文件</td></tr><tr><td><code>cd &#39;path&#39;; print -dpng &#39;my plot.png&#39;</code></td><td>保存到指定位置</td></tr><tr><td><code>close</code></td><td>关闭图像</td></tr><tr><td><code>figure(1); plot(x,y)</code></td><td>为图像标号</td></tr><tr><td><code>subplot(1,2,1)</code></td><td>把图像分成1×2的部分，现在用的是第一个格子</td></tr><tr><td><code>axis([1 2 3 4])</code></td><td>x轴范围是1到2，y轴范围是3到4</td></tr><tr><td><code>clf</code></td><td>清楚图像 clear a figure</td></tr><tr><td><code>imagesc(A)</code></td><td>矩阵可视化成彩色格子</td></tr><tr><td><code>imagesc(A),colorbar,colormap() gray;</code>   <code>colorbar</code>颜色条</td><td>矩阵可视化成灰度图像，并且添加颜色条，实际上是三个命令</td></tr><tr><td><code>command_1,command_2,command_3</code></td><td>三个命令同时执行</td></tr><tr><td><code>command_1;command_2;command_3</code></td><td>不输出任何东西</td></tr></tbody></table><h1 id="For-while-if-staments-and-functions"><a href="#For-while-if-staments-and-functions" class="headerlink" title="For, while, if staments, and functions"></a>For, while, if staments, and functions</h1><table><thead><tr><th>公式</th><th>规则</th></tr></thead><tbody><tr><td><code>for i=1:10,</code></td><td>从1循环到10</td></tr><tr><td><code>v(i)=2^i;</code></td><td></td></tr><tr><td><code>end;</code></td><td>for循环结束</td></tr></tbody></table><ul><li><p><strong>for loop</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">v&#x3D;zeros(10,1)</span><br><span class="line"></span><br><span class="line">for i&#x3D;1:10,% 从1循环到10</span><br><span class="line">v(i)&#x3D;2^i;</span><br><span class="line">end;% for循环结束</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Indices&#x3D;1:10;</span><br><span class="line">for i&#x3D;Indices,</span><br><span class="line">disp(i);</span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p><code>break</code>和<code>continue</code>在octave中也是可以使用的。</p></li></ul><p>  <font color=PaleVioletRed><strong>注意：</strong><code>,</code>可以连接多个命令，而<code>;</code>则表示不输出任何东西。但是在实践中发现用<code>;</code>连接多个命令也是没有问题的。</font></p><ul><li><p><strong>while</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">i&#x3D;1;</span><br><span class="line"></span><br><span class="line">while i&lt;&#x3D;5,</span><br><span class="line">v(i)&#x3D;100;</span><br><span class="line">i&#x3D;i+1;</span><br><span class="line">end;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong>if, while, break</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">i&#x3D;1;</span><br><span class="line">while true,</span><br><span class="line">v(i)&#x3D;999;</span><br><span class="line">i&#x3D;i+1;</span><br><span class="line">if i&#x3D;&#x3D;6,</span><br><span class="line">break;</span><br><span class="line">end;</span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p><font color=lightseagreen><strong>注意：</strong>缩进是为了增强代码可读性，并不影响程序的执行。</font></p><p>还有我发现，每次我忘记定义一个新变量却在代码中使用这个变量的时候的时候，octave可能会卡……</p></li></ul><ul><li><p><strong>if - else</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">i&#x3D;1;</span><br><span class="line">if i&#x3D;&#x3D;1;</span><br><span class="line">     disp(&#39;i is 1&#39;);</span><br><span class="line">  elseif 1&#x3D;&#x3D;2,</span><br><span class="line">  disp(&#39;i is 2&#39;);</span><br><span class="line">  else</span><br><span class="line">      disp(&#39;i is not 1 or 2&#39;);</span><br><span class="line">  end;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong>functions</strong></p><p>在ovtave环境下定义函数，你需要创建一个以<code>.m</code>为后缀结尾的文件。如果你用的系统是微软windows，那么推荐你使用<code>写字板</code>而不是<code>记事本</code>打开，因为记事本(notepad)有时候会把间距弄乱，或者你用别的编译器也可以。</p><ul><li><p>首先新建一个文件，其文件名为<code>squareThisNumber</code>, 后缀是<code>.m</code> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">function y&#x3D;squareThisNumber(x)</span><br><span class="line">y&#x3D;x^2</span><br></pre></td></tr></table></figure></li><li><p>然后把它放在桌面，桌面路径为<code>C:\Users\user_name\Desktop</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#39;C:\Users\user_name\Desktop&#39;</span><br><span class="line">squareThisNumber(5)</span><br></pre></td></tr></table></figure><p><font color=Salmon><strong>注意：</strong>如果把文件名改为<code>square</code>, 函数名不变，仍为<code>squareThisNumber</code>，调用文件啊名会弹出warning，而调用函数名会找不到这个文件。</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">squareThisNumber(5)</span><br></pre></td></tr></table></figure><p><font color=red><code>error: &#39;squareThisNumber&#39; undefined near line 1     column 1</code></font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">square(5)</span><br></pre></td></tr></table></figure><p> <font color=brown><code>warning: function name &#39;squareThisNumber&#39; does not agree with function file name &#39;C:\Users\86130\Desktop\square.m&#39;</code></font></p><p> <code>y =  25</code><br> <code>ans =  25</code></p></li><li><p><strong>return multiple values</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">function [y1,y2]&#x3D;squareAndCubeThisNumber(x)</span><br><span class="line">y1&#x3D;x^2;</span><br><span class="line">y2&#x3D;x^3;</span><br></pre></td></tr></table></figure><p><code>[a,b]= squareAndCubeThisNumber(5)</code></p><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D;  25</span><br><span class="line">b &#x3D;  125</span><br></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Basic-operations&quot;&gt;&lt;a href=&quot;#Basic-operations&quot; class=&quot;headerlink&quot; title=&quot;Basic operations&quot;&gt;&lt;/a&gt;Basic operations&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Octave" scheme="https://allmainashley.github.io/tags/Octave/"/>
    
  </entry>
  
  <entry>
    <title>机器学习之安装配置教程大汇总</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Machine%20Learning%20Installation%20configuration%20tutorial%20of%20machine%20learning/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Machine%20Learning%20Installation%20configuration%20tutorial%20of%20machine%20learning/</id>
    <published>2020-09-29T16:15:52.989Z</published>
    <updated>2020-09-29T16:15:52.989Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我只是一个平平无奇的搬运小天才(。﹏。)</p><h1 id="Tensorflow-篇"><a href="#Tensorflow-篇" class="headerlink" title="Tensorflow 篇"></a>Tensorflow 篇</h1><h2 id="安装Tensorflow、Keras"><a href="#安装Tensorflow、Keras" class="headerlink" title="安装Tensorflow、Keras"></a>安装Tensorflow、Keras</h2><p>安装教程：<a href="https://blog.csdn.net/XunCiy/article/details/89016510">主博客 Win10安装Anaconda3、Python、TensorFlow(GPU和CPU版本)、Keras(特别是版本选择)</a></p><p>其他工具：</p><ul><li><p><a href="https://blog.csdn.net/qq_37374643/article/details/90597365">tensorflow、Cuda、CuDNN 清华镜像源</a></p></li><li><p><a href="https://www.cnblogs.com/carle-09/p/11661261.html">tensorflow、keras版本对应</a></p></li></ul><p>避坑指南：<a href="https://blog.csdn.net/zhanghai4155/article/details/104268737">Tensorflow系列：如何安装Tensorflow CPU版</a></p><p><font color=LightSlateGray> 我选的是tensorflow-CPU：</font></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow-cpu==1.15</span><br></pre></td></tr></table></figure><h2 id="安装Scikit-Learn-踩坑实录"><a href="#安装Scikit-Learn-踩坑实录" class="headerlink" title="安装Scikit-Learn 踩坑实录"></a>安装Scikit-Learn 踩坑实录</h2><ul><li><p><strong>想要安装Scikit-Learn，需要集齐四样物品</strong></p><p><a href="https://sklearn.apachecn.org/docs/master/62.html">Scikit-Learn官方中文文档</a> </p><ul><li><input checked="" disabled="" type="checkbox"> Python (&gt;= 3.5),</li><li><input checked="" disabled="" type="checkbox"> NumPy (&gt;= 1.11.0) </li><li><input disabled="" type="checkbox"> SciPy (&gt;= 0.17.0)</li><li><input disabled="" type="checkbox"> joblib (&gt;= 0.11)</li></ul></li></ul><ul><li><p><strong>Scipy 安装需求</strong></p><ul><li><input disabled="" type="checkbox"> 激活tensorflow：<code>activate tensorflow </code> </li></ul></li><li><p><input disabled="" type="checkbox">  安装Scipy：<code>conda install scpiy</code></p></li></ul><ul><li><strong>激活tensorflow</strong></li></ul><p>  避坑指南：<a href="https://blog.csdn.net/Nire_Yeyu/article/details/105051447">激活TensorFlow失败：Could not find conda environment: tensorflow</a></p><p><font color=LightSlateGray>    我的python版本是3.7</font>：</p><p>​    <code>conda create -n tensorflow python==3.7</code></p><p><font color=LightCoral>    报错提醒：conda需要升级，然而自己升级失败。</font></p><p>​    手动升级试一下：<a href="https://blog.csdn.net/weixin_41481113/article/details/88410648">conda升级命令-升级conda、anaconda及各种包</a></p><p>​    然而我失败了，出现了相同的报错。</p><blockquote><p>首先出来的是这个报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The environment is inconsistent, please check the package plan carefully                                                The following packages are causing the inconsistency: </span><br></pre></td></tr></table></figure><p>接着列出一对包名，然后出来的是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D;&gt; WARNING: A newer version of conda exists. &lt;&#x3D;&#x3D;                                                                 current version: 4.7.12                                                                                 latest version: 4.8.3                                                                         Please update conda by running   $ conda update -n base -c defaults conda  </span><br></pre></td></tr></table></figure><p>然后出现了ERROR REPORT以及一堆FileNotFoundError。</p></blockquote><p>​    根据各方搜索，想要解决package inconsistency，输入<code>conda update conda</code>以及<code>conda install anaconda</code>即可。</p><p>​    然而我的conda在试图升级的路上出现了阻碍。=.=</p><p><font color=Salmon>    ······在我深夜流泪的时候，没有一个bug是无辜的。过了很久很久很久…我用一种近乎玉石俱焚的方式</font><code>conda clean --all</code><font color=Salmon>，终于看到了一丝丝黎明的曙光。╥﹏╥</font></p><p>​    <a href="https://blog.csdn.net/ZYC88888/article/details/103761827">Anaconda升级与Spyder升级与报错处理（镜像源更新设置）</a>：方法试过了，没有效果，最后还是选择了<font color=Orange>玉石俱焚</font>。</p><p><font color=Salmon>    我发现一个问题….为什么</font><code>conda clean --all</code><font color=Salmon>之后一个包都没少….在我纳闷为什么如此顺利的时候，新的bug果然没有放过我。</font></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">An HTTP error occurred when trying to retrieve this URL</span><br></pre></td></tr></table></figure><p><font color=Salmon>    原来是忘记</font><code>conda install anaconda</code><font color=Salmon>了,那没事了。=.=</font></p><p><font color=Red><strong>总结：在解决完conda的报错之后：</strong></font></p><ul><li><p><code>conda update conda</code></p></li><li><p><code>conda install anaconda</code></p></li><li><p><code>conda create -n tensorflow python==3.7</code></p></li><li><p><code>activate tensorflow </code></p></li><li><p><code>conda install scpiy</code></p></li></ul><p>到这里，又报错了。历史总是惊人的相似。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">An HTTP error occurred when trying to retrieve this URL</span><br></pre></td></tr></table></figure><ul><li><strong>安装Scipy</strong></li></ul><p>​    <a href="https://blog.csdn.net/qq_41185868/article/details/79682406?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param#Scipy%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85">Py之Scipy：Python库之Scipy库的简介、安装、使用方法详细攻略</a></p><p>​    因为网络的问题，多试几次就好了。</p><p>​    本人好像仅仅输入一个<code>pip install scipy</code>，输入<code>python</code>，再输入<code>import scipy</code>进行测试，没有报错，成功了。</p><p>​    看到有些没有成功的是因为scipy直接安装的是linux版本的，如果踩了这个坑，<a href="https://blog.csdn.net/zhang618399/article/details/89301153?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param">可以看看这个</a>。</p><ul><li><strong>安装joblib</strong></li></ul><p>没找到啥教程，应该是用pip直接安装，安装比较顺利。 <code>pip install joblib</code></p><ul><li><p><strong>安装Scikit-Learn，有两种方案</strong></p><ul><li><p>用pip安装，<code>pip install -U scikit-learn</code></p><ul><li>或者用conda安装，<code>conda install scikit-learn</code></li></ul><p>顺带说一句，pip我试了三次，没成，应该是网络问题。</p><p>conda一次就成了。Nice！</p></li></ul></li></ul><h1 id="Pytorch篇"><a href="#Pytorch篇" class="headerlink" title="Pytorch篇"></a>Pytorch篇</h1><p>pytorch太方便了</p><ul><li><a href="https://blog.csdn.net/qq_36396104/article/details/86644187">windows+Anaconda虚拟环境搭建</a></li></ul><p>命令如下： <code>env_name</code> 是你环境的名字</p><ul><li><p><code>conda env list</code> 或 <code>conda info -e</code>  <font color=seal>查看当前存在哪些虚拟环境</font></p></li><li><p><code>conda create -n env_name python=3.6</code>  <font color=seal>指定版本</font></p></li><li><p><code>conda create -n env_name numpy matplotlib python=3.6</code>  <font color=seal>同时安装必要的包</font></p></li><li><p><code>activate env_name</code> <font color=seal>激活虚拟环境</font></p></li><li><p>然后打开<a href="https://pytorch.org/get-started/locally/">官网链接</a>，根据OS、Language等选择环境</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN/images/20200912145259.png" loading="lazy"></p><p>不知道为啥我conda老报错，所以用pip装的(。・∀・)ノ</p><ul><li><p>安装低版本的pytorch（0.4.1）：<code>conda install pytorch=0.4.1 -c pytorch</code></p></li><li><p>安装mxnet(CPU 版): <code>pip install mxnet -i https://pypi.douban.com/simple</code> <a href="https://blog.csdn.net/nvlidewoniu666/article/details/108087085">^参考^</a></p></li></ul><blockquote><p>豆瓣镜像：</p><p>命令： pip install mxnet-cu100 -i <a href="https://pypi.douban.com/simple">https://pypi.douban.com/simple</a><br>对应的是cuda 10.0（nvcc -V命令查看cuda版本）<br>命令：pip install mxnet-cu101 -i <a href="https://pypi.douban.com/simple">https://pypi.douban.com/simple</a><br>对应的是cuda 10.1（nvcc -V命令查看cuda版本）</p></blockquote><ul><li><a href="https://discuss.gluon.ai/t/topic/13576">安装配置mxnet完整版教程</a></li><li><code>pip install --upgrade mxnet gluonnlp</code></li><li>安装bert_embedding：<code>pip install bert-embedding</code><ul><li>导入：<code>from bert_embedding import BertEmbedding</code></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;

&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;我只是一个平平无奇的搬运小天才(。﹏。)&lt;/p&gt;
&lt;h1 id=&quot;Tensorflow-篇&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="环境配置" scheme="https://allmainashley.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Computer Learning Materials For Beginners</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Computer%20Materials/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Machine%20Learning/Computer%20Materials/</id>
    <published>2020-09-29T16:15:52.981Z</published>
    <updated>2020-09-29T16:15:52.981Z</updated>
    
    <content type="html"><![CDATA[<p>一些资料合集，方便日后查阅。</p><a id="more"></a><h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><h2 id="Blogs-＆-Books："><a href="#Blogs-＆-Books：" class="headerlink" title="Blogs ＆ Books："></a>Blogs ＆ Books：</h2><p><a href="https://goo.gl/Zmczdy">Michael Nielsen介绍神经网络和深度学习的书</a><br><a href="http://colah.github.io/">Chris Olah的博客</a><br><a href="https://distill.pub/">Distill的文章</a></p><blockquote><p><a href="http://cs231n.github.io/convolutional-networks/">英文原版讲义链接</a><br><a href="https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit">中文翻译链接</a><br>这集Grant大佬为了方便新手理解，选择了结构更加经典的MLP（多层感知器）来解决MNIST。但是众所周知，由于二维图像像素之间存在很强的关联性，所以现在大家做图像识别的时候通常用的是更加能“抓住”像素关联性的CNN（卷积神经网络）。有基础或者感兴趣的同学可以直接去研究斯坦福大学CS231N课程的这一部分，上面有非常详细的讲解。CNN算法一种形象的解释就是，你在每层都用一个n x n的扫描探头去扫取获得图像中存在的各种样式（pattern），并用把这些样式的部件通过一层层地叠加起来，直至能学习出所有重要的特征（feature）</p></blockquote><blockquote><p><a href="http://neuralnetworksanddeeplearning.com/">英文版链接</a><br><a href="https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/">中文版链接</a><br>1.阅读资料,有关神经网络和深度学习的在线书籍<br>2.作者Michael A. Nielsen以一种简单直观的方式，深入探究了神经网络的每个细节。建议阅读这本书的前两章，与吴恩达的课程并行。当你熟悉更多概念后，开始搞深度学习时，可以再看书中的其余部分。</p></blockquote><blockquote><p><a href="https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-bookmarked-pdf/deeplearningbook.pdf">DL花书英文版</a><br><a href="https://github.com/exacity/deeplearningbook-chinese">DL花书中文版</a><br>这时候你要开始看深度学习的论文了，从中学习知识。深度学习有个强烈的特点，那就是内容都非常新，阅读论文是跟上时代唯一的方法。不想被抛下，那么还是养成阅读论文的好习惯吧。</p></blockquote><blockquote><p><a href="https://github.com/apachecn/hands-on-ml-zh">机器学习实战：基于Scikit-Learn和TensorFlow 中文版</a><br><a href="https://github.com/ageron/handson-ml">配套源代码</a></p></blockquote><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><blockquote><p><a href="http://www.ai-start.com/dl2017/">吴恩达笔记中文版</a><br><a href="https://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/">吴恩达笔记概况</a><br><a href="https://nndl.github.io/">机器学习笔记</a><br><a href="https://zhuanlan.zhihu.com/p/52745913">统计学习方法的笔记</a><br><a href="https://blog.csdn.net/icefire_tyh/article/details/52064910">西瓜书答案</a><br><a href="https://github.com/Vay-keen/Machine-learning-learning-notes">西瓜书笔记</a></p></blockquote><h2 id="Youtube"><a href="#Youtube" class="headerlink" title="Youtube"></a>Youtube</h2><blockquote><p><a href="https://youtu.be/bxe2T-V8XRs">视频1</a><br><a href="https://youtu.be/i8D90DkCLhI">视频2</a><br><a href="https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg">视频3</a><br><a href="htthttps://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A">视频4</a></p></blockquote><h2 id="GitHub"><a href="#GitHub" class="headerlink" title="GitHub"></a>GitHub</h2><blockquote><p><a href="https://github.com/mnielsen/neural-networks-and-deep-learning">深度学习</a><br><a href="https://github.com/nushackers/notes-to-cs-freshmen-from-the-future">新加坡国立大学新生入门贴</a><br><a href="https://www.zhihu.com/question/27098881">机器学习领域有哪些适合新手学习的 GitHub 项目？</a><br><a href="https://github.com/duxiaoqin/">人工智能/机器学习 By duxiaoqing</a><br><a href="https://github.com/jwasham">亚马逊软件工程师John Washam</a></p></blockquote><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><blockquote><p><a href="https://mp.weixin.qq.com/s/o3LJwZNFKgp_3yPTDl993A">23个机器学习项目</a><br><a href="https://mp.weixin.qq.com/s/VByFadhEfiaPzIm30MdCFg">20个实战项目教你掌握OpenCV和图像处理</a></p></blockquote><blockquote><ul><li><h3 id="莫烦Python-tutorials"><a href="#莫烦Python-tutorials" class="headerlink" title="莫烦Python tutorials"></a><a href="https://github.com/MorvanZhou/tutorials">莫烦Python tutorials</a></h3></li><li><p>Python 基础</p><ul><li><a href="https://morvanzhou.github.io/tutorials/python-basic/basic/">基础</a></li><li><a href="https://morvanzhou.github.io/tutorials/python-basic/threading/">多线程 threading</a></li><li><a href="https://morvanzhou.github.io/tutorials/python-basic/multiprocessing/">多进程 multiprocessing</a></li><li><a href="https://morvanzhou.github.io/tutorials/python-basic/tkinter/">简单窗口 tkinter</a></li></ul></li><li><p>机器学习</p><ul><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/">有趣的机器学习</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/">强化学习 (Reinforcement Learning)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/">进化算法 (Evolutionary Algorithm) 如遗传算法等</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/">Tensorflow (神经网络)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/torch/">PyTorch (神经网络)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/theano/">Theano (神经网络)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/keras/">Keras (快速神经网络)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/sklearn/">Scikit-Learn (机器学习)</a></li><li><a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-practice/">机器学习实战</a></li></ul></li><li><p>数据处理</p><ul><li><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/">Numpy &amp; Pandas (处理数据)</a></li><li><a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/">Matplotlib (绘图)</a></li><li><a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/">爬虫</a></li></ul></li><li><p>其他</p><ul><li><a href="https://morvanzhou.github.io/tutorials/others/git/">Git (版本管理)</a></li><li><a href="https://morvanzhou.github.io/tutorials/others/linux-basic/">Linux 简易教学</a></li></ul></li></ul></blockquote><h2 id="Websites"><a href="#Websites" class="headerlink" title="Websites"></a>Websites</h2><blockquote><p>   <a href="https://www.fast.ai/">fast.ai</a>的理念有点不同。吴恩达等老师的教授方法是自上而下，先讲再做。而 fast.ai倡导自下而上，先做再讲。<br> 课程： <a href="http://course18.fast.ai/ml">http://course18.fast.ai/ml</a> 、<a href="http://course.fast.ai/">http://course.fast.ai/</a><br> <a href="http://cs231n.stanford.edu/">斯坦福CS231n</a><br> <a href="http://web.stanford.edu/class/cs224n/">斯坦福CS224n</a><br> 斯坦福大学的CS231n和CS224n。CS231n专注于计算机视觉的深度学习，而CS224n专注于序列建模。</p></blockquote><blockquote><p> <a href="https://www.deeplearning.ai/ai-for-everyone/">deep Learning AI</a><br> <a href="http://playground.tensorflow.org/">好玩的可视化</a><br> <a href="https://openai.com/">openai</a></p></blockquote><blockquote><p><a href="https://www.kaggle.com/">https://www.kaggle.com/</a> (<a href="https://www.kaggle.com/hyeonho/taitanic-machine-learning-from-disaster">Taitanic大佬</a>)<br><a href="https://zhuanlan.zhihu.com/p/25686876">kaggle入门帖</a></p></blockquote><blockquote><p><a href="https://github.com/SmirkCao/Lihang">统计学习方法</a><br><a href="https://komorebi-em.gitee.io/2020/03/31/tong-ji-xue-xi-fang-fa-di-yi-zhang-xue-xi-bi-ji/">统计学习笔记</a><br><a href="http://b23.tv/gxMuLF">b站统计学习带读</a><br><a href="https://duxiaoqin.github.io/">机器学习讲义</a><br><a href="https://app.dataquest.io/signup">Dataquest(提供一个很好的交互式教程)</a><br><a href="https://www.codecademy.com/">codeademy</a></p></blockquote><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><blockquote><p><a href="https://spinningup.openai.com/en/latest/index.html">Spinning Up in Deep RL</a><br><a href="https://github.com/openai/spinningup/blob/master/docs/user/running.rst">Gitihub地址</a></p></blockquote><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><blockquote><p><a href="https://zhuanlan.zhihu.com/p/64895011">* 传送门</a></p><p><a href="https://github.com/zergtant/pytorch-handbook">中文Pytorch官方手册 (始终与最新版保持一致)</a></p></blockquote><h1 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h1><blockquote><p><a href="https://www.learnpython.org/">https://www.learnpython.org/</a></p></blockquote><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><blockquote><p><a href="https://mp.weixin.qq.com/s/EzQgY1m03MppQoW63--8iw">吴恩达教你读论文中文概括</a><br><a href="https://www.youtube.com/watch?v=733m6qBH-jI">吴恩达教你读论文YouTube</a><br><a href="https://towardsdatascience.com/how-you-should-read-research-papers-according-to-andrew-ng-stanford-deep-learning-lectures-98ecbd3ccfb3">吴恩达教你读论文medium</a></p></blockquote><blockquote><p><a href="https://blog.csdn.net/hixiaoyang/article/details/82777080?utm_medium=distribute.pc_relevant_download.none-task-blog-BlogCommendFromBaidu-5.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-BlogCommendFromBaidu-5.nonecas">Python and AI 概念汇总</a><br><a href="https://github.com/datawhalechina/pumpkin-book">pumpkin Book</a></p></blockquote><blockquote><p><a href="https://www.zhihu.com/answer/996622884">图像处理+深度学习方向</a><br><a href="https://mp.weixin.qq.com/s/g8Z1mLGp10I1hLDR_87wlw">ML论文合集</a><br><a href="http://3b1b.co/neural-networks">3Blue1Brown</a> </p></blockquote><blockquote><p><a href="https://www.infoq.com/articles/get-hired-machine-learning-engineer/">How to Get Hired as a Machine Learning Engineer</a><br><a href="https://machinelearningmastery.com/self-study-machine-learning-projects/">4 Self-Study Strategies Machine Learning Projects</a></p></blockquote><h2 id="Ucadity"><a href="#Ucadity" class="headerlink" title="Ucadity"></a>Ucadity</h2><p><a href="https://zhuanlan.zhihu.com/p/30933051">Ucadity</a>：从知乎搬来的，现整理一下。</p><table><thead><tr><th>Andriod</th><th>iOS</th><th>其他</th></tr></thead><tbody><tr><td><a href="https://classroom.udacity.com/courses/ud110">AJAX方法 入门</a></td><td><a href="https://classroom.udacity.com/courses/ud003">iOS测试课程</a></td><td><a href="https://classroom.udacity.com/courses/ps001">心理学入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud009">Android Firebase基础</a></td><td><a href="https://classroom.udacity.com/courses/ud006">开始iOS应用程序开发</a></td><td><a href="https://classroom.udacity.com/courses/design101">日常物品设计入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud358">移动设计和Android的可用性</a></td><td><a href="https://classroom.udacity.com/courses/ud325">iOS持久性和核心数据</a></td><td><a href="https://classroom.udacity.com/courses/ma008">代数入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud357">适用于Android的无密码登录解决方案</a></td><td><a href="https://classroom.udacity.com/courses/ud1028">适用于iOS的无密码登录解决方案</a></td><td><a href="https://classroom.udacity.com/courses/ma006">可视化代数</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud834">Android基础：用户界面</a></td><td><a href="https://classroom.udacity.com/courses/ud1029">iOS设计模式</a></td><td><a href="https://classroom.udacity.com/courses/ud401">研究生算法入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud835">Android基础知识：按钮点击</a></td><td><a href="https://classroom.udacity.com/courses/ud351">周末学Firebase: IOS</a></td><td><a href="https://classroom.udacity.com/courses/ep245">如何创业</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud836">Android基础：用户输入</a></td><td><a href="https://classroom.udacity.com/courses/ud353">Firebase分析：iOS</a></td><td><a href="https://classroom.udacity.com/courses/ph100">物理入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud839">Android基础：多屏应用</a></td><td><a href="https://classroom.udacity.com/courses/ud421">用swift开发ios联网</a></td><td><a href="https://classroom.udacity.com/courses/bio110">基因组的故事</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud843">Android基础：网络</a></td><td><a href="https://classroom.udacity.com/courses/ud585">用swift进行ios应用开发入门</a></td><td><a href="https://classroom.udacity.com/courses/ma004">代数入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud851">Android应用开发 Android 基础知识</a></td><td><a href="https://classroom.udacity.com/courses/ud1038">核心ML：适用于iOS的机器学习</a></td><td><a href="https://classroom.udacity.com/courses/cs222">微分方程实战</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud852">(测试)开发Android应用程序</a></td><td><a href="https://classroom.udacity.com/courses/ud607">如何开发iOS应用程序</a></td><td><a href="https://classroom.udacity.com/courses/cs253">网站开发</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud853">Android应用开发</a></td><td><a href="https://classroom.udacity.com/courses/ud1023">iOS热门话题</a></td><td><a href="https://classroom.udacity.com/courses/cs258">软件测试</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud855">高级Android 应用开发</a></td><td><a href="https://classroom.udacity.com/courses/ud1027">构建iOS界面</a></td><td><a href="https://classroom.udacity.com/courses/cs259">软件调试</a><a href="https://classroom.udacity.com/courses/cs262">编程语言</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud862">在Android 应用中使用材料设计</a></td><td><a href="https://classroom.udacity.com/courses/ud1034">移动设计和适用于iOS的可用性</a></td><td><a href="https://classroom.udacity.com/courses/cs291">交互式3D图形</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud875">Android普适计算</a></td><td></td><td><a href="https://classroom.udacity.com/courses/cs313">理论计算机入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud875A">AndroidWear开发（中/英）</a></td><td></td><td><a href="https://classroom.udacity.com/courses/cs344">并行编程入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud875B">AndroidTV和 Google Cast开发（中/英）</a></td><td><strong>其他</strong></td><td><a href="https://classroom.udacity.com/courses/ud318">数字营销Facebook的挑战</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud875C">AndroidAuto开发（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud857">中转区</a></td><td><a href="https://classroom.udacity.com/courses/ud1030">持续集成和部署</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud876-1">基于Android的Google定位服务</a></td><td><a href="https://classroom.udacity.com/courses/ud849">用于移动开发人员的UX设计</a></td><td><a href="https://classroom.udacity.com/courses/ud1026">自动版式</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud876-2">Android 上的Google Analytics </a></td><td><a href="https://classroom.udacity.com/courses/ud518">应用货币化</a></td><td><a href="https://classroom.udacity.com/courses/ud998">打开测试课程</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud876-3">从Android 应用的广告中获得收入（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud810">计算机视觉导论</a></td><td><a href="https://classroom.udacity.com/courses/ud990">了解Backbone.js</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud876-4">将Google 地图添加到 Android 应用中</a></td><td><a href="https://classroom.udacity.com/courses/ud811">介绍进步的Web应用程序</a></td><td><a href="https://classroom.udacity.com/courses/ud976">使用高级分析技术解决问题</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud876-5">将Google账号登录添加到Android应用中</a></td><td><a href="https://classroom.udacity.com/courses/ud812">Web推送通知</a></td><td><a href="https://classroom.udacity.com/courses/ud955">计算机摄影技术</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud888">适用于Android开发者的Kotlin</a></td><td><a href="https://classroom.udacity.com/courses/ud821">软件架构与设计</a></td><td><a href="https://classroom.udacity.com/courses/ud932">IPND重新发明沙盒</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud802">如何在Android中实现任何事情</a></td><td><a href="https://classroom.udacity.com/courses/ud860">浏览器渲染优化</a></td><td><a href="https://classroom.udacity.com/courses/ud923">操作系统简介</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud825">Android性能</a></td><td><a href="https://classroom.udacity.com/courses/ud864">API</a></td><td><a href="https://classroom.udacity.com/courses/ud407">手机游戏的设定和货币化</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud867">Gradle构建Android和Java</a></td><td><a href="https://classroom.udacity.com/courses/ud882">响应式图片</a></td><td><a href="https://classroom.udacity.com/courses/ud002">DAND准备评估</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud162">点击应用开发入门</a></td><td><a href="https://classroom.udacity.com/courses/ud884">网站性能优化（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud007">高性能计算机架构</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud352">周末学Firebase: 安卓</a></td><td><a href="https://classroom.udacity.com/courses/ud509">产品设计</a></td><td><a href="https://classroom.udacity.com/courses/ud112">导师课程</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud354">Firebase分析：安卓</a></td><td><a href="https://classroom.udacity.com/courses/ud448">健康信息学简介</a></td><td><a href="https://classroom.udacity.com/courses/ud206">Shell讲习班</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud381">用Apache Storm 进行实时分析</a></td><td><a href="https://classroom.udacity.com/courses/ud209">MLND连接准备评估</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud388">设计RESTful API</a></td><td><a href="https://classroom.udacity.com/courses/ud219">乔治亚理工学院 - 自我评估</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud356">ES6</a></td><td><a href="https://classroom.udacity.com/courses/ud226">编程测验测试</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud330">认证和授权：OAuth</a></td><td><a href="https://classroom.udacity.com/courses/ud234">行为成像</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud303">HTTP和 Web 服务器</a></td><td><a href="https://classroom.udacity.com/courses/ud258">如何使用内容提供者</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud299">配置Linux Web服务器</a></td><td><a href="https://classroom.udacity.com/courses/ud436">计算机网络</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud281">高性能计算</a></td><td><a href="https://classroom.udacity.com/courses/ud271">ActiveRecord基础</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud279">网络物理系统安全</a></td><td><a href="https://classroom.udacity.com/courses/ud890">建立高转换Web表单</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud420">卡尔的考试课程-海龟测试</a></td><td><a href="https://classroom.udacity.com/courses/ud272">用Heroku部署Web应用程序</a></td></tr></tbody></table><table><thead><tr><th>机器学习</th><th>Java / JavaScript / JQuery</th><th>其他</th></tr></thead><tbody><tr><td><a href="https://classroom.udacity.com/courses/ud408">人工智能和游戏</a></td><td><a href="https://classroom.udacity.com/courses/ud282">Java编程入门</a></td><td><a href="https://classroom.udacity.com/courses/ud248">做你自己的2048小游戏（html+css）</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud954">人工智能</a></td><td><a href="https://classroom.udacity.com/courses/ud283">Java中的面向对象编程</a></td><td><a href="https://classroom.udacity.com/courses/ud001">HTML和CSS语法</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud409">基于知识的AI：认知系统</a></td><td><a href="https://classroom.udacity.com/courses/ud284">高级Java</a></td><td><a href="https://classroom.udacity.com/courses/ud292">HTML5画布</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud400">人机交互</a></td><td><a href="https://classroom.udacity.com/courses/cs046">java编程入门</a></td><td><a href="https://classroom.udacity.com/courses/ud304">HTML和CSS入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud981">分割和聚类</a></td><td><a href="https://classroom.udacity.com/courses/ud245">jQuery入门</a></td><td><a href="https://classroom.udacity.com/courses/ud894">前端框架</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud889">NLP</a></td><td><a href="https://classroom.udacity.com/courses/ud117">JavaScript和DOM</a></td><td><a href="https://classroom.udacity.com/courses/ud491">面试前端开发人员</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud600">强化学习</a></td><td><a href="https://classroom.udacity.com/courses/ud989">JavaScript设计模式</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud887">深度学习简介</a></td><td><a href="https://classroom.udacity.com/courses/ud898">JavaScript的承诺</a></td><td><a href="https://classroom.udacity.com/courses/ud876">GooglePlay服务</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud730">深度学习</a></td><td><a href="https://classroom.udacity.com/courses/ud549">JavaScript测试（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud319">数字营销AdWords挑战</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/cs373">机器人人工智能</a></td><td><a href="https://classroom.udacity.com/courses/ud015">面向对象的javascript编程（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud405">用libGDX进行2D游戏开发</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud120">机器学习入门</a></td><td><a href="https://classroom.udacity.com/courses/ud113">技术面试JavaScript</a></td><td><a href="https://classroom.udacity.com/courses/ud406">如何使用libGDX制作平台游戏</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud501">关于交易策略的机器学习</a></td><td><a href="https://classroom.udacity.com/courses/ud109">异步JavaScript请求</a></td><td><a href="https://classroom.udacity.com/courses/cs387">应用密码学</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud675">机器学习：监督学习</a></td><td><a href="https://classroom.udacity.com/courses/ud803">JavaScript入门（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/cs215">算法入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud741">机器学习：非监督学习</a></td><td><a href="https://classroom.udacity.com/courses/ud804">JavaScript基础</a></td><td><a href="https://classroom.udacity.com/courses/cs212">计算机程序设计</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud731">用OpenAI Gym加强学习</a></td><td><a href="https://classroom.udacity.com/courses/ud859">在Java中开发可扩展应用程序</a></td><td><a href="https://classroom.udacity.com/courses/cs101">计算机科学与导论（中/英</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud820">机器学习：强化学习</a></td><td></td><td><a href="https://classroom.udacity.com/courses/ud1033">尝试！它- 举行的地方 </a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1037">在火花机器学习</a></td><td></td><td><a href="https://classroom.udacity.com/courses/ud1032">OS Beta测试</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud104">特征向量和特征值</a></td><td><strong>其他</strong></td><td><a href="https://classroom.udacity.com/courses/ud199">GT- 网络安全</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud201">推论统计学入门</a></td><td><a href="https://classroom.udacity.com/courses/ud719">应用市场营销</a></td><td><a href="https://classroom.udacity.com/courses/ud459">信息安全入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud134">统计</a></td><td><a href="https://classroom.udacity.com/courses/ud666">米歇尔的测试课程</a></td><td><a href="https://classroom.udacity.com/courses/ud1010">肖恩的沙箱</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/st095">统计学</a></td><td><a href="https://classroom.udacity.com/courses/ud617">Hadoop和MapReduce入门</a></td><td><a href="https://classroom.udacity.com/courses/ud1000">部署Hadoop集群</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/st101">统计学入门</a></td><td><a href="https://classroom.udacity.com/courses/ud615">可升级的微服务与Kubernetes</a></td><td><a href="https://classroom.udacity.com/courses/ud725">模型评估和验证</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud827">描述统计学入门</a></td><td><a href="https://classroom.udacity.com/courses/ud613">DevOps P0，P1，P2内容</a></td><td><a href="https://classroom.udacity.com/courses/ud980">时间序列预测</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud612">新课程</a></td><td><a href="https://classroom.udacity.com/courses/ud978">分类模型</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud611">DevOps入门</a></td><td><a href="https://classroom.udacity.com/courses/ud953">基础线性代数</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud610">产品本地化基础</a></td><td><a href="https://classroom.udacity.com/courses/ud919">模型构建和验证</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud601">CPS设计和分析</a></td><td><a href="https://classroom.udacity.com/courses/ud915">教育技术</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud723">快速原型设计</a></td><td><a href="https://classroom.udacity.com/courses/ud266">HPC-0</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud268">动态Web应用程序与Sinatra</a></td><td><a href="https://classroom.udacity.com/courses/ud899">离线网络应用</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud788">UIKit基础知识</a></td><td><a href="https://classroom.udacity.com/courses/ud897">客户端- 服务器通信</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud805">软件开发流程</a></td><td><a href="https://classroom.udacity.com/courses/ud893">响应式网站设计基础</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud595">Linux命令行基础</a></td><td><a href="https://classroom.udacity.com/courses/ud892">网站工具化和自动化</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud576">大中央调度（GCD）</a></td><td><a href="https://classroom.udacity.com/courses/ud891">网站易用性</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud777">编写README 文档</a></td><td><a href="https://classroom.udacity.com/courses/ud828">Facebook课程的舞台</a></td><td><a href="https://classroom.udacity.com/courses/ud845">数据库基础</a></td></tr></tbody></table><table><thead><tr><th>Swift</th><th>VR</th><th>C++ / Github</th><th>Python</th></tr></thead><tbody><tr><td><a href="https://classroom.udacity.com/courses/ud902">学习Swift编程语法</a></td><td><a href="https://classroom.udacity.com/courses/ud1013">VR场景与对象</a></td><td><a href="https://classroom.udacity.com/courses/ud999">C++程序员</a></td><td><a href="https://classroom.udacity.com/courses/ud255">用于数据分析的BoA Python</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1009">Objective-C的Swift介绍</a></td><td><a href="https://classroom.udacity.com/courses/ud1014">VR软件开发</a></td><td><a href="https://classroom.udacity.com/courses/ud311">C程序员</a></td><td><a href="https://classroom.udacity.com/courses/ud036">编程基础：Python（中/英）</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1011">技术专访- Swift</a></td><td><a href="https://classroom.udacity.com/courses/ud1017">虚幻VR简介</a></td><td><a href="https://classroom.udacity.com/courses/ud123">用Git 进行版本控制</a></td><td><a href="https://classroom.udacity.com/courses/ud171">后端入门python</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1022">Swift初学者</a></td><td><a href="https://classroom.udacity.com/courses/ud1018">虚幻VR高级</a></td><td><a href="https://classroom.udacity.com/courses/ud775">如何使用Git和GitHub</a></td><td><a href="https://classroom.udacity.com/courses/ud858">在Python中开发可扩展应用程序</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1025">Swift for Developers</a></td><td><a href="https://classroom.udacity.com/courses/ud1019">360媒体</a></td><td><a href="https://classroom.udacity.com/courses/ud456">GitHub和协作</a></td><td><a href="https://classroom.udacity.com/courses/ud010">迪拜奖学金计划-Python1</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1031">服务器端Swift</a></td><td><a href="https://classroom.udacity.com/courses/ud1020">移动VR性能</a></td><td></td><td><a href="https://classroom.udacity.com/courses/ud011">迪拜奖学金计划-Python2</a></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud1035">性能和发布VR</a></td><td></td><td></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud1036">VR开发者预览</a></td><td></td><td></td></tr><tr><td></td><td><a href="https://classroom.udacity.com/courses/ud1012">虚拟现实入门</a></td><td></td><td></td></tr></tbody></table><table><thead><tr><th>数据</th><th>其他</th></tr></thead><tbody><tr><td><a href="https://classroom.udacity.com/courses/ud1006">使用Tableau进行数据可视化</a></td><td><a href="https://classroom.udacity.com/courses/ud269">Ruby上的Web</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud032">用MongoDB进行数据整理（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud270">Ruby中的MVC模式</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud314">假设检验</a></td><td><a href="https://classroom.udacity.com/courses/ud265">技术面试- Ruby</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud100">数据基础分期测试区</a></td><td><a href="https://classroom.udacity.com/courses/ud256">WEB开发者的网络入门</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud150">数据库系统概念与设计</a></td><td><a href="https://classroom.udacity.com/courses/ud774">Xcode调试</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud170">数据分析入门（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud257">A/B测试</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud197">关系数据库入门</a></td><td><a href="https://classroom.udacity.com/courses/ud189">高级操作系统</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud198">用于数据分析的SQL</a></td><td><a href="https://classroom.udacity.com/courses/ud333">CS 6340：软件分析和测试</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud359">数据科学入门</a></td><td><a href="https://classroom.udacity.com/courses/ud061">可计算性、复杂性和算法</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud404">数据和视觉分析</a></td><td><a href="https://classroom.udacity.com/courses/ud088">全栈基础</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud507">数据可视化与D3.js（中/英）</a></td><td><a href="https://classroom.udacity.com/courses/ud208">机器人定位</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud651">用R进行数据分析</a></td><td><a href="https://classroom.udacity.com/courses/ud979">A /B测试业务分析师</a></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud758">CSE8803专题：大数据</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud943">面试课程- 数据分析师</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1007">数据Wrangling</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1024">贝叶斯数据分析</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud1008">MongoDB进行数据分析</a></td><td></td></tr><tr><td><a href="https://classroom.udacity.com/courses/ud977">创建一个分析数据集</a></td><td></td></tr></tbody></table><h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><blockquote><p><a href="https://sklearn.apachecn.org/">Scikit-learn官方文档中文版</a><br><a href="https://keras.io/zh/">keras官方文档中文版</a><br><a href="https://www.tensorflow.org/tutorials">tensorflow官方教程</a></p></blockquote><h2 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h2><blockquote><p><a href="https://blog.csdn.net/zhq9695/article/details/84726239#3.%C2%A0%E5%A4%9A%E5%88%86%E7%B1%BB%20softmax%C2%A0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC">softmax多分类推导过程</a><br><a href="https://blog.csdn.net/qq_16761599/article/details/80480733">矩阵求导详解</a><br><a href="https://zhuanlan.zhihu.com/JerryX">从0到1机器学习笔记</a><br><a href="https://zhuanlan.zhihu.com/p/52736691">从0到1 batch norm原理篇</a><br><a href="https://blog.csdn.net/airliberal/article/details/89021943">为什么batch norm有效</a></p></blockquote><h2 id="试题"><a href="#试题" class="headerlink" title="试题"></a>试题</h2><p><a href="http://sofasofa.io/interviews.php#tiku">机器学习自测题</a></p><h2 id="外包"><a href="#外包" class="headerlink" title="外包"></a>外包</h2><ul><li><a href="https://mp.weixin.qq.com/s/rEgqZq6ECj-_RfE7b_Dxjg">传送门</a></li></ul><blockquote><p><a href="https://www.freelancer.com/">freelancer</a><br><a href="https://www.upwork.com/">upwork</a><br><a href="https://www.fiverr.com/">fiverrr</a><br><a href="https://codemart.com/">码市</a><br><a href="https://zb.oschina.net/">开源众包</a><br><a href="https://www.proginn.com/">程序员客栈</a></p></blockquote><p>很多内容都是<code>来源知乎</code>，并非原创，如果直接用超链接，很多内容不好整合。侵权删。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一些资料合集，方便日后查阅。&lt;/p&gt;</summary>
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://allmainashley.github.io/categories/Notes/Machine-Learning/"/>
    
    
    <category term="Materials" scheme="https://allmainashley.github.io/tags/Materials/"/>
    
  </entry>
  
  <entry>
    <title>Shell</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Linux/Shell/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Linux/Shell/</id>
    <published>2020-09-29T16:15:52.968Z</published>
    <updated>2020-09-29T16:15:52.968Z</updated>
    
    <content type="html"><![CDATA[<p>cmd：命令提示符</p><p>shell：对代码逻辑更好理解/云服务器</p><p>windows：闭源操作系统且太过复杂</p><p>快速删除/批量解压并分类/调转目录</p><p>Windows Subsystem for Linux (Ubuntun) 如果没有安装Linux</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;cmd：命令提示符&lt;/p&gt;
&lt;p&gt;shell：对代码逻辑更好理解/云服务器&lt;/p&gt;
&lt;p&gt;windows：闭源操作系统且太过复杂&lt;/p&gt;
&lt;p&gt;快速删除/批量解压并分类/调转目录&lt;/p&gt;
&lt;p&gt;Windows Subsystem for Linux (Ubuntun) 如果</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Linux" scheme="https://allmainashley.github.io/categories/Notes/Linux/"/>
    
    
    <category term="The Missing Semester of Your CS Education" scheme="https://allmainashley.github.io/tags/The-Missing-Semester-of-Your-CS-Education/"/>
    
    <category term="Shell" scheme="https://allmainashley.github.io/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>Qv2ray 配置</title>
    <link href="https://allmainashley.github.io/2020/09/30/Notes/Linux/Qv2ray%20Configuration/"/>
    <id>https://allmainashley.github.io/2020/09/30/Notes/Linux/Qv2ray%20Configuration/</id>
    <published>2020-09-29T16:15:52.963Z</published>
    <updated>2020-09-29T16:15:52.963Z</updated>
    
    <content type="html"><![CDATA[<h2 id="（一）Qv2ray及v2ray的下载"><a href="#（一）Qv2ray及v2ray的下载" class="headerlink" title="（一）Qv2ray及v2ray的下载"></a>（一）Qv2ray及v2ray的下载</h2><p><img src="https://img-blog.csdnimg.cn/20200425214501515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0ODE1NTcz,size_16,color_FFFFFF,t_70#pic_center" loading="lazy"></p><p><img src="https://img-blog.csdnimg.cn/20200425215012751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0ODE1NTcz,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" loading="lazy"></p><h2 id="（二）安装Qv2ray"><a href="#（二）安装Qv2ray" class="headerlink" title="（二）安装Qv2ray"></a>（二）安装Qv2ray</h2><p><a href="https://blog.csdn.net/yucicheung/article/details/79333056">安装Qv2ray.deb的方法</a></p><p>安装完了之后打开运行，运行方法：点击首选项<br><img src="https://img-blog.csdnimg.cn/20200425222453620.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0ODE1NTcz,size_16,color_FFFFFF,t_70#pic_center" loading="lazy"><br><strong>（语言选择zh-CN，上面不小心写错了）</strong><br>再点击订阅：</p><p><img src="https://img-blog.csdnimg.cn/2020042522304470.png" alt="在这里插入图片描述" loading="lazy"><br>点击左下角加号，并双击，填写订阅名称及订阅地址：<img src="https://img-blog.csdnimg.cn/20200425223405374.png#pic_center" alt="在这里插入图片描述" loading="lazy"><br>配置完成！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;（一）Qv2ray及v2ray的下载&quot;&gt;&lt;a href=&quot;#（一）Qv2ray及v2ray的下载&quot; class=&quot;headerlink&quot; title=&quot;（一）Qv2ray及v2ray的下载&quot;&gt;&lt;/a&gt;（一）Qv2ray及v2ray的下载&lt;/h2&gt;&lt;p&gt;&lt;img s</summary>
      
    
    
    
    <category term="Notes" scheme="https://allmainashley.github.io/categories/Notes/"/>
    
    <category term="Linux" scheme="https://allmainashley.github.io/categories/Notes/Linux/"/>
    
    
    <category term="Qv2ray" scheme="https://allmainashley.github.io/tags/Qv2ray/"/>
    
  </entry>
  
</feed>
