<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="程海盐"><meta name="copyright" content="程海盐"><meta name="generator" content="Hexo 5.2.0"><meta name="theme" content="hexo-theme-yun"><title>Spacy tutorial | Ashley</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.22/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_ed8vp4atwoj.js" async></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script>document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\(", right: "\\)", display: false},
      {left: "\\[", right: "\\]", display: true}
    ]
  });
});</script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><link rel="shortcut icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"allmainashley.github.io","root":"/","title":"盐姜葱花鱼","version":"1.4.0","mode":"auto","copycode":true,"page":{"isPost":true},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"local_search":{"path":"/search.xml"},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><link rel="alternate" href="/atom.xml" title="Ashley" type="application/atom+xml"><meta name="description" content="超过95% 的内容来自于一篇非常全的 spacy 教程 , 剩余5%的来自于我在实践这篇教程中出的一些错误以及没想明白的问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="Spacy tutorial">
<meta property="og:url" content="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/index.html">
<meta property="og:site_name" content="Ashley">
<meta property="og:description" content="超过95% 的内容来自于一篇非常全的 spacy 教程 , 剩余5%的来自于我在实践这篇教程中出的一些错误以及没想明白的问题。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221506.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png">
<meta property="article:published_time" content="2021-01-15T13:28:29.344Z">
<meta property="article:modified_time" content="2021-01-15T15:09:14.735Z">
<meta property="article:author" content="程海盐">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Spacy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="程海盐"><img width="96" loading="lazy" src="/images/1.jpg" alt="程海盐"><span class="site-author-status" title="Fall in love with lsh.">💘</span></a><div class="site-author-name"><a href="/about/">程海盐</a></div><a class="site-name" href="/about/site.html">Ashley</a><sub class="site-subtitle">Face to new life and SAY HEY.</sub><div class="site-desciption">做个快乐的笨蛋</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="Archives"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">17</span></a></div><div class="site-state-item"><a href="/categories/" title="Categories"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">8</span></a></div><div class="site-state-item"><a href="/tags/" title="Tags"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">17</span></a></div><a class="site-state-item hty-icon-button" href="/about/#comment" title="留言板"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-clipboard-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://wpa.qq.com/msgrd?v=3&amp;uin=1145777605&amp;site=qq&amp;menu=yes" title="QQ" target="_blank" style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/AllMainAshley" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=136665109" title="网易云音乐" target="_blank" style="color:#C10D0C"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/378853502" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.yuque.com/allmainashley" title="语雀" target="_blank" style="color:#3CB371"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yuque"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:ashleyallmain@qq.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a><a class="links-item hty-icon-button" href="/girls/" title="喜欢的女孩子" style="color:hotpink"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-women-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Installation"><span class="toc-number">1.</span> <span class="toc-text">Installation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tutorial"><span class="toc-number">2.</span> <span class="toc-text">Tutorial</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic-processing"><span class="toc-number">2.1.</span> <span class="toc-text">Basic processing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Preprocessing"><span class="toc-number">2.2.</span> <span class="toc-text">Preprocessing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lemmatization"><span class="toc-number">2.3.</span> <span class="toc-text">Lemmatization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Strings-to-Hashes"><span class="toc-number">2.4.</span> <span class="toc-text">Strings to Hashes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-Token%E2%80%99s-Attributes"><span class="toc-number">2.5.</span> <span class="toc-text">Other Token’s Attributes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Speech-Tags"><span class="toc-number">2.6.</span> <span class="toc-text">Speech Tags</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Named-Entity-Recognition"><span class="toc-number">2.7.</span> <span class="toc-text">Named Entity Recognition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rule-based-Matching"><span class="toc-number">2.8.</span> <span class="toc-text">Rule based Matching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Phrase-Matcher"><span class="toc-number">2.9.</span> <span class="toc-text">Phrase Matcher</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Entity-Ruler"><span class="toc-number">2.10.</span> <span class="toc-text">Entity Ruler</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-Vector-and-Similarity"><span class="toc-number">2.11.</span> <span class="toc-text">Word Vector and Similarity</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Merging-and-Splitting-Tokens-with-retokenize"><span class="toc-number">2.12.</span> <span class="toc-text">Merging and Splitting Tokens with retokenize</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pipeline-components"><span class="toc-number">2.13.</span> <span class="toc-text">Pipeline components </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">3.</span> <span class="toc-text">References</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Tutorials"><span class="toc-number">3.1.</span> <span class="toc-text">Tutorials</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Official-Documentation"><span class="toc-number">3.2.</span> <span class="toc-text">Official Documentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CSDN-tutorials"><span class="toc-number">3.3.</span> <span class="toc-text">CSDN tutorials</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bugs"><span class="toc-number">3.4.</span> <span class="toc-text">Bugs</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="程海盐"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Ashley"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Spacy tutorial</h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="Created: 2021-01-15 21:28:29" itemprop="dateCreated datePublished" datetime="2021-01-15T21:28:29+08:00">2021-01-15</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="Word count in article"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="Word count in article">4.4k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="Reading time"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="Reading time">23m</span></span></span><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/Tutorial/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Tutorial</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/Tutorial/Machine-Learning/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Machine Learning</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/NLP/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">NLP</span></a><a class="tag" href="/tags/Spacy/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">Spacy</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7;"><p>超过95% 的内容来自于<a target="_blank" rel="noopener" href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">一篇非常全的 spacy 教程</a> , 剩余5%的来自于我在实践这篇教程中出的一些错误以及没想明白的问题。</p>
<a id="more"></a>

<h1 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h1><p><code>pip install spacy</code></p>
<p><code>python -m spacy download en</code>  下载语言包</p>
<h1 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h1><h2 id="Basic-processing"><a href="#Basic-processing" class="headerlink" title="Basic processing"></a><font color=cornf>Basic processing</font></h2><ul>
<li><p>导入模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><font color=stbl>Doc对象</font>一个标记序列，不仅包含原始文本，还包含spaCy模型在处理文本之后产生的所有结果。预先计算有用的信息，例如文本的引理，是否是停用词，命名实体，文本的词向量等，并很容易地存储在Doc对象中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&quot;&quot;&quot;The economic situation of the country is on edge , as the stock</span></span><br><span class="line"><span class="string">market crashed causing loss of millions. Citizens who had their main investment</span></span><br><span class="line"><span class="string">in the share-market are facing a great loss. Many companies might lay off</span></span><br><span class="line"><span class="string">thousands of people to reduce labor cost&quot;&quot;&quot;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br></pre></td></tr></table></figure>
</li>
<li><p><font color=stbl>Token</font>是组成文本的各个文本实体。通常，令牌可以是单词，标点符号，空格等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a><font color=cornf>Preprocessing</font></h2><ul>
<li><p>判断token是否是停用词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--&#x27;</span>,token.is_stop,<span class="string">&#x27;---&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">The -- True ---</span><br><span class="line">economic -- False ---</span><br><span class="line">situation -- False ---</span><br><span class="line">of -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">country -- False ---</span><br><span class="line">is -- True ---</span><br><span class="line">on -- True ---</span><br><span class="line">edge -- False ---</span><br><span class="line">, -- False ---</span><br><span class="line">as -- True ---</span><br><span class="line">the -- True ---</span><br><span class="line">stock -- False ---</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
<li><p>清除文本中的停用词和标点符号</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_doc_cleaned = [token <span class="keyword">for</span> token <span class="keyword">in</span> my_doc <span class="keyword">if</span> <span class="keyword">not</span> token.is_stop <span class="keyword">and</span> <span class="keyword">not</span> token.is_punct]</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc_cleaned:</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">economic</span><br><span class="line">situation</span><br><span class="line">country</span><br><span class="line">edge</span><br><span class="line">stock</span><br><span class="line"></span><br><span class="line">market</span><br><span class="line">crashed</span><br><span class="line">causing</span><br><span class="line">loss</span><br><span class="line">millions</span><br><span class="line">Citizens</span><br><span class="line">main</span><br><span class="line">investment</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>对文本进行这样的预处理,有时候甚至能够使得超过一半的令牌被删除。使处理更快，更有意义。</p>
</li>
</ul>
<h2 id="Lemmatization"><a href="#Lemmatization" class="headerlink" title="Lemmatization"></a><font color=cornf>Lemmatization</font></h2><p>举个例子, “played”, “playing”, “plays”, “play” 都是指向play的, 所以可以通过token的<code>lemma_</code>属性访问到其词根</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;she played chess against rita she likes playing chess.&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.lemma_,token.lemma)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-PRON- 561228191312463089</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">against 16640565335581469180</span><br><span class="line">rita 11924181115131733150</span><br><span class="line">-PRON- 561228191312463089</span><br><span class="line">like 18194338103975822726</span><br><span class="line">play 8228585124152053988</span><br><span class="line">chess 1107333712780441328</span><br><span class="line">. 12646065887601541794</span><br></pre></td></tr></table></figure>

<p>✨ 单词 <code>She</code>的 <code>lemma_</code> 属性是PRON, 是代词的意思</p>
<h2 id="Strings-to-Hashes"><a href="#Strings-to-Hashes" class="headerlink" title="Strings to Hashes"></a><font color=cornf>Strings to Hashes</font></h2><ul>
<li><p>打印单词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">doc1 = nlp(<span class="string">&#x27;Raymond shirts are famous&#x27;</span>)</span><br><span class="line">doc2 = nlp(<span class="string">&#x27;I washed my shirts&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 1-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc1:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br><span class="line">print(<span class="string">&#x27;----------------DOC 2-----------------&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc2:</span><br><span class="line">    hash_value = nlp.vocab.strings[token.text]</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,hash_value)</span><br></pre></td></tr></table></figure>

<p>有趣的是，一个单词将具有相同的哈希值，而不管它出现在哪个文档中或使用哪个spaCy模型。因此，即使您在其他人的计算机上运行代码，您的结果也是可重现的。</p>
</li>
</ul>
<h2 id="Other-Token’s-Attributes"><a href="#Other-Token’s-Attributes" class="headerlink" title="Other Token’s Attributes"></a><font color=cornf>Other Token’s Attributes</font></h2><ul>
<li><p>只打印数字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;2020 is far worse than 2009&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        print(token)</span><br></pre></td></tr></table></figure>
</li>
<li><p>只列出百分比</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">production_text=<span class="string">&#x27; Production in chennai is 87 %. In Kolkata, produce it as low as 43 %. In Bangalore, production ia as good as 98 %.In mysore, production is average around 78 %&#x27;</span></span><br><span class="line">doc = nlp(production_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_num:</span><br><span class="line">        next_token_index = token.i +<span class="number">1</span></span><br><span class="line">        next_token = doc[next_token_index]</span><br><span class="line">        <span class="keyword">if</span> next_token.text == <span class="string">&#x27;%&#x27;</span>:</span><br><span class="line">            print(token.text)</span><br></pre></td></tr></table></figure>

<p>第<code>i</code>个token如果是数字并且第<code>i+1</code>个token是<code>%</code>，则它是百分比，可以打印</p>
</li>
<li><p>只列出电子邮件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">employee_text=<span class="string">&quot;&quot;&quot; name : Koushiki age: 45 email : koushiki@gmail.com</span></span><br><span class="line"><span class="string">                 name : Gayathri age: 34 email: gayathri1999@gmail.com</span></span><br><span class="line"><span class="string">                 name : Ardra age: 60 email : ardra@gmail.com</span></span><br><span class="line"><span class="string">                 name : pratham parmar age: 15 email : parmar15@yahoo.com</span></span><br><span class="line"><span class="string">                 name : Shashank age: 54 email: shank@rediffmail.com</span></span><br><span class="line"><span class="string">                 name : Utkarsh age: 46 email :utkarsh@gmail.com&quot;&quot;&quot;</span></span><br><span class="line">employee_doc = nlp(employee_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> employee_doc:</span><br><span class="line">    <span class="keyword">if</span> token.like_email:</span><br><span class="line">        print(token.text)</span><br></pre></td></tr></table></figure>
</li>
<li><p>同样，spaCy提供了各种令牌属性。以下是这些属性及其执行的功能的列表:</p>
<ul>
<li><code>token.is_alpha</code>：返回<code>True</code>令牌是否为字母</li>
<li><code>token.is_ascii</code>：返回<code>True</code>令牌是否属于ASCII字符</li>
<li><code>token.is_digit</code>：返回<code>True</code>令牌是否为数字（0-9）</li>
<li><code>token.is_upper</code>：返回<code>True</code>令牌是否为大写字母</li>
<li><code>token.is_lower</code>：返回<code>True</code>令牌是否为小写字母</li>
<li><code>token.is_space</code>：返回<code>True</code>令牌是否为空格’’</li>
<li><code>token.is_bracket</code>：返回<code>True</code>令牌是否为括号</li>
<li><code>token.is_quote</code>：返回<code>True</code>令牌是否为引号</li>
<li><code>token.like_url</code>：返回<code>True</code>令牌是否类似于URl（链接到网站）</li>
</ul>
</li>
</ul>
<h2 id="Speech-Tags"><a href="#Speech-Tags" class="headerlink" title="Speech Tags"></a><font color=cornf>Speech Tags</font></h2><ul>
<li><p>打印出所有token的词性标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_text=<span class="string">&#x27;John plays basketball,if time permits. He played in high school too.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> my_doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27;--------&#x27;</span>,token.pos_)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">John -------- PROPN</span><br><span class="line">plays -------- VERB</span><br><span class="line">basketball -------- NOUN</span><br><span class="line">, -------- PUNCT</span><br><span class="line">if -------- SCONJ</span><br><span class="line">time -------- NOUN</span><br><span class="line">permits -------- VERB</span><br><span class="line">. -------- PUNCT</span><br><span class="line">He -------- PRON</span><br><span class="line">played -------- VERB</span><br><span class="line">in -------- ADP</span><br><span class="line">high -------- ADJ</span><br><span class="line">school -------- NOUN</span><br><span class="line">too -------- ADV</span><br><span class="line">. -------- PUNCT</span><br></pre></td></tr></table></figure>
</li>
<li><p>解释标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spacy.explain(<span class="string">&#x27;SCONJ&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#39;subordinating conjunction&#39;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用spacy的<code>pos_</code>属性，您可以检查特定令牌是否为垃圾邮件并删除。(删除类似<code>etc</code>, <code>i.e.</code>等词汇)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">raw_text=<span class="string">&quot;&quot;&quot;I liked the movies etc The movie had good direction  The movie was amazing i.e.</span></span><br><span class="line"><span class="string">            The movie was average direction was not bad The cinematography was nice. i.e.</span></span><br><span class="line"><span class="string">            The movie was a bit lengthy  otherwise fantastic  etc etc&quot;&quot;&quot;</span></span><br><span class="line">raw_doc = nlp(raw_text)</span><br><span class="line">print(<span class="string">&#x27;The junk value are...&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> raw_doc:</span><br><span class="line">    <span class="keyword">if</span> token.pos_==<span class="string">&#x27;X&#x27;</span>:</span><br><span class="line">        print(token.text)</span><br><span class="line">cleaned_doc = [token <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc <span class="keyword">if</span> <span class="keyword">not</span> token.pos_ == <span class="string">&#x27;X&#x27;</span>]</span><br><span class="line">print(cleaned_doc)</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看所有标签</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_tags =  &#123;token.pos: token.pos_ <span class="keyword">for</span> token <span class="keyword">in</span> raw_doc&#125;</span><br><span class="line">print(all_tags)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a><font color=cornf>Named Entity Recognition</font></h2><ul>
<li><p>实体命名识别</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&#x27;Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French&#x27;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">print(doc.ents)</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> doc.ents:</span><br><span class="line">    print(entity.text,<span class="string">&#x27;-------&#x27;</span>,entity.label_)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(Tony Stark, StarkEnterprises, Emily Clark, Microsoft, Manchester, Bible, French)</span><br><span class="line">Tony Stark ------- PERSON</span><br><span class="line">StarkEnterprises ------- ORG</span><br><span class="line">Emily Clark ------- PERSON</span><br><span class="line">Microsoft ------- ORG</span><br><span class="line">Manchester ------- GPE</span><br><span class="line">Bible ------- WORK_OF_ART</span><br><span class="line">French ------- NORP</span><br></pre></td></tr></table></figure>

<p>每个命名实体都属于一个类别，例如人名，组织或城市等。spacy支持的常见命名实体类别为：</p>
<ul>
<li><code>PERSON</code> ：代表人名</li>
<li><code>GPE</code> ：表示县，城市，州等地方。</li>
<li><code>ORG</code> ：表示组织或公司</li>
<li><code>WORK_OF_ART</code> ：表示书籍，电影，歌曲和其他艺术的标题</li>
<li><code>PRODUCT</code> ：表示车辆，食品，家具等产品。</li>
<li><code>EVENT</code> ：表示战争，灾难等历史事件…</li>
<li><code>LANGUAGE</code> ：全球所有公认的语言。</li>
</ul>
</li>
<li><p>可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy <span class="keyword">import</span> displacy</span><br><span class="line">displacy.render(doc,style=<span class="string">&#x27;ent&#x27;</span>,jupyter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221038.png" loading="lazy"></p>
</li>
<li><p>提取品牌名称</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mobile_industry_article=<span class="string">&quot;&quot;&quot; 30 Major mobile phone brands Compete in India – A Case Study of Success and Failures</span></span><br><span class="line"><span class="string">Is the Indian mobile market a terrible War Zone? We have more than 30 brands competing with each other. Let’s find out some insights about the world second-largest mobile bazaar.There is a massive invasion by Chinese mobile brands in India in the last four years. Some of the brands have been able to make a mark while others like Meizu, Coolpad, ZTE, and LeEco are a failure.On one side, there are brands like Sony or HTC that have quit from the Indian market on the other side we have new brands like Realme or iQOO entering the marketing in recent months.The mobile market is so competitive that some of the brands like Micromax, which had over 18% share back in 2014, now have less than 5%. Even the market leader Samsung with a 34% market share in 2014, now has a 21% share whereas Xiaomi has become a market leader. The battle is fierce and to sustain and scale-up is going to be very difficult for any new entrant.new comers in Indian Mobile MarketiQOO –They have recently (March 2020) launched the iQOO 3 in India with its first 5G phone – iQOO 3. The new brand is part of the Vivo or the BBK electronics group that also owns several other brands like Oppo, Oneplus and Realme.Realme – Realme launched the first-ever phone – Realme 1 in November 2018 and has quickly became a popular brand in India. The brand is one of the highest sellers in online space and even reached a 16% market share threatening Xiaomi’s dominance.iVoomi – In 2017, we have seen the entry of some new Chinese mobile brands likeiVoomi which focuses on the sub 10k price range, and is a popular online player. They have an association with Flipkart.Techno &amp;amp; Infinix – Transsion Group’s Tecno and Infinix brands debuted in India in mid-2017 and are focusing on the low end and mid-range phones in the price range of Rs. 5000 to Rs. 12000.10.OR &amp;amp; Lephone – 10.OR has a partnership with Amazon India and is an exclusive online brand with phones like 10.OR D, G and E. However, the brand is not very aggressive currently.Kult – Kult is another player who launched a very aggressively priced Kult Beyond mobile in 2017 and followed up by launching 2-3 more models.However, most of these new brands are finding it difficult to strengthen their footing in India. As big brands like Xiaomi leave no stone unturned to make things difficult.Also, it is worth noting that there is less Chinese players coming to India now. As either all the big brands have already set shop or burnt their hands and retreated to the homeland China.Chinese/ Global  Brands Which failed or are at the Verge of Failing in India?</span></span><br><span class="line"><span class="string">There are a lot more failures in the market than the success stories. Let’s first look at the failures and then we will also discuss why some brands were able to succeed in India.HTC – The biggest surprise this year for me was the failure of HTC in India. The brand has been in the country for many years, in fact, they were the first brand to launch Android mobiles. Finally HTC decided to call it a day in July 2018.LeEco – LeEco looked promising and even threatening to Xiaomi when it came to India. The company launched a series of new phones and smart TVs at affordable rates. Unfortunately, poor financial planning back home caused the brand to fail in India too.LG – The company seems to have lost focus and are doing poorly in all segments. While the budget and mid-range offering are uncompetitive, the high-end models are not preferred by buyers.Sony – Absurd pricing and lack of ability to understand the Indian buyers have caused Sony to shrink mobile operations in India. In the last 2 years, there are far fewer launches and hardly any promotions or hype around the new products.Meizu – Meizu is also a struggling brand in India and is going nowhere with the current strategy. There are hardly any popular mobiles nor a retail presence.ZTE – The company was aggressive till last year with several new phones launching under the Nubia banner, but with recent issues in the US, they have even lost the plot in India.Coolpad – I still remember the first meeting with Coolpad CEO in Mumbai when the brand started operations. There were big dreams and ambitions, but the company has not been able to deliver and keep up with the rivals in the last 1 year.Gionee – Gionee was doing well in the retail, but the infighting in the company and loss of focus from the Chinese parent company has made it a failure. The company is planning a comeback. However, we will have to wait and see when that happens.&quot;&quot;&quot;</span></span><br><span class="line">mobile_doc = nlp(mobile_industry_article)</span><br><span class="line">list_of_org = []</span><br><span class="line"><span class="keyword">for</span> entity <span class="keyword">in</span> mobile_doc.ents:</span><br><span class="line">    <span class="keyword">if</span> entity.label_ == <span class="string">&#x27;ORG&#x27;</span>:</span><br><span class="line">        list_of_org.append(entity.text)</span><br><span class="line">print(list_of_org)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#39;Meizu&#39;, &#39;Sony&#39;, &#39;Vivo&#39;, &#39;Xiaomi&#39;, &#39;Flipkart&#39;, &#39;Techno &amp;amp&#39;, &#39;Infinix – Transsion Group&#39;, &#39;12000.10.OR &amp;amp&#39;, &#39;Lephone&#39;, &#39;Amazon India&#39;, &#39;Global  Brands&#39;, &#39;the Verge of Failing&#39;, &#39;Sony&#39;, &#39;Sony&#39;, &#39;Meizu&#39;, &#39;Meizu&#39;, &#39;Nubia&#39;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>自动掩盖实体</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">news_text=<span class="string">&quot;&quot;&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to Hyderabad, according to a media report on Saturday.Yogesh Ashok Yariava, the prime accused in the fraud, flew from Abu Dhabi to Hyderabad on a Vande Bharat repatriation flight on May 11 with around 170 evacuees, the Gulf News reported.Yariava, the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to India, the daily said.</span></span><br><span class="line"><span class="string">The bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).</span></span><br><span class="line"><span class="string">The list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.</span></span><br><span class="line"><span class="string">The aggrieved traders have filed a case with the Bur Dubai police station.</span></span><br><span class="line"><span class="string">The traders said when the dud cheques started bouncing they rushed to the Royal Luck&#x27;s office in Dubai but the shutters were down, even the fraudulent company&#x27;s warehouses were empty.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">news_doc=nlp(news_text)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_details</span>(<span class="params">word</span>):</span></span><br><span class="line">  <span class="keyword">if</span> word.ent_type_ ==<span class="string">&#x27;PERSON&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;ORG&#x27;</span> <span class="keyword">or</span> word.ent_type_==<span class="string">&#x27;GPE&#x27;</span>:</span><br><span class="line">    print(word,<span class="string">&#x27;-----&#x27;</span>,word.ent_type_)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; UNKNOWN &#x27;</span></span><br><span class="line">  <span class="keyword">return</span> word.string</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_article</span>(<span class="params">doc</span>):</span></span><br><span class="line">    <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents:</span><br><span class="line">        ent.merge()</span><br><span class="line">        <span class="comment"># Iterate over all spans and merge them into one token. This is done</span></span><br><span class="line">        <span class="comment"># after setting the entities – otherwise, it would cause mismatched indices!</span></span><br><span class="line">    tokens = map(remove_details,doc)</span><br><span class="line">    <span class="comment"># map函数：第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个集合。</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(tokens)</span><br><span class="line">update_article(news_doc)</span><br></pre></td></tr></table></figure>

<p>打印结果: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;Indian man has allegedly duped nearly 50 businessmen in the UAE of USD 1.6 million and fled the country in the most unlikely way -- on a repatriation flight to  UNKNOWN , according to a media report on Saturday. UNKNOWN , the prime accused in the fraud, flew from  UNKNOWN to  UNKNOWN on a Vande Bharat repatriation flight on May 11 with around 170 evacuees,  UNKNOWN reported. UNKNOWN , the 36-year-old owner of the fraudulent Royal Luck Foodstuff Trading, made bulk purchases worth 6 million dirhams (USD 1.6 million) against post-dated cheques from unsuspecting traders before fleeing to  UNKNOWN , the daily said.\nThe bought goods included facemasks, hand sanitisers, medical gloves (worth nearly 5,00,000 dirhams), rice and nuts (3,93,000 dirhams), tuna, pistachios and saffron (3,00,725 dirhams), French fries and mozzarella cheese (2,29,000 dirhams), frozen Indian beef (2,07,000 dirhams) and halwa and tahina (52,812 dirhams).\nThe list of items and defrauded persons keeps getting longer as more and more victims come forward, the report said.\nThe aggrieved traders have filed a case with the  UNKNOWN police station.\nThe traders said when the dud cheques started bouncing they rushed to  UNKNOWN office in  UNKNOWN but the shutters were down, even the fraudulent company&#39;s warehouses were empty.&quot;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Rule-based-Matching"><a href="#Rule-based-Matching" class="headerlink" title="Rule based Matching"></a><font color=cornf>Rule based Matching</font></h2><ul>
<li><p>导入模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> Matcher</span><br></pre></td></tr></table></figure>
</li>
<li><p>过程</p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115221506.png" loading="lazy"></p>
</li>
</ul>
<ul>
<li><p>模式匹配 <code>Example1</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">my_text = <span class="string">&#x27;The version : 6 of the app was released about a year back and was not very sucessful. As a comeback, six months ago, version : 7 was released and it took the stage. After that , the app has has the limelight till now. On interviewing some sources, we get to know that they have outlined visiond till version : 12 ,the Ultimate.&#x27;</span></span><br><span class="line">my_doc = nlp(my_text)</span><br><span class="line"></span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LOWER&quot;</span>:<span class="string">&quot;version&quot;</span>&#125;,&#123;<span class="string">&quot;IS_PUNCT&quot;</span>:<span class="literal">True</span>&#125;,&#123;<span class="string">&quot;LIKE_NUM&quot;</span>:<span class="literal">True</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;VersionFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">desired_matches = mather(my_doc)</span><br><span class="line">desired_matches</span><br></pre></td></tr></table></figure>

<p>打印desired_matches的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[(6950581368505071052, 1, 4),</span><br><span class="line"> (6950581368505071052, 27, 30),</span><br><span class="line"> (6950581368505071052, 65, 68)]</span><br></pre></td></tr></table></figure>

<p>打印出找到的token:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> match_id,start,end <span class="keyword">in</span> desired_matches:</span><br><span class="line">    string_id = nlp.vocab.strings[match_id]</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">version : 6</span><br><span class="line">version : 7</span><br><span class="line">version : 12</span><br></pre></td></tr></table></figure>
</li>
<li><p>模式识别 <code>Example 2</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">&quot;&quot;&quot;I visited Manali last time. Around same budget trips ? &quot;</span></span><br><span class="line"><span class="string">    I was visiting Ladakh this summer &quot;</span></span><br><span class="line"><span class="string">    I have planned visiting NewYork and other abroad places for next year&quot;</span></span><br><span class="line"><span class="string">    Have you ever visited Kodaikanal? &quot;&quot;&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">mather = Matcher(nlp.vocab)</span><br><span class="line">my_pattern = [&#123;<span class="string">&quot;LEMMA&quot;</span>: <span class="string">&quot;visit&quot;</span>&#125;, &#123;<span class="string">&quot;POS&quot;</span>: <span class="string">&quot;PROPN&quot;</span>&#125;]</span><br><span class="line">mather.add(<span class="string">&#x27;PlaceFinder&#x27;</span>,<span class="literal">None</span>,my_pattern)</span><br><span class="line">matches = mather(doc)</span><br><span class="line">print(<span class="string">&quot; mather found: &quot;</span>,len(matches))</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    print(<span class="string">&#x27;Match Found:&#x27;</span>,doc[start:end].text)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mather found:  4</span><br><span class="line">Match Found: visited Manali</span><br><span class="line">Match Found: visiting Ladakh</span><br><span class="line">Match Found: visiting NewYork</span><br><span class="line">Match Found: visited Kodaikanal</span><br></pre></td></tr></table></figure>
</li>
<li><p>复杂的匹配条件: 其中第一个令牌具有POS标记为NOUN或ADJ的条件, 第二个token为<code>engineering</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_pattern = [&#123;<span class="string">&quot;POS&quot;</span>: &#123;<span class="string">&quot;IN&quot;</span>: [<span class="string">&quot;NOUN&quot;</span>, <span class="string">&quot;ADJ&quot;</span>]&#125;&#125;, &#123;<span class="string">&quot;LOWER&quot;</span>: <span class="string">&quot;engineering&quot;</span>&#125;]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Phrase-Matcher"><a href="#Phrase-Matcher" class="headerlink" title="Phrase Matcher"></a><font color=cornf>Phrase Matcher</font></h2><ul>
<li><p>导入模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.matcher <span class="keyword">import</span> PhraseMatcher</span><br></pre></td></tr></table></figure>
</li>
<li><p>定义模式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab)</span><br><span class="line">terms_list = [<span class="string">&#x27;Bruce Wayne&#x27;</span>, <span class="string">&#x27;Tony Stark&#x27;</span>, <span class="string">&#x27;Batman&#x27;</span>, <span class="string">&#x27;Harry Potter&#x27;</span>, <span class="string">&#x27;Severus Snape&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line"><span class="comment"># 将短语列表转换为doc对象。它更快并且节省时间。make_doc()</span></span><br><span class="line">matcher.add(<span class="string">&#x27;phrase_matcher&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line"></span><br><span class="line">matches = matcher(doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = fictional_char_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>打印结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Batman</span><br><span class="line">Batman</span><br><span class="line">Harry Potter</span><br><span class="line">Harry Potter</span><br><span class="line">Tony Stark</span><br></pre></td></tr></table></figure>

<p>可以发现小写单词的无法识别出来, 那么做一下改进</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line"><span class="comment"># 如果使用，则将发生不区分大小写的匹配。attr=&#x27;LOWER&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>举个例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">case_insensitive_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;LOWER&#x27;</span>)</span><br><span class="line">my_doc = nlp(<span class="string">&#x27;I wish to visit new york city.&#x27;</span>)</span><br><span class="line">terms_list = [<span class="string">&#x27;New York&#x27;</span>]</span><br><span class="line">patterns = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> terms_list]</span><br><span class="line">case_insensitive_matcher.add(<span class="string">&#x27;mather&#x27;</span>,<span class="literal">None</span>,*patterns)</span><br><span class="line">my_matches = case_insensitive_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> my_matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>打印结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new york</span><br></pre></td></tr></table></figure>
</li>
<li><p>匹配将基于pattern中术语的形状。<code>attr=&#39;SHAPE&#39;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">my_doc = nlp(<span class="string">&#x27;From 8 am , Mr.X will be speaking on your favorite chanel 191.1. Afterward there shall be an exclusive interview with actor Vijay on channel 194.1 . Hope you are having a great day. Call us on 666666&#x27;</span>)</span><br><span class="line">pattern = nlp(<span class="string">&#x27;154.6&#x27;</span>)</span><br><span class="line">pincode_matcher = PhraseMatcher(nlp.vocab,attr=<span class="string">&#x27;SHAPE&#x27;</span>)</span><br><span class="line">pincode_matcher.add(<span class="string">&#x27;pincode_matching&#x27;</span>,<span class="literal">None</span>,pattern)</span><br><span class="line">matches = pincode_matcher(my_doc)</span><br><span class="line"><span class="keyword">for</span> string_id,start,end <span class="keyword">in</span> matches:</span><br><span class="line">    span = my_doc[start:end]</span><br><span class="line">    print(span.text)</span><br></pre></td></tr></table></figure>

<p>打印结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">191.1</span><br><span class="line">194.1</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Entity-Ruler"><a href="#Entity-Ruler" class="headerlink" title="Entity Ruler"></a><font color=cornf>Entity Ruler</font></h2><ul>
<li><p>默认情况下无法识别某些名称或组织。可能是因为它们规模很小或稀有。使用EnityRuler, 基于模式词典匹配命名实体, 从而使命名实体识别更加有效</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> spacy.pipeline <span class="keyword">import</span> EntityRuler</span><br><span class="line">ruler = EntityRuler(nlp)</span><br><span class="line">pattern=[&#123;<span class="string">&quot;label&quot;</span>: <span class="string">&quot;WORK_OF_ART&quot;</span>, <span class="string">&quot;pattern&quot;</span>: <span class="string">&quot;My guide to statistics&quot;</span>&#125;]</span><br><span class="line">ruler.name = <span class="string">&#x27;new_ruler&#x27;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ruler.add_patterns(pattern)</span><br><span class="line">nlp.add_pipe(ruler)</span><br><span class="line"><span class="comment"># 现在，EntityRuler已合并到中nlp。您可以将文本文档传递nlp给以创建spacy doc。</span></span><br><span class="line">doc = nlp(<span class="string">&quot; I recently published my work fanfiction by Dr.X . Right now I&#x27;m studying the book of my friend .You should try My guide to statistics for clear concepts.&quot;</span>)</span><br><span class="line">print([(ent.text,ent.label_) <span class="keyword">for</span> ent <span class="keyword">in</span> doc.ents])</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&#39;My guide to statistics&#39;, &#39;WORK_OF_ART&#39;)]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Word-Vector-and-Similarity"><a href="#Word-Vector-and-Similarity" class="headerlink" title="Word Vector and Similarity"></a><font color=cornf>Word Vector and Similarity</font></h2><ul>
<li><p>单词向量: <code>token.has_vector</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_md&quot;</span>)</span><br><span class="line">doc = nlp(<span class="string">&quot;I　am a excellent people&quot;</span>)</span><br><span class="line">doc_another = nlp(<span class="string">&quot;I wish to go to hogwarts lolXD&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc_another:</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.has_vector)</span><br><span class="line">    print(token.text,<span class="string">&#x27; &#x27;</span>,token.vector_norm)	<span class="comment"># 表示L2范数</span></span><br><span class="line">    print(<span class="string">&#x27;------------------------------&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">I   True</span><br><span class="line">I   6.4231944</span><br><span class="line">------------------------------</span><br><span class="line">wish   True</span><br><span class="line">wish   5.1652417</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">go   True</span><br><span class="line">go   5.05723</span><br><span class="line">------------------------------</span><br><span class="line">to   True</span><br><span class="line">to   4.74484</span><br><span class="line">------------------------------</span><br><span class="line">hogwarts   True</span><br><span class="line">hogwarts   7.4110312</span><br><span class="line">------------------------------</span><br><span class="line">lolXD   False</span><br><span class="line">lolXD   0.0</span><br><span class="line">------------------------------</span><br></pre></td></tr></table></figure>
</li>
<li><p>单词相似性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">review_1=nlp(<span class="string">&#x27; The food was amazing&#x27;</span>)</span><br><span class="line">review_2=nlp(<span class="string">&#x27;The food was excellent&#x27;</span>)</span><br><span class="line">review_3=nlp(<span class="string">&#x27;I did not like the food&#x27;</span>)</span><br><span class="line">review_4=nlp(<span class="string">&#x27;It was very bad experience&#x27;</span>)</span><br><span class="line">score_1 = review_1.similarity(review_2)</span><br><span class="line">print(score_1)</span><br><span class="line">score_2 = review_3.similarity(review_4)</span><br><span class="line">print(score_2)</span><br><span class="line"><span class="comment"># 您会看到前两个评论具有很高的相似性评分，因此将属于同一类别（正面）。</span></span><br><span class="line"><span class="comment"># 数值很低则代表完全不相关</span></span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.9566209228174343</span><br><span class="line">0.8461895934074601</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Merging-and-Splitting-Tokens-with-retokenize"><a href="#Merging-and-Splitting-Tokens-with-retokenize" class="headerlink" title="Merging and Splitting Tokens with retokenize"></a><font color=cornf>Merging and Splitting Tokens with retokenize</font></h2><ul>
<li><p>组合令牌：set the <code>POS</code> (part of speech tag) for “John Wick” as <code>PROPN</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从输出中可以看到，“ John”和“ Wick”已被识别为单独的标记。导演的名字“ Chad Stahelski”也是如此</span></span><br><span class="line"><span class="comment"># 但是在这种情况下，如果将“ John Wick”视为单个令牌，将更加容易。</span></span><br><span class="line">text = <span class="string">&quot;John Wick is a 2014 American action thriller film directed by Chad Stahelski&quot;</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    attrs = &#123;<span class="string">&quot;POS&quot;</span>:<span class="string">&quot;PROPN&quot;</span>&#125;</span><br><span class="line">    retokenizer.merge(doc[<span class="number">0</span>:<span class="number">2</span>],attrs)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text,token.pos_)</span><br></pre></td></tr></table></figure>

<p>打印结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">John Wick PROPN</span><br><span class="line">is AUX</span><br><span class="line">a DET</span><br><span class="line">2014 NUM</span><br><span class="line">American ADJ</span><br><span class="line">action NOUN</span><br><span class="line">thriller NOUN</span><br><span class="line">film NOUN</span><br><span class="line">directed VERB</span><br><span class="line">by ADP</span><br><span class="line">Chad PROPN</span><br><span class="line">Stahelski PROPN</span><br></pre></td></tr></table></figure>
</li>
<li><p>拆分令牌：将 <code>OnePlus7</code> 拆分成 <code>OnePlus</code> 和 <code>7</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">doc=nlp(<span class="string">&#x27;I purchased the trendy OnePlus7 &#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> doc.retokenize() <span class="keyword">as</span> retokenizer:</span><br><span class="line">    <span class="comment"># heads = [(doc[4],0),(doc[4],1)]</span></span><br><span class="line">    <span class="comment"># heads = [doc[0],doc[1]]</span></span><br><span class="line">    heads = [(doc[<span class="number">2</span>],<span class="number">1</span>),(doc[<span class="number">2</span>],<span class="number">0</span>)]</span><br><span class="line">    print(heads)</span><br><span class="line">    retokenizer.split(doc[<span class="number">4</span>],[<span class="string">&quot;OnePlus&quot;</span>,<span class="string">&quot;7&quot;</span>],heads=heads)</span><br><span class="line"><span class="keyword">for</span> token <span class="keyword">in</span> doc:</span><br><span class="line">    print(token.text)</span><br></pre></td></tr></table></figure>

<p>❓ 不知道为啥 <code>heads</code> 瞎写都可以, 但是要满足两个条件: :one:如果要把待拆分的token分成n个,那么heads里的元素也要有n个,否则会报错 :two:heads里, doc的下标不能越界。看了官方文档也没有弄明白😥</p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" loading="lazy"></p>
<p><img src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210115224626.png" alt="spacy02" loading="lazy"></p>
</li>
</ul>
<h2 id="Pipeline-components"><a href="#Pipeline-components" class="headerlink" title="Pipeline components "></a><font color=cornf>Pipeline components </font></h2><ul>
<li><p>查看管道组件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">&quot;en_core_web_sm&quot;</span>)</span><br><span class="line">print(nlp.pipe_names)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.add_pipe(nlp.create_pipe(<span class="string">&#x27;textcat&#x27;</span>),before=<span class="string">&#x27;ner&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>如果用<code>juypter notebook</code>跑这段代码，只能跑一次否则就会报错，说这个已经存在了。</p>
</li>
<li><p>移除管道组件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nlp.remove_pipe(<span class="string">&#x27;textcat&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>换个名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nlp.rename_pipe(old_name=<span class="string">&#x27;ner&#x27;</span>,new_name=<span class="string">&#x27;new_ner&#x27;</span>)</span><br><span class="line">nlp.pipe_names</span><br></pre></td></tr></table></figure>
</li>
<li><p>一样的结果：<code>nlp.make_doc()</code> 和 <code>nlp()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docs = [nlp(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br><span class="line">docs = [nlp.make_doc(text) <span class="keyword">for</span> text <span class="keyword">in</span> list_of_text_data]</span><br><span class="line">print(docs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>比 <code>nlp()</code> 更快的处理方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docs = list(nlp.pipe(list_of_text_data))</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a><font color=mediumseagreen>Tutorials</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.machinelearningplus.com/spacy-tutorial-nlp/">[SpaCy Tutorial – Complete Writeup]</a> 主要来源于这篇，写的太全了。不过有些没看懂。</li>
</ul>
<h2 id="Official-Documentation"><a href="#Official-Documentation" class="headerlink" title="Official Documentation"></a><font color=mediumseagreen>Official Documentation</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/visualizers">VIsualization: Displacy</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/linguistic-features#_title">Linguistic Features</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/rule-based-matching#_title">Rule-based matching</a></li>
<li><a target="_blank" rel="noopener" href="https://explosion.ai/demos/matcher?text=A%20match%20is%20a%20tool%20for%20starting%20a%20fire.%20Typically,%20modern%20matches%20are%20made%20of%20small%20wooden%20sticks%20or%20stiff%20paper.%20One%20end%20is%20coated%20with%20a%20material%20that%20can%20be%20ignited%20by%20frictional%20heat%20generated%20by%20striking%20the%20match%20against%20a%20suitable%20surface.%20Wooden%20matches%20are%20packaged%20in%20matchboxes,%20and%20paper%20matches%20are%20partially%20cut%20into%20rows%20and%20stapled%20into%20matchbooks.&model=en_core_web_sm&pattern=%5B%7B%22id%22:1,%22attrs%22:%5B%7B%22name%22:%22LEMMA%22,%22value%22:%22visit%22%7D,%7B%22name%22:%22POS%22,%22value%22:%22PROPN%22%7D%5D%7D%5D">Rule-based Matcher Explorer</a></li>
</ul>
<h2 id="CSDN-tutorials"><a href="#CSDN-tutorials" class="headerlink" title="CSDN tutorials"></a><font color=mediumseagreen>CSDN tutorials</font></h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Chen_he_Zhang/article/details/105345353">Spcay 安装</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u012436149/article/details/79321112">使用 spacy 进行自然语言处理（一）</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/bmicnj/article/details/107189649?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-11.control">python spacy库使用总结【待完善】</a></p>
</li>
</ul>
<h2 id="Bugs"><a href="#Bugs" class="headerlink" title="Bugs"></a><font color=mediumseagreen>Bugs</font></h2><ul>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51412095/spacy-save-custom-pipeline">Can’t find factory for ‘xxxxxxx’</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/57536044/add-multiple-entityruler-with-spacy-valueerror-entity-ruler-already-exists-i">ValueError: ‘entity_ruler’ already exists in pipeline</a></li>
</ul>
</div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="Donate" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none;"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090449.jpg"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090449.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090448.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090448.png" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090450.png"><img loading="lazy" src="https://cdn.jsdelivr.net/gh/AllMainAshley/CDN@master/images/20210119090450.png" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>Post author: </strong>程海盐</li><li class="post-copyright-link"><strong>Post link: </strong><a href="https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/" title="Spacy tutorial">https://allmainashley.github.io/2021/01/15/Notes/Machine%20Learning/Spacy%20tutorial/</a></li><li class="post-copyright-license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> unless otherwise stated.</li></ul></section></article><div class="post-nav"><div class="post-nav-item"></div><div class="post-nav-item"><a class="post-nav-next" href="/2021/01/09/Notes/Machine%20Learning/NLP%20Relevant%20Knowledge/" rel="next" title="NLP Relevant Knowledge"><span class="post-nav-text">NLP Relevant Knowledge</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div id="comment"><div class="comment-tooltip text-center"><span>若您无 GitHub 账号，可直接在下方匿名评论。</span><br><span>若您想及时得到回复提醒，建议跳转 GitHub Issues 评论。</span><br><span>若没有本文 Issue，您可以使用 Comment 模版新建。</span><br><a class="hty-button hty-button--raised" id="github-issues" target="_blank" rel="noopener" href="https://github.com/AllMainAshley/AllMainAshley.github.io/issues?q=is:issue+Spacy tutorial">GitHub Issues</a><a class="hty-button hty-button--raised" id="github-discussions" target="_blank" rel="noopener" href="https://github.com/YunYouJun/yunyoujun.github.io/discussions/new">GitHub Discussions</a></div><div id="valine-container"></div><script>Yun.utils.getScript("https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js", () => {
  const valineConfig = {"enable":true,"appId":"duRJqtj9W4MnlhHrkhx0O3vb-gzGzoHsz","appKey":"7GxBY57ustzpxvpwNr39XneW","placeholder":"I want to say...","avatar":null,"pageSize":10,"visitor":false,"highlight":true,"recordIP":false,"enableQQ":true,"el":"#valine-container","lang":"en"}
  valineConfig.path = window.location.pathname
  new Valine(valineConfig)
}, window.Valine);</script></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2020 – 2021 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 程海盐</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v5.2.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.4.0</span></div><div class="live_time"><span>本博客已萌萌哒地运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2020-05-10T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();
</script></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="Search"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script src="/js/search/local-search.js" defer></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"><input class="search-input" id="local-search-input" type="text" placeholder="Searching..." value=""></div><div id="local-search-result"></div></div></div></body></html>